{"ast":null,"code":"/**\n * @file Definitions of all models available in Transformers.js.\n * \n * **Example:** Load and run an `AutoModel`.\n * \n * ```javascript\n * import { AutoModel, AutoTokenizer } from '@xenova/transformers';\n *\n * let tokenizer = await AutoTokenizer.from_pretrained('Xenova/bert-base-uncased');\n * let model = await AutoModel.from_pretrained('Xenova/bert-base-uncased');\n *\n * let inputs = await tokenizer('I love transformers!');\n * let { logits } = await model(inputs);\n * // Tensor {\n * //     data: Float32Array(183132) [-7.117443084716797, -7.107812881469727, -7.092104911804199, ...]\n * //     dims: (3) [1, 6, 30522],\n * //     type: \"float32\",\n * //     size: 183132,\n * // }\n * ```\n * \n * We also provide other `AutoModel`s (listed below), which you can use in the same way as the Python library. For example:\n * \n * **Example:** Load and run a `AutoModelForSeq2SeqLM`.\n * ```javascript\n * import { AutoModelForSeq2SeqLM, AutoTokenizer } from '@xenova/transformers';\n * \n * let tokenizer = await AutoTokenizer.from_pretrained('Xenova/t5-small');\n * let model = await AutoModelForSeq2SeqLM.from_pretrained('Xenova/t5-small');\n *\n * let { input_ids } = await tokenizer('translate English to German: I love transformers!');\n * let outputs = await model.generate(input_ids);\n * let decoded = await tokenizer.decode(outputs[0][0], { skip_special_tokens: true });\n * // 'Ich liebe Transformatoren!'\n * ```\n * \n * @module models\n */\n\nimport { AutoConfig } from './configs.js';\nimport { Callable, isIntegralNumber, isTypedArray } from './utils/core.js';\nimport { getModelFile, getModelJSON } from './utils/hub.js';\nimport { LogitsProcessorList, GenerationConfig, ForceTokensLogitsProcessor, ForcedBOSTokenLogitsProcessor, ForcedEOSTokenLogitsProcessor, SuppressTokensAtBeginLogitsProcessor, WhisperTimeStampLogitsProcessor, NoRepeatNGramLogitsProcessor, RepetitionPenaltyLogitsProcessor, Sampler } from './utils/generation.js';\nimport { Tensor } from './utils/tensor.js';\nimport { executionProviders, ONNX } from './backends/onnx.js';\nconst {\n  InferenceSession,\n  Tensor: ONNXTensor\n} = ONNX;\n\n/**\n * @typedef {import('./utils/hub.js').PretrainedOptions} PretrainedOptions\n */\n\n//////////////////////////////////////////////////\n// Model types: used internally\nclass ModelType {}\n;\n\n// Either encoder-only or encoder-decoder (and will be decided by `model.config.is_encoder_decoder`)\nclass EncoderOnlyModelType extends ModelType {}\n;\nclass EncoderDecoderModelType extends ModelType {}\n;\nclass Seq2SeqModelType extends EncoderDecoderModelType {}\n;\nclass DecoderOnlyModelType extends ModelType {}\n;\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// Helper functions\n\n// Will be populated later\nconst MODEL_TYPE_MAPPING = new Map();\nconst MODEL_CLASS_MAPPING = new Map();\n\n/**\n * Helper function to determine which `forward` method to run for a specific model.\n * @param {Object} self The calling object\n * @param {Object} model_inputs The inputs to be sent to the model\n * @returns {Promise<Object>} The model output\n */\nasync function forward(self, model_inputs) {\n  if (MODEL_TYPE_MAPPING.get(self.constructor.name) === DecoderOnlyModelType) {\n    return await decoderForward(self, model_inputs);\n  } else {\n    return await encoderForward(self, model_inputs);\n  }\n}\n\n/**\n * Constructs an InferenceSession using a model file located at the specified path.\n * @param {string} pretrained_model_name_or_path The path to the directory containing the model file.\n * @param {string} fileName The name of the model file.\n * @param {PretrainedOptions} options Additional options for loading the model.\n * @returns {Promise<InferenceSession>} A Promise that resolves to an InferenceSession object.\n * @private\n */\nasync function constructSession(pretrained_model_name_or_path, fileName, options) {\n  // TODO add option for user to force specify their desired execution provider\n  let modelFileName = `onnx/${fileName}${options.quantized ? '_quantized' : ''}.onnx`;\n  let buffer = await getModelFile(pretrained_model_name_or_path, modelFileName, true, options);\n  try {\n    return await InferenceSession.create(buffer, {\n      executionProviders\n    });\n  } catch (err) {\n    // If the execution provided was only wasm, throw the error\n    if (executionProviders.length === 1 && executionProviders[0] === 'wasm') {\n      throw err;\n    }\n    console.warn(err);\n    console.warn('Something went wrong during model construction (most likely a missing operation). ' + 'Using `wasm` as a fallback. ');\n    return await InferenceSession.create(buffer, {\n      executionProviders: ['wasm']\n    });\n  }\n}\n\n/**\n * Validate model inputs\n * @param {InferenceSession} session The InferenceSession object that will be run.\n * @param {Object} inputs The inputs to check.\n * @returns {Promise<Object>} A Promise that resolves to the checked inputs.\n * @throws {Error} If any inputs are missing.\n * @private\n */\nasync function validateInputs(session, inputs) {\n  // NOTE: Only create a shallow copy\n  const checkedInputs = {};\n  const missingInputs = [];\n  for (let inputName of session.inputNames) {\n    if (inputs[inputName] === undefined) {\n      missingInputs.push(inputName);\n    } else {\n      checkedInputs[inputName] = inputs[inputName];\n    }\n  }\n  if (missingInputs.length > 0) {\n    throw new Error(`An error occurred during model execution: \"Missing the following inputs: ${missingInputs.join(', ')}.`);\n  }\n  const numInputsProvided = Object.keys(inputs).length;\n  const numInputsNeeded = session.inputNames.length;\n  if (numInputsProvided > numInputsNeeded) {\n    // No missing inputs, but too many inputs were provided.\n    // Warn the user and ignore the extra inputs.\n    let ignored = Object.keys(inputs).filter(inputName => !session.inputNames.includes(inputName));\n    console.warn(`WARNING: Too many inputs were provided (${numInputsProvided} > ${numInputsNeeded}). The following inputs will be ignored: \"${ignored.join(', ')}\".`);\n  }\n  return checkedInputs;\n}\n\n/**\n * Executes an InferenceSession using the specified inputs.\n * NOTE: `inputs` must contain at least the input names of the model.\n *  - If additional inputs are passed, they will be ignored.\n *  - If inputs are missing, an error will be thrown.\n * \n * @param {InferenceSession} session The InferenceSession object to run.\n * @param {Object} inputs An object that maps input names to input tensors.\n * @returns {Promise<Object>} A Promise that resolves to an object that maps output names to output tensors.\n * @private\n */\nasync function sessionRun(session, inputs) {\n  const checkedInputs = await validateInputs(session, inputs);\n  try {\n    let output = await session.run(checkedInputs);\n    output = replaceTensors(output);\n    return output;\n  } catch (e) {\n    // This usually occurs when the inputs are of the wrong type.\n    console.error(`An error occurred during model execution: \"${e}\".`);\n    console.error('Inputs given to model:', checkedInputs);\n    throw e;\n  }\n}\n\n/**\n * Replaces ONNX Tensor objects with custom Tensor objects to support additional functions.\n * @param {Object} obj The object to replace tensor objects in.\n * @returns {Object} The object with tensor objects replaced by custom Tensor objects.\n * @private\n */\nfunction replaceTensors(obj) {\n  for (let prop in obj) {\n    if (obj[prop] instanceof ONNXTensor) {\n      obj[prop] = new Tensor(obj[prop]);\n    }\n  }\n  return obj;\n}\n\n/**\n * Converts an array or Tensor of integers to an int64 Tensor.\n * @param {Array|Tensor} items The input integers to be converted.\n * @returns {Tensor} The int64 Tensor with the converted values.\n * @throws {Error} If the input array is empty or the input is a batched Tensor and not all sequences have the same length.\n * @private\n */\nfunction toI64Tensor(items) {\n  if (items instanceof Tensor) {\n    return items;\n  }\n  // items is an array\n  if (items.length === 0) {\n    throw Error(\"items must be non-empty\");\n  }\n  if (Array.isArray(items[0])) {\n    // batched\n    if (items.some(x => x.length !== items[0].length)) {\n      throw Error(\"Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' and/or 'truncation=True' to have batched tensors with the same length.\");\n    }\n    return new Tensor('int64', BigInt64Array.from(items.flat().map(x => BigInt(x))), [items.length, items[0].length]);\n  } else {\n    //flat\n    return new Tensor('int64', BigInt64Array.from(items.map(x => BigInt(x))), [1, items.length]);\n  }\n}\n\n/**\n * Prepares an attention mask for a sequence of tokens based on configuration options.\n * @param {Object} self The calling object instance.\n * @param {Tensor} tokens The input tokens.\n * @returns {Tensor} The attention mask tensor.\n * @private\n */\nfunction prepareAttentionMask(self, tokens) {\n  // Prepare attention mask\n  let pad_token_id = self.config.pad_token_id ?? null;\n  let eos_token_id = self.config.eos_token_id ?? null;\n  if (isIntegralNumber(eos_token_id)) {\n    eos_token_id = [eos_token_id];\n  }\n  let is_pad_token_in_inputs = tokens.indexOf(pad_token_id) !== -1;\n  let is_pad_token_not_equal_to_eos_token_id = eos_token_id === null || !eos_token_id.includes(pad_token_id);\n  if (is_pad_token_in_inputs && is_pad_token_not_equal_to_eos_token_id) {\n    let data = BigInt64Array.from(\n    // Note: != so that int matches bigint\n    tokens.data.map(x => x != pad_token_id));\n    return new Tensor('int64', data, tokens.dims);\n  } else {\n    return new Tensor('int64', new BigInt64Array(tokens.data.length).fill(1n), tokens.dims);\n  }\n}\n\n/**\n * Creates a boolean tensor with a single value.\n * @param {boolean} value The value of the tensor.\n * @returns {Tensor} The boolean tensor.\n * @private\n */\nfunction boolTensor(value) {\n  return new Tensor('bool', [value], [1]);\n}\n\n// JS doesn't support mixins, so we define some reused functions here, and allow \"this\" to be passed in\n/**\n * Perform forward pass on the seq2seq model (both encoder and decoder).\n * @param {Object} self The seq2seq model object.\n * @param {Object} model_inputs The input object for the model containing encoder and decoder inputs.\n * @param {Object} options The options\n * @param {boolean} [options.add_decoder_pkv=true] Flag to add the decoder past key values.\n * @returns {Promise<Seq2SeqLMOutput>} Promise that resolves with the output of the seq2seq model.\n * @private\n */\nasync function seq2seqForward(self, model_inputs) {\n  let {\n    add_decoder_pkv = true\n  } = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n  let {\n    encoder_outputs,\n    past_key_values\n  } = model_inputs;\n  if (!encoder_outputs) {\n    // Encoder outputs are not given, so we must compute them.\n    encoder_outputs = (await encoderForward(self, model_inputs)).last_hidden_state;\n  }\n  let decoderFeeds = {\n    input_ids: model_inputs.decoder_input_ids,\n    encoder_hidden_states: encoder_outputs,\n    use_cache_branch: boolTensor(past_key_values !== null)\n  };\n  if (self.decoder_merged_session.inputNames.includes('encoder_attention_mask')) {\n    decoderFeeds.encoder_attention_mask = model_inputs.attention_mask;\n  }\n  self.addPastKeyValues(decoderFeeds, past_key_values, add_decoder_pkv);\n  const decoderResults = await sessionRun(self.decoder_merged_session, decoderFeeds);\n  let logits = decoderResults.logits;\n  past_key_values = self.getPastKeyValues(decoderResults, past_key_values);\n  return new Seq2SeqLMOutput({\n    logits,\n    past_key_values,\n    encoder_outputs\n  });\n}\n\n/**\n * Start the beam search process for the seq2seq model.\n * @param {Object} self The seq2seq model object.\n * @param {Object[]} inputTokenIds Array of input token ids for each input sequence.\n * @param {number} numOutputTokens The maximum number of output tokens for the model.\n * @param {boolean} [requires_attention_mask=true] Flag to indicate if the model requires an attention mask.\n * @returns {Object[]} Array of beam search objects.\n * @private\n */\nfunction seq2seqStartBeams(self, inputTokenIds, numOutputTokens) {\n  let requires_attention_mask = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : true;\n  let beams = [];\n  let beamId = 0;\n\n  // decoder_input_ids == output_token_ids\n  let decoder_input_ids = self.config.decoder_start_token_id;\n  if (!Array.isArray(decoder_input_ids)) {\n    decoder_input_ids = [decoder_input_ids];\n  }\n  for (let tokens of inputTokenIds) {\n    // TODO: Improve\n    // Currently, just add back batch dimension.\n    // In future, allow for true parallel execution\n    tokens.dims = [1, ...tokens.dims];\n\n    // Create beam\n    let start = {\n      inputs: tokens,\n      encoder_outputs: null,\n      past_key_values: null,\n      output_token_ids: decoder_input_ids,\n      done: false,\n      score: 0,\n      id: beamId++ // assign unique id to beams\n    };\n\n    if (requires_attention_mask) {\n      start.attention_mask = prepareAttentionMask(self, tokens);\n    }\n    beams.push(start);\n  }\n  return beams;\n}\n\n/**\n * Run beam search on the seq2seq model for a single beam.\n * @param {Object} self The seq2seq model object.\n * @param {Object} beam The beam search object for which to run the model.\n * @param {Object} options options\n * @param {string} [options.input_name='input_ids'] The name of the input tensor for the encoder.\n * @returns {Promise<Object>} Promise that resolves with the output of the seq2seq model for the given beam.\n * @private\n */\nasync function seq2seqRunBeam(self, beam) {\n  let {\n    input_name = 'input_ids'\n  } = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n  // 1. Prepare\n  let model_inputs = {\n    [input_name]: beam.inputs,\n    decoder_input_ids: toI64Tensor(beam.output_token_ids.slice(-1)),\n    encoder_outputs: beam.encoder_outputs,\n    past_key_values: beam.past_key_values\n  };\n  if (beam.attention_mask) {\n    model_inputs.attention_mask = beam.attention_mask;\n  }\n\n  // 2. Run\n  let output = await self.forward(model_inputs);\n\n  // 3. Update\n  beam.past_key_values = output.past_key_values;\n  beam.encoder_outputs = output.encoder_outputs;\n  return output;\n}\n\n/**\n * Forward pass of an encoder model.\n * @param {Object} self The encoder model.\n * @param {Object} model_inputs The input data to be used for the forward pass.\n * @returns {Promise<Object>} Promise that resolves with an object containing the model's outputs.\n * @private\n */\nasync function encoderForward(self, model_inputs) {\n  let encoderFeeds = {};\n  for (let key of self.session.inputNames) {\n    encoderFeeds[key] = model_inputs[key];\n  }\n  return await sessionRun(self.session, encoderFeeds);\n}\n\n/**\n * Forward pass of a decoder model.\n * @param {Object} self The decoder model.\n * @param {Object} model_inputs The input data to be used for the forward pass.\n * @returns {Promise<Object>} Promise that resolves with an object containing the logits and past key values.\n * @private\n */\nasync function decoderForward(self, model_inputs) {\n  let past_key_values = model_inputs.past_key_values;\n  let decoderFeeds = {\n    input_ids: model_inputs.input_ids,\n    attention_mask: model_inputs.attention_mask ?? prepareAttentionMask(self, model_inputs.input_ids),\n    use_cache_branch: boolTensor(past_key_values !== null)\n  };\n  self.addPastKeyValues(decoderFeeds, past_key_values);\n  let decoderResults = await sessionRun(self.session, decoderFeeds);\n  let logits = decoderResults.logits;\n  past_key_values = self.getPastKeyValues(decoderResults, past_key_values);\n  return {\n    logits,\n    past_key_values\n  };\n}\n\n/**\n * Starts the generation of text by initializing the beams for the given input token IDs.\n * @param {Object} self The text generation model object.\n * @param {any} inputTokenIds An array of input token IDs to generate text from.\n * @param {number} numOutputTokens The maximum number of tokens to generate for each beam.\n * @param {Tensor} [inputs_attention_mask] The attention mask tensor for the input token IDs.\n * @returns {Object[]} An array of beams initialized with the given inputs and parameters.\n * @private\n */\nfunction decoderStartBeams(self, inputTokenIds, numOutputTokens, inputs_attention_mask) {\n  let beams = [];\n  let beamId = 0;\n  for (let tokens of inputTokenIds) {\n    // TODO: Improve\n    // Currently, just add back batch dimension.\n    // In future, allow for true parallel execution\n    tokens.dims = [1, ...tokens.dims];\n    let attn_mask;\n    if (inputs_attention_mask) {\n      attn_mask = inputs_attention_mask[beamId];\n      attn_mask.dims = [1, ...attn_mask.dims];\n    } else {\n      attn_mask = prepareAttentionMask(self, tokens);\n    }\n    let start = {\n      input: tokens,\n      model_input_ids: tokens,\n      attention_mask: attn_mask,\n      past_key_values: null,\n      output_token_ids: [],\n      num_output_tokens: numOutputTokens,\n      done: false,\n      score: 0,\n      id: beamId++ // assign unique id to beams\n    };\n\n    beams.push(start);\n  }\n  return beams;\n}\n\n/**\n * Runs a single step of the text generation process for a given beam.\n *\n * @param {Object} self The decoder object.\n * @param {Object} beam The beam to run.\n * @param {Tensor} beam.input The input tensor.\n * @param {Tensor} beam.model_input_ids The input ids to the model.\n * @param {Tensor} beam.attention_mask The attention mask.\n * @param {Object} beam.past_key_values The past key values.\n * @param {number[]} beam.output_token_ids The output token ids.\n * @returns {Promise<Object>} The output of the generation step.\n * @private\n */\nasync function decoderRunBeam(self, beam) {\n  let attnMaskData = new BigInt64Array(beam.input.data.length + beam.output_token_ids.length).fill(1n);\n\n  // 1. Prepare\n  let model_inputs = {\n    input_ids: beam.model_input_ids,\n    attention_mask: new Tensor('int64', attnMaskData, [1, attnMaskData.length]),\n    past_key_values: beam.past_key_values\n  };\n\n  // 2. Run\n  let output = await self.forward(model_inputs);\n\n  // 3. Update\n  beam.past_key_values = output.past_key_values;\n  return output;\n}\n\n/**\n * Update a beam with a new token ID.\n * @param {Object} beam The beam to update.\n * @param {number} newTokenId The new token ID to add to the beam's output.\n * @private\n */\nfunction decoderUpdatebeam(beam, newTokenId) {\n  beam.output_token_ids = [...beam.output_token_ids, newTokenId];\n  beam.model_input_ids = new Tensor('int64', [BigInt(newTokenId)], [1, 1]);\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n/**\n * A base class for pre-trained models that provides the model configuration and an ONNX session.\n * @extends Callable\n */\nexport class PreTrainedModel extends Callable {\n  /**\n   * Creates a new instance of the `PreTrainedModel` class.\n   * @param {Object} config The model configuration.\n   * @param {any} session session for the model.\n   */\n  constructor(config, session) {\n    super();\n    this.config = config;\n    this.session = session;\n  }\n\n  /**\n  * Disposes of all the ONNX sessions that were created during inference.\n  * @returns {Promise<unknown[]>} An array of promises, one for each ONNX session that is being disposed.\n  * @todo Use https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/FinalizationRegistry\n  */\n  async dispose() {\n    let promises = [];\n    for (let key of Object.keys(this)) {\n      let item = this[key];\n      if (item instanceof InferenceSession) {\n        promises.push(item.handler.dispose());\n      }\n    }\n    return await Promise.all(promises);\n  }\n\n  /**\n   * Instantiate one of the model classes of the library from a pretrained model.\n   * \n   * The model class to instantiate is selected based on the `model_type` property of the config object\n   * (either passed as an argument or loaded from `pretrained_model_name_or_path` if possible)\n   * \n   * @param {string} pretrained_model_name_or_path The name or path of the pretrained model. Can be either:\n   * - A string, the *model id* of a pretrained model hosted inside a model repo on huggingface.co.\n   *   Valid model ids can be located at the root-level, like `bert-base-uncased`, or namespaced under a\n   *   user or organization name, like `dbmdz/bert-base-german-cased`.\n   * - A path to a *directory* containing model weights, e.g., `./my_model_directory/`.\n   * @param {PretrainedOptions} options Additional options for loading the model.\n   * \n   * @returns {Promise<PreTrainedModel>} A new instance of the `PreTrainedModel` class.\n   */\n  static async from_pretrained(pretrained_model_name_or_path) {\n    let {\n      quantized = true,\n      progress_callback = null,\n      config = null,\n      cache_dir = null,\n      local_files_only = false,\n      revision = 'main'\n    } = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    let options = {\n      quantized,\n      progress_callback,\n      config,\n      cache_dir,\n      local_files_only,\n      revision\n    };\n    let modelType = MODEL_TYPE_MAPPING.get(this.name);\n    let info;\n    if (modelType === DecoderOnlyModelType) {\n      info = await Promise.all([AutoConfig.from_pretrained(pretrained_model_name_or_path, options), constructSession(pretrained_model_name_or_path, 'decoder_model_merged', options)]);\n    } else if (modelType === Seq2SeqModelType) {\n      info = await Promise.all([AutoConfig.from_pretrained(pretrained_model_name_or_path, options), constructSession(pretrained_model_name_or_path, 'encoder_model', options), constructSession(pretrained_model_name_or_path, 'decoder_model_merged', options), getModelJSON(pretrained_model_name_or_path, 'generation_config.json', false, options)]);\n    } else if (modelType === EncoderDecoderModelType) {\n      info = await Promise.all([AutoConfig.from_pretrained(pretrained_model_name_or_path, options), constructSession(pretrained_model_name_or_path, 'encoder_model', options), constructSession(pretrained_model_name_or_path, 'decoder_model_merged', options)]);\n    } else if (modelType === EncoderOnlyModelType) {\n      info = await Promise.all([AutoConfig.from_pretrained(pretrained_model_name_or_path, options), constructSession(pretrained_model_name_or_path, 'model', options)]);\n    } else {\n      console.warn('Malformed class definition.', this);\n      throw Error(`Unable to load model: ${pretrained_model_name_or_path}. Please report this bug at https://github.com/xenova/transformers.js/issues/new/choose.`);\n    }\n\n    // @ts-ignore\n    return new this(...info);\n  }\n\n  /**\n   * Runs the model with the provided inputs\n   * @param {Object} model_inputs Object containing input tensors\n   * @returns {Promise<Object>} Object containing output tensors\n   */\n  async _call(model_inputs) {\n    return await this.forward(model_inputs);\n  }\n\n  /**\n   * Forward method for a pretrained model. If not overridden by a subclass, the correct forward method\n   * will be chosen based on the model type.\n   * @param {Object} model_inputs The input data to the model in the format specified in the ONNX model.\n   * @returns {Promise<Object>} The output data from the model in the format specified in the ONNX model.\n   * @throws {Error} This method must be implemented in subclasses.\n   */\n  async forward(model_inputs) {\n    return await forward(this, model_inputs);\n  }\n\n  /**\n   * @param {GenerationConfig} generation_config \n   * @param {number} input_ids_seq_length The starting sequence length for the input ids.\n   * @returns {LogitsProcessorList}\n   */\n  _get_logits_processor(generation_config, input_ids_seq_length) {\n    let logits_processor = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;\n    const processors = new LogitsProcessorList();\n\n    // if (generation_config.diversity_penalty !== null && generation_config.diversity_penalty > 0.0) {\n    //     processors.push(new HammingDiversityLogitsProcessor(\n    //         generation_config.diversity_penalty,\n    //         generation_config.num_beams,\n    //         generation_config.num_beam_groups\n    //     ));\n    // }\n\n    // if (generation_config.encoder_repetition_penalty !== null && generation_config.encoder_repetition_penalty !== 1.0) {\n    //     processors.push(new EncoderRepetitionPenaltyLogitsProcessor(\n    //         generation_config.encoder_repetition_penalty,\n    //         encoder_input_ids\n    //     ));\n    // }\n\n    if (generation_config.repetition_penalty !== null && generation_config.repetition_penalty !== 1.0) {\n      processors.push(new RepetitionPenaltyLogitsProcessor(generation_config.repetition_penalty));\n    }\n    if (generation_config.no_repeat_ngram_size !== null && generation_config.no_repeat_ngram_size > 0) {\n      processors.push(new NoRepeatNGramLogitsProcessor(generation_config.no_repeat_ngram_size));\n    }\n\n    // if (generation_config.encoder_no_repeat_ngram_size !== null && generation_config.encoder_no_repeat_ngram_size > 0) {\n    //     if (this.config.is_encoder_decoder) {\n    //         processors.push(new EncoderNoRepeatNGramLogitsProcessor(\n    //             generation_config.encoder_no_repeat_ngram_size,\n    //             encoder_input_ids\n    //         ));\n    //     } else {\n    //         throw new Error(\"It's impossible to use `encoder_no_repeat_ngram_size` with decoder-only architecture\");\n    //     }\n    // }\n\n    // if (generation_config.bad_words_ids !== null) {\n    //     processors.push(new NoBadWordsLogitsProcessor(generation_config.bad_words_ids, generation_config.eos_token_id));\n    // }\n\n    // if (generation_config.min_length !== null && generation_config.eos_token_id !== null && generation_config.min_length > 0) {\n    //     processors.push(new MinLengthLogitsProcessor(generation_config.min_length, generation_config.eos_token_id));\n    // }\n\n    // if (generation_config.min_new_tokens !== null && generation_config.eos_token_id !== null && generation_config.min_new_tokens > 0) {\n    //     processors.push(new MinNewTokensLengthLogitsProcessor(\n    //         input_ids_seq_length,\n    //         generation_config.min_new_tokens,\n    //         generation_config.eos_token_id\n    //     ));\n    // }\n\n    // if (prefix_allowed_tokens_fn !== null) {\n    //     processors.push(new PrefixConstrainedLogitsProcessor(\n    //         prefix_allowed_tokens_fn,\n    //         generation_config.num_beams / generation_config.num_beam_groups\n    //     ));\n    // }\n\n    if (generation_config.forced_bos_token_id !== null) {\n      processors.push(new ForcedBOSTokenLogitsProcessor(generation_config.forced_bos_token_id));\n    }\n    if (generation_config.forced_eos_token_id !== null) {\n      processors.push(new ForcedEOSTokenLogitsProcessor(generation_config.max_length, generation_config.forced_eos_token_id));\n    }\n\n    // if (generation_config.remove_invalid_values === true) {\n    //     processors.push(new InfNanRemoveLogitsProcessor());\n    // }\n\n    // if (generation_config.exponential_decay_length_penalty !== null) {\n    //     processors.push(new ExponentialDecayLengthPenalty(\n    //         generation_config.exponential_decay_length_penalty,\n    //         generation_config.eos_token_id,\n    //         input_ids_seq_length\n    //     ));\n    // }\n\n    // if (generation_config.suppress_tokens !== null) {\n    //     processors.push(new SuppressTokensLogitsProcessor(generation_config.suppress_tokens));\n    // }\n\n    if (generation_config.begin_suppress_tokens !== null) {\n      let begin_index = input_ids_seq_length > 1 || generation_config.forced_bos_token_id === null ? input_ids_seq_length : input_ids_seq_length + 1;\n      if (generation_config.forced_decoder_ids !== null) {\n        // generation starts after the last token that is forced\n        begin_index += generation_config.forced_decoder_ids[generation_config.forced_decoder_ids.length - 1][0];\n      }\n      processors.push(new SuppressTokensAtBeginLogitsProcessor(generation_config.begin_suppress_tokens, begin_index));\n    }\n    if (generation_config.forced_decoder_ids !== null) {\n      processors.push(new ForceTokensLogitsProcessor(generation_config.forced_decoder_ids));\n    }\n    if (logits_processor !== null) {\n      processors.extend(logits_processor);\n    }\n\n    // `LogitNormalization` should always be the last logit processor, when present\n    // if (generation_config.renormalize_logits === true) {\n    //     processors.push(new LogitNormalization());\n    // }\n\n    return processors;\n  }\n\n  /**\n  * This function merges multiple generation configs together to form a final generation config to be used by the model for text generation.\n  * It first creates an empty `GenerationConfig` object, then it applies the model's own `generation_config` property to it. Finally, if a `generation_config` object was passed in the arguments, it overwrites the corresponding properties in the final config with those of the passed config object.\n  *\n  * @param {GenerationConfig} generation_config A `GenerationConfig` object containing generation parameters.\n  * @returns {GenerationConfig} The final generation config object to be used by the model for text generation.\n  */\n  _get_generation_config(generation_config) {\n    // Create empty generation config (contains defaults)\n    let gen_config = new GenerationConfig();\n\n    // Apply model's generation config, if it exists\n    if ('generation_config' in this) {\n      Object.assign(gen_config, this.generation_config);\n    }\n\n    // Finally, use any generation config specified by the user\n    // when calling `generate`\n    if (generation_config !== null) {\n      Object.assign(gen_config, generation_config);\n    }\n    return gen_config;\n  }\n\n  /**\n   * @typedef {import('./utils/maths.js').TypedArray} TypedArray\n   */\n\n  /**\n   * Generates text based on the given inputs and generation configuration using the model.\n   * @param {Tensor|Array|TypedArray} inputs An array of input token IDs.\n   * @param {Object|null} generation_config The generation configuration to use. If null, default configuration will be used.\n   * @param {Object|null} logits_processor An optional logits processor to use. If null, a new LogitsProcessorList instance will be created.\n   * @param {Object} options options\n   * @param {Object} [options.inputs_attention_mask=null] An optional attention mask for the inputs.\n   * @returns {Promise<number[][]>} An array of generated output sequences, where each sequence is an array of token IDs.\n   * @throws {Error} Throws an error if the inputs array is empty.\n   */\n  async generate(inputs) {\n    let generation_config = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;\n    let logits_processor = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;\n    let {\n      inputs_attention_mask = null\n    } = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : {};\n    if (!(inputs instanceof Tensor) && !isTypedArray(inputs) && !Array.isArray(inputs)) {\n      throw Error(`\\`inputs\\` must be a Tensor, TypedArray, or Array, but is \"${inputs.constructor.name}\".`);\n    }\n    let input_ids_seq_length;\n\n    // Prepare `input_ids` which will be used for auto-regressive generation\n    // TODO: Update to align with HF transformers' implementation\n    if (this.config.is_encoder_decoder) {\n      // Generating from the encoder outputs\n      input_ids_seq_length = 0;\n    } else {\n      input_ids_seq_length = inputs instanceof Tensor ? inputs.dims[0] : inputs.length;\n\n      // decoder-only\n      if (input_ids_seq_length === 0) {\n        throw Error(\"Must supply a non-empty array of input token ids.\");\n      }\n    }\n\n    // Update generation config with defaults\n    generation_config = this._get_generation_config(generation_config);\n    logits_processor = logits_processor ?? new LogitsProcessorList();\n\n    // Update logits processor\n    logits_processor = this._get_logits_processor(generation_config, input_ids_seq_length, logits_processor);\n\n    // TODO implement early_stopping\n    // https://huggingface.co/blog/how-to-generate\n\n    let numOutputTokens = 1;\n    const maxOutputTokens = numOutputTokens + (generation_config.max_new_tokens ?? Infinity);\n\n    // Only use max length if max_new_tokens is not provided\n    const useMaxLength = Number.isInteger(generation_config.max_length) && (generation_config.max_new_tokens ?? null) === null;\n    let sampler = Sampler.getSampler(generation_config);\n\n    // @ts-ignore\n    let beams = this.getStartBeams(inputs, numOutputTokens, inputs_attention_mask);\n    while (beams.some(x => !x.done) && numOutputTokens < maxOutputTokens) {\n      let newest_beams = [];\n      for (let beam of beams) {\n        if (beam.done) {\n          // Add this beam back into the pool\n          newest_beams.push(beam);\n          continue;\n        }\n        if (useMaxLength && beam.output_token_ids.length >= generation_config.max_length) {\n          // Set this beam to done and add it back into the pool\n          beam.done = true;\n          newest_beams.push(beam);\n          continue;\n        }\n\n        // @ts-ignore\n        let output = await this.runBeam(beam);\n\n        // Logits are of the form [batch_size, out_seq_length, vocab_size]\n        // In most cases, this will be [batch_size, 1, vocab_size]\n        // So, we select the last token's logits:\n        // (equivalent to `logits = outputs.logits[:, -1, :]`)\n        let logits = output.logits.slice(null, -1, null);\n\n        // Apply logits processor\n        logits_processor(beam.output_token_ids, logits);\n        let sampledTokens = sampler(logits);\n        for (let [newTokenId, logProb] of sampledTokens) {\n          // use previous beam as a starting point\n          let newBeam = {\n            ...beam\n          };\n\n          // update new beam\n          // @ts-ignore\n          this.updateBeam(newBeam, newTokenId);\n          newBeam.score += logProb;\n          if (newTokenId === this.config.eos_token_id) {\n            newBeam.done = true;\n          }\n          newest_beams.push(newBeam);\n        }\n      }\n      ++numOutputTokens;\n\n      // Next, we get the best beams, per ID\n      newest_beams = this.groupBeams(newest_beams).map(group => group.sort((a, b) => b.score - a.score) // sort by score\n      .slice(0, generation_config.num_beams) // remove outside beam width\n      );\n\n      // Flatten beams\n      beams = newest_beams.flat();\n\n      // Run callback\n      if (generation_config.callback_function) {\n        generation_config.callback_function(beams);\n      }\n    }\n\n    // TODO: Ensure that we can return non-batched outputs\n\n    return this.groupBeams(beams).map(batch => {\n      if (generation_config.num_return_sequences > 1) {\n        return batch.slice(0, generation_config.num_return_sequences).map(x => x.output_token_ids);\n      } else {\n        return [batch[0].output_token_ids];\n      }\n    }).flat(); // Flatten across batches (depth=1)\n  }\n\n  /**\n   * Groups an array of beam objects by their ids.\n   *\n   * @param {Array} beams The array of beam objects to group.\n   * @returns {Array} An array of arrays, where each inner array contains beam objects with the same id.\n   */\n  groupBeams(beams) {\n    // Group beams by their ids\n    const groups = Object.create(null);\n    for (const obj of beams) {\n      if (groups[obj.id] === undefined) {\n        groups[obj.id] = [obj];\n      } else {\n        groups[obj.id].push(obj);\n      }\n    }\n    return Object.values(groups);\n  }\n\n  /**\n   * Returns an object containing past key values from the given decoder results object.\n   *\n   * @param {Object} decoderResults The decoder results object.\n   * @param {Object} pastKeyValues The previous past key values.\n   * @returns {Object} An object containing past key values.\n   */\n  getPastKeyValues(decoderResults, pastKeyValues) {\n    const pkvs = Object.create(null);\n    for (const name in decoderResults) {\n      if (name.startsWith('present')) {\n        let newName = name.replace('present', 'past_key_values');\n        if (pastKeyValues !== null && name.includes('encoder')) {\n          // Optimization introduced by optimum to reuse past key values. So, we just replace the constant\n          // outputs with the previous past key values.\n          // https://github.com/huggingface/optimum/blob/0bf2c05fb7e1182b52d21b703cfc95fd9e4ea3dc/optimum/onnxruntime/base.py#L677-L704\n          pkvs[newName] = pastKeyValues[newName];\n        } else {\n          pkvs[newName] = decoderResults[name];\n        }\n      }\n    }\n    return pkvs;\n  }\n\n  /**\n   * Adds past key values to the decoder feeds object. If pastKeyValues is null, creates new tensors for past key values.\n   *\n   * @param {Object} decoderFeeds The decoder feeds object to add past key values to.\n   * @param {Object} pastKeyValues An object containing past key values.\n   * @param {boolean} [hasDecoder=false] Whether the model has a decoder.\n   */\n  addPastKeyValues(decoderFeeds, pastKeyValues) {\n    let hasDecoder = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : false;\n    if (pastKeyValues) {\n      Object.assign(decoderFeeds, pastKeyValues);\n    } else {\n      // TODO support batches (i.e., batch_size > 1)\n      if (hasDecoder) {\n        // @ts-ignore\n        let encoder_dims = [1, this.num_encoder_heads, 0, this.encoder_dim_kv];\n        // @ts-ignore\n        for (let i = 0; i < this.num_encoder_layers; ++i) {\n          decoderFeeds[`past_key_values.${i}.encoder.key`] = new Tensor('float32', [], encoder_dims);\n          decoderFeeds[`past_key_values.${i}.encoder.value`] = new Tensor('float32', [], encoder_dims);\n        }\n\n        // @ts-ignore\n        let decoder_dims = [1, this.num_decoder_heads, 0, this.decoder_dim_kv];\n        // @ts-ignore\n        for (let i = 0; i < this.num_decoder_layers; ++i) {\n          decoderFeeds[`past_key_values.${i}.decoder.key`] = new Tensor('float32', [], decoder_dims);\n          decoderFeeds[`past_key_values.${i}.decoder.value`] = new Tensor('float32', [], decoder_dims);\n        }\n      } else {\n        // @ts-ignore\n        let dims = [1, this.num_heads, 0, this.dim_kv];\n        // @ts-ignore\n        for (let i = 0; i < this.num_layers; ++i) {\n          decoderFeeds[`past_key_values.${i}.key`] = new Tensor('float32', [], dims);\n          decoderFeeds[`past_key_values.${i}.value`] = new Tensor('float32', [], dims);\n        }\n      }\n    }\n  }\n}\n//////////////////////////////////////////////////\n// Base model output class\nexport class ModelOutput {}\n\n/**\n * Base class for model's outputs, with potential hidden states and attentions.\n */\nexport class BaseModelOutput extends ModelOutput {\n  /**\n   * @param {Object} output The output of the model.\n   * @param {Tensor} output.last_hidden_state Sequence of hidden-states at the output of the last layer of the model.\n   * @param {Tensor} [output.hidden_states] Hidden-states of the model at the output of each layer plus the optional initial embedding outputs.\n   * @param {Tensor} [output.attentions] Attentions weights after the attention softmax, used to compute the weighted average in the self-attention heads.\n   */\n  constructor(_ref) {\n    let {\n      last_hidden_state,\n      hidden_states = null,\n      attentions = null\n    } = _ref;\n    super();\n    this.last_hidden_state = last_hidden_state;\n    this.hidden_states = hidden_states;\n    this.attentions = attentions;\n  }\n}\n//////////////////////////////////////////////////\n// Bert models\nexport class BertPreTrainedModel extends PreTrainedModel {}\nexport class BertModel extends BertPreTrainedModel {}\n\n/**\n * BertForMaskedLM is a class representing a BERT model for masked language modeling.\n * @extends BertPreTrainedModel\n */\nexport class BertForMaskedLM extends BertPreTrainedModel {\n  /**\n   * Calls the model on new inputs.\n   *\n   * @param {Object} model_inputs The inputs to the model.\n   * @returns {Promise<MaskedLMOutput>} An object containing the model's output logits for masked language modeling.\n   */\n  async _call(model_inputs) {\n    return new MaskedLMOutput(await super._call(model_inputs));\n  }\n}\n\n/**\n * BertForSequenceClassification is a class representing a BERT model for sequence classification.\n * @extends BertPreTrainedModel\n */\nexport class BertForSequenceClassification extends BertPreTrainedModel {\n  /**\n   * Calls the model on new inputs.\n   *\n   * @param {Object} model_inputs The inputs to the model.\n   * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.\n   */\n  async _call(model_inputs) {\n    return new SequenceClassifierOutput(await super._call(model_inputs));\n  }\n}\n\n/**\n * BertForTokenClassification is a class representing a BERT model for token classification.\n * @extends BertPreTrainedModel\n */\nexport class BertForTokenClassification extends BertPreTrainedModel {\n  /**\n   * Calls the model on new inputs.\n   *\n   * @param {Object} model_inputs The inputs to the model.\n   * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.\n   */\n  async _call(model_inputs) {\n    return new TokenClassifierOutput(await super._call(model_inputs));\n  }\n}\n\n/**\n * BertForQuestionAnswering is a class representing a BERT model for question answering.\n * @extends BertPreTrainedModel\n */\nexport class BertForQuestionAnswering extends BertPreTrainedModel {\n  /**\n   * Calls the model on new inputs.\n   *\n   * @param {Object} model_inputs The inputs to the model.\n   * @returns {Promise<QuestionAnsweringModelOutput>} An object containing the model's output logits for question answering.\n   */\n  async _call(model_inputs) {\n    return new QuestionAnsweringModelOutput(await super._call(model_inputs));\n  }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// DistilBert models\nexport class DistilBertPreTrainedModel extends PreTrainedModel {}\nexport class DistilBertModel extends DistilBertPreTrainedModel {}\n\n/**\n * DistilBertForSequenceClassification is a class representing a DistilBERT model for sequence classification.\n * @extends DistilBertPreTrainedModel\n */\nexport class DistilBertForSequenceClassification extends DistilBertPreTrainedModel {\n  /**\n   * Calls the model on new inputs.\n   *\n   * @param {Object} model_inputs The inputs to the model.\n   * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.\n   */\n  async _call(model_inputs) {\n    return new SequenceClassifierOutput(await super._call(model_inputs));\n  }\n}\n\n/**\n * DistilBertForTokenClassification is a class representing a DistilBERT model for token classification.\n * @extends DistilBertPreTrainedModel\n */\nexport class DistilBertForTokenClassification extends DistilBertPreTrainedModel {\n  /**\n   * Calls the model on new inputs.\n   *\n   * @param {Object} model_inputs The inputs to the model.\n   * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.\n   */\n  async _call(model_inputs) {\n    return new TokenClassifierOutput(await super._call(model_inputs));\n  }\n}\n\n/**\n * DistilBertForQuestionAnswering is a class representing a DistilBERT model for question answering.\n * @extends DistilBertPreTrainedModel\n */\nexport class DistilBertForQuestionAnswering extends DistilBertPreTrainedModel {\n  /**\n   * Calls the model on new inputs.\n   *\n   * @param {Object} model_inputs The inputs to the model.\n   * @returns {Promise<QuestionAnsweringModelOutput>} An object containing the model's output logits for question answering.\n   */\n  async _call(model_inputs) {\n    return new QuestionAnsweringModelOutput(await super._call(model_inputs));\n  }\n}\n\n/**\n * DistilBertForMaskedLM is a class representing a DistilBERT model for masking task.\n * @extends DistilBertPreTrainedModel\n */\nexport class DistilBertForMaskedLM extends DistilBertPreTrainedModel {\n  /**\n   * Calls the model on new inputs.\n   *\n   * @param {Object} model_inputs The inputs to the model.\n   * @returns {Promise<MaskedLMOutput>} returned object\n   */\n  async _call(model_inputs) {\n    return new MaskedLMOutput(await super._call(model_inputs));\n  }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// MobileBert models\nexport class MobileBertPreTrainedModel extends PreTrainedModel {}\nexport class MobileBertModel extends MobileBertPreTrainedModel {}\n\n/**\n * MobileBertForMaskedLM is a class representing a MobileBERT model for masking task.\n * @extends MobileBertPreTrainedModel\n */\nexport class MobileBertForMaskedLM extends MobileBertPreTrainedModel {\n  /**\n   * Calls the model on new inputs.\n   *\n   * @param {Object} model_inputs The inputs to the model.\n   * @returns {Promise<MaskedLMOutput>} returned object\n   */\n  async _call(model_inputs) {\n    return new MaskedLMOutput(await super._call(model_inputs));\n  }\n}\n\n/**\n * @extends MobileBertPreTrainedModel\n */\nexport class MobileBertForSequenceClassification extends MobileBertPreTrainedModel {\n  /**\n   * Calls the model on new inputs.\n   *\n   * @param {Object} model_inputs The inputs to the model.\n   * @returns {Promise<SequenceClassifierOutput>} returned object\n   */\n  async _call(model_inputs) {\n    return new SequenceClassifierOutput(await super._call(model_inputs));\n  }\n}\n\n/**\n * @extends MobileBertPreTrainedModel\n */\nexport class MobileBertForQuestionAnswering extends MobileBertPreTrainedModel {\n  /**\n   * Calls the model on new inputs.\n   *\n   * @param {Object} model_inputs The inputs to the model.\n   * @returns {Promise<QuestionAnsweringModelOutput>} returned object\n   */\n  async _call(model_inputs) {\n    return new QuestionAnsweringModelOutput(await super._call(model_inputs));\n  }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// SqueezeBert models\nexport class SqueezeBertPreTrainedModel extends PreTrainedModel {}\nexport class SqueezeBertModel extends SqueezeBertPreTrainedModel {}\nexport class SqueezeBertForMaskedLM extends SqueezeBertPreTrainedModel {\n  /**\n   * Calls the model on new inputs.\n   *\n   * @param {Object} model_inputs The inputs to the model.\n   * @returns {Promise<MaskedLMOutput>} returned object\n   */\n  async _call(model_inputs) {\n    return new MaskedLMOutput(await super._call(model_inputs));\n  }\n}\nexport class SqueezeBertForSequenceClassification extends SqueezeBertPreTrainedModel {\n  /**\n   * Calls the model on new inputs.\n   *\n   * @param {Object} model_inputs The inputs to the model.\n   * @returns {Promise<SequenceClassifierOutput>} returned object\n   */\n  async _call(model_inputs) {\n    return new SequenceClassifierOutput(await super._call(model_inputs));\n  }\n}\nexport class SqueezeBertForQuestionAnswering extends SqueezeBertPreTrainedModel {\n  /**\n   * Calls the model on new inputs.\n   *\n   * @param {Object} model_inputs The inputs to the model.\n   * @returns {Promise<QuestionAnsweringModelOutput>} returned object\n   */\n  async _call(model_inputs) {\n    return new QuestionAnsweringModelOutput(await super._call(model_inputs));\n  }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// Albert models\nexport class AlbertPreTrainedModel extends PreTrainedModel {}\nexport class AlbertModel extends AlbertPreTrainedModel {}\nexport class AlbertForSequenceClassification extends AlbertPreTrainedModel {\n  /**\n   * Calls the model on new inputs.\n   *\n   * @param {Object} model_inputs The inputs to the model.\n   * @returns {Promise<SequenceClassifierOutput>} returned object\n   */\n  async _call(model_inputs) {\n    return new SequenceClassifierOutput(await super._call(model_inputs));\n  }\n}\nexport class AlbertForQuestionAnswering extends AlbertPreTrainedModel {\n  /**\n   * Calls the model on new inputs.\n   *\n   * @param {Object} model_inputs The inputs to the model.\n   * @returns {Promise<QuestionAnsweringModelOutput>} returned object\n   */\n  async _call(model_inputs) {\n    return new QuestionAnsweringModelOutput(await super._call(model_inputs));\n  }\n}\nexport class AlbertForMaskedLM extends AlbertPreTrainedModel {\n  /**\n   * Calls the model on new inputs.\n   *\n   * @param {Object} model_inputs The inputs to the model.\n   * @returns {Promise<MaskedLMOutput>} returned object\n   */\n  async _call(model_inputs) {\n    return new MaskedLMOutput(await super._call(model_inputs));\n  }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// T5 models\nexport class T5PreTrainedModel extends PreTrainedModel {}\n;\nexport class T5Model extends T5PreTrainedModel {\n  /**\n   * Generates text based on the provided arguments.\n   * @throws {Error} Throws an error as the current model class (T5Model) is not compatible with `.generate()`.\n   * @returns {Promise<any>}\n   * @param {any[]} args\n   */\n  async generate() {\n    throw Error(\"The current model class (T5Model) is not compatible with `.generate()`, as it doesn't have a language model head. Please use one of the following classes instead: {'T5ForConditionalGeneration'}\");\n  }\n}\n\n/**\n * T5Model is a class representing a T5 model for conditional generation.\n * @extends T5PreTrainedModel\n */\nexport class T5ForConditionalGeneration extends T5PreTrainedModel {\n  /**\n   * Creates a new instance of the `T5ForConditionalGeneration` class.\n   * @param {Object} config The model configuration.\n   * @param {any} session session for the model.\n   * @param {any} decoder_merged_session session for the decoder.\n   * @param {GenerationConfig} generation_config The generation configuration.\n   */\n  constructor(config, session, decoder_merged_session, generation_config) {\n    super(config, session);\n    this.decoder_merged_session = decoder_merged_session;\n    this.generation_config = generation_config;\n    this.num_decoder_layers = this.config.num_decoder_layers;\n    this.num_decoder_heads = this.config.num_heads;\n    this.decoder_dim_kv = this.config.d_kv;\n    this.num_encoder_layers = this.config.num_layers;\n    this.num_encoder_heads = this.config.num_heads;\n    this.encoder_dim_kv = this.config.d_kv;\n  }\n\n  /**\n   * Generates the start beams for a given set of inputs and output length.\n   * @param {number[][]} inputs The input token IDs.\n   * @param {number} numOutputTokens The desired output length.\n   * @returns {Array} The start beams.\n   */\n  getStartBeams(inputs, numOutputTokens) {\n    return seq2seqStartBeams(this, inputs, numOutputTokens);\n  }\n\n  /**\n   * Runs a single step of the beam search generation algorithm.\n   * @param {any} beam The current beam being generated.\n   * @returns {Promise<any>} The updated beam after a single generation step.\n   */\n  async runBeam(beam) {\n    return await seq2seqRunBeam(this, beam);\n  }\n\n  /**\n   * Updates the given beam with a new token ID.\n   * @param {any} beam The current beam.\n   * @param {number} newTokenId The new token ID to add to the output sequence.\n   */\n  updateBeam(beam, newTokenId) {\n    beam.output_token_ids = [...beam.output_token_ids, newTokenId];\n  }\n\n  /**\n   * Runs the forward pass of the model for a given set of inputs.\n   * @param {Object} model_inputs The model inputs.\n   * @returns {Promise<Object>} The model output.\n   */\n  async forward(model_inputs) {\n    return await seq2seqForward(this, model_inputs);\n  }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// MT5 models\nexport class MT5PreTrainedModel extends PreTrainedModel {}\n;\nexport class MT5Model extends MT5PreTrainedModel {\n  /**\n   * \n   * @param  {...any} args\n   * @returns {Promise<any>}\n   * @throws {Error}\n   */\n  async generate() {\n    throw Error(\"The current model class (MT5Model) is not compatible with `.generate()`, as it doesn't have a language model head. Please use one of the following classes instead: {'MT5ForConditionalGeneration'}\");\n  }\n}\n\n/**\n * A class representing a conditional sequence-to-sequence model based on the MT5 architecture.\n *\n * @extends MT5PreTrainedModel\n */\nexport class MT5ForConditionalGeneration extends MT5PreTrainedModel {\n  /**\n   * Creates a new instance of the `MT5ForConditionalGeneration` class.\n   * @param {any} config The model configuration.\n   * @param {any} session The ONNX session containing the encoder weights.\n   * @param {any} decoder_merged_session The ONNX session containing the merged decoder weights.\n   * @param {GenerationConfig} generation_config The generation configuration.\n   */\n  constructor(config, session, decoder_merged_session, generation_config) {\n    super(config, session);\n    this.decoder_merged_session = decoder_merged_session;\n    this.generation_config = generation_config;\n    this.num_decoder_layers = this.config.num_decoder_layers;\n    this.num_decoder_heads = this.config.num_heads;\n    this.decoder_dim_kv = this.config.d_kv;\n    this.num_encoder_layers = this.config.num_layers;\n    this.num_encoder_heads = this.config.num_heads;\n    this.encoder_dim_kv = this.config.d_kv;\n  }\n\n  /**\n  * Generates the start beams for the given input tokens and output sequence length.\n  *\n  * @param {any[]} inputs The input sequence.\n  * @param {number} numOutputTokens The desired length of the output sequence.\n  * @param {...*} args Additional arguments to pass to the `seq2seqStartBeams` function.\n  * @returns {any[]} An array of `Beam` objects representing the start beams.\n  */\n  getStartBeams(inputs, numOutputTokens) {\n    return seq2seqStartBeams(this, inputs, numOutputTokens);\n  }\n\n  /**\n   * Runs a single step of the beam search generation algorithm.\n   * @param {any} beam The current beam being generated.\n   * @returns {Promise<any>} The updated beam after a single generation step.\n   */\n  async runBeam(beam) {\n    return await seq2seqRunBeam(this, beam);\n  }\n\n  /**\n   * Updates the given beam with the new predicted token.\n   * @param {any} beam The beam to update.\n   * @param {number} newTokenId The index of the predicted token.\n  */\n  updateBeam(beam, newTokenId) {\n    beam.output_token_ids = [...beam.output_token_ids, newTokenId];\n  }\n\n  /**\n  * Runs the forward pass of the model on the given inputs.\n  * @param {any} model_inputs The model inputs.\n  * @returns {Promise<any>} A Promise that resolves to the model outputs.\n  */\n  async forward(model_inputs) {\n    return await seq2seqForward(this, model_inputs);\n  }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// Bart models\nexport class BartPretrainedModel extends PreTrainedModel {}\n;\n\n/**\n * BART encoder and decoder model.\n * \n * @hideconstructor\n * @extends BartPretrainedModel\n */\nexport class BartModel extends BartPretrainedModel {\n  /**\n   * Throws an error because the current model class (BartModel) is not compatible with `.generate()`.\n   * \n   * @throws {Error} The current model class (BartModel) is not compatible with `.generate()`.\n   * @returns {Promise<any>}\n   */\n  async generate() {\n    throw Error(\"The current model class (BartModel) is not compatible with `.generate()`, as it doesn't have a language model head. Please use one of the following classes instead: {'BartForConditionalGeneration'}\");\n  }\n}\n\n/**\n * BART model with a language model head for conditional generation.\n * @extends BartPretrainedModel\n */\nexport class BartForConditionalGeneration extends BartPretrainedModel {\n  /**\n   * Creates a new instance of the `BartForConditionalGeneration` class.\n   * @param {Object} config The configuration object for the Bart model.\n   * @param {Object} session The ONNX session used to execute the model.\n   * @param {Object} decoder_merged_session The ONNX session used to execute the decoder.\n   * @param {Object} generation_config The generation configuration object.\n   */\n  constructor(config, session, decoder_merged_session, generation_config) {\n    super(config, session);\n    this.decoder_merged_session = decoder_merged_session;\n    this.generation_config = generation_config;\n    this.num_decoder_layers = this.config.decoder_layers;\n    this.num_decoder_heads = this.config.decoder_attention_heads;\n    this.decoder_dim_kv = this.config.d_model / this.num_decoder_heads;\n    this.num_encoder_layers = this.config.encoder_layers;\n    this.num_encoder_heads = this.config.encoder_attention_heads;\n    this.encoder_dim_kv = this.config.d_model / this.num_encoder_heads;\n  }\n\n  /**\n   * Returns the initial beam for generating output text.\n   * @param {Object} inputs The input object containing the encoded input text.\n   * @param {number} numOutputTokens The maximum number of output tokens to generate.\n   * @param  {...any} args Additional arguments to pass to the sequence-to-sequence generation function.\n   * @returns {any} The initial beam for generating output text.\n   */\n  getStartBeams(inputs, numOutputTokens) {\n    return seq2seqStartBeams(this, inputs, numOutputTokens);\n  }\n\n  /**\n   * Runs a single step of the beam search generation algorithm.\n   * @param {any} beam The current beam being generated.\n   * @returns {Promise<any>} The updated beam after a single generation step.\n   */\n  async runBeam(beam) {\n    return await seq2seqRunBeam(this, beam);\n  }\n\n  /**\n   * Updates the beam by appending the newly generated token ID to the list of output token IDs.\n   * @param {any} beam The current beam being generated.\n   * @param {number} newTokenId The ID of the newly generated token to append to the list of output token IDs.\n   */\n  updateBeam(beam, newTokenId) {\n    beam.output_token_ids = [...beam.output_token_ids, newTokenId];\n  }\n\n  /**\n   * Runs the forward pass of the model for a given set of inputs.\n   * @param {Object} model_inputs The model inputs.\n   * @returns {Promise<Object>} The model output.\n   */\n  async forward(model_inputs) {\n    return await seq2seqForward(this, model_inputs);\n  }\n}\nexport class BartForSequenceClassification extends BartPretrainedModel {\n  /**\n   * Calls the model on new inputs.\n   *\n   * @param {Object} model_inputs The inputs to the model.\n   * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.\n   */\n  async _call(model_inputs) {\n    return new SequenceClassifierOutput(await super._call(model_inputs));\n  }\n}\n\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// Roberta models\nexport class RobertaPreTrainedModel extends PreTrainedModel {}\nexport class RobertaModel extends RobertaPreTrainedModel {}\n\n/**\n * RobertaForMaskedLM class for performing masked language modeling on Roberta models.\n * @extends RobertaPreTrainedModel\n */\nexport class RobertaForMaskedLM extends RobertaPreTrainedModel {\n  /**\n   * Calls the model on new inputs.\n   *\n   * @param {Object} model_inputs The inputs to the model.\n   * @returns {Promise<MaskedLMOutput>} returned object\n   */\n  async _call(model_inputs) {\n    return new MaskedLMOutput(await super._call(model_inputs));\n  }\n}\n\n/**\n * RobertaForSequenceClassification class for performing sequence classification on Roberta models.\n * @extends RobertaPreTrainedModel\n */\nexport class RobertaForSequenceClassification extends RobertaPreTrainedModel {\n  /**\n   * Calls the model on new inputs.\n   *\n   * @param {Object} model_inputs The inputs to the model.\n   * @returns {Promise<SequenceClassifierOutput>} returned object\n   */\n  async _call(model_inputs) {\n    return new SequenceClassifierOutput(await super._call(model_inputs));\n  }\n}\n\n/**\n * RobertaForQuestionAnswering class for performing question answering on Roberta models.\n * @extends RobertaPreTrainedModel\n */\nexport class RobertaForQuestionAnswering extends RobertaPreTrainedModel {\n  /**\n   * Calls the model on new inputs.\n   *\n   * @param {Object} model_inputs The inputs to the model.\n   * @returns {Promise<QuestionAnsweringModelOutput>} returned object\n   */\n  async _call(model_inputs) {\n    return new QuestionAnsweringModelOutput(await super._call(model_inputs));\n  }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// T5 models\nexport class WhisperPreTrainedModel extends PreTrainedModel {}\n;\n\n/**\n * WhisperModel class for training Whisper models without a language model head.\n * @extends WhisperPreTrainedModel\n */\nexport class WhisperModel extends WhisperPreTrainedModel {\n  /**\n   * Throws an error when attempting to generate output since this model doesn't have a language model head.\n   * @throws Error\n   * @returns {Promise<any>}\n   * @param {any[]} args\n   */\n  async generate() {\n    throw Error(\"The current model class (WhisperModel) is not compatible with `.generate()`, as it doesn't have a language model head. Please use one of the following classes instead: {'WhisperForConditionalGeneration'}\");\n  }\n}\n\n/**\n * WhisperForConditionalGeneration class for generating conditional outputs from Whisper models.\n * @extends WhisperPreTrainedModel\n */\nexport class WhisperForConditionalGeneration extends WhisperPreTrainedModel {\n  /**\n   * Creates a new instance of the `WhisperForConditionalGeneration` class.\n   * @param {Object} config Configuration object for the model.\n   * @param {Object} session ONNX Session object for the model.\n   * @param {Object} decoder_merged_session ONNX Session object for the decoder.\n   * @param {Object} generation_config Configuration object for the generation process.\n   */\n  constructor(config, session, decoder_merged_session, generation_config) {\n    super(config, session);\n    this.decoder_merged_session = decoder_merged_session;\n    this.generation_config = generation_config;\n    this.num_decoder_layers = this.config.decoder_layers;\n    this.num_decoder_heads = this.config.decoder_attention_heads;\n    this.decoder_dim_kv = this.config.d_model / this.num_decoder_heads;\n    this.num_encoder_layers = this.config.encoder_layers;\n    this.num_encoder_heads = this.config.encoder_attention_heads;\n    this.encoder_dim_kv = this.config.d_model / this.num_encoder_heads;\n  }\n\n  /**\n   * Generates outputs based on input and generation configuration.\n   * @param {Object} inputs Input data for the model.\n   * @param {Object} generation_config Configuration object for the generation process.\n   * @param {Object} logits_processor Optional logits processor object.\n   * @returns {Promise<Object>} Promise object represents the generated outputs.\n   */\n  async generate(inputs) {\n    let generation_config = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;\n    let logits_processor = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;\n    // Create generation config object\n    generation_config = this._get_generation_config(generation_config);\n\n    // Whisper has additional options for returning timestamps\n    generation_config.return_timestamps ??= false;\n\n    // TODO add language and task\n\n    if (generation_config.return_timestamps) {\n      logits_processor = [new WhisperTimeStampLogitsProcessor(generation_config)];\n    }\n    return super.generate(inputs, generation_config, logits_processor);\n  }\n\n  /**\n   * Gets the start beams for generating outputs.\n   * @param {Array} inputTokenIds Array of input token IDs.\n   * @param {number} numOutputTokens Number of output tokens to generate.\n   * @returns {Array} Array of start beams.\n   */\n  getStartBeams(inputTokenIds, numOutputTokens) {\n    // arguments ignored in this case\n    return seq2seqStartBeams(this, inputTokenIds, numOutputTokens, false);\n  }\n\n  /**\n   * Runs a single step of the beam search generation algorithm.\n   * @param {any} beam The current beam being generated.\n   * @returns {Promise<any>} The updated beam after a single generation step.\n   */\n  async runBeam(beam) {\n    return await seq2seqRunBeam(this, beam, {\n      input_name: 'input_features'\n    });\n  }\n\n  /**\n   * Updates the beam by appending the newly generated token ID to the list of output token IDs.\n   * @param {any} beam The current beam being generated.\n   * @param {number} newTokenId The ID of the newly generated token to append to the list of output token IDs.\n   */\n  updateBeam(beam, newTokenId) {\n    beam.output_token_ids = [...beam.output_token_ids, newTokenId];\n  }\n\n  /**\n   * Runs the forward pass of the model for a given set of inputs.\n   * @param {Object} model_inputs The model inputs.\n   * @returns {Promise<Object>} The model output.\n   */\n  async forward(model_inputs) {\n    return await seq2seqForward(this, model_inputs);\n  }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n/**\n * Vision Encoder-Decoder model based on OpenAI's GPT architecture for image captioning and other vision tasks\n * @extends PreTrainedModel\n */\nexport class VisionEncoderDecoderModel extends PreTrainedModel {\n  /**\n   * Creates a new instance of the `VisionEncoderDecoderModel` class.\n   * @param {Object} config The configuration object specifying the hyperparameters and other model settings.\n   * @param {Object} session The ONNX session containing the encoder model.\n   * @param {any} decoder_merged_session The ONNX session containing the merged decoder model.\n   */\n  constructor(config, session, decoder_merged_session) {\n    super(config, session);\n    this.decoder_merged_session = decoder_merged_session;\n    this.num_layers = this.config.decoder.n_layer;\n    this.num_heads = this.config.decoder.n_head;\n    this.dim_kv = this.config.decoder.n_embd / this.num_heads;\n  }\n\n  /**\n   * Generate beam search outputs for the given input pixels and number of output tokens.\n   *\n   * @param {array} inputs The input pixels as a Tensor.\n   * @param {number} numOutputTokens The number of output tokens to generate.\n   * @param {...*} args Optional additional arguments to pass to seq2seqStartBeams.\n   * @returns {any} An array of Beam objects representing the top-K output sequences.\n   */\n  getStartBeams(inputs, numOutputTokens) {\n    return seq2seqStartBeams(this, inputs, numOutputTokens);\n  }\n\n  /**\n   * Runs a single step of the beam search generation algorithm.\n   * @param {any} beam The current beam being generated.\n   * @returns {Promise<any>} The updated beam after a single generation step.\n   */\n  async runBeam(beam) {\n    return seq2seqRunBeam(this, beam, {\n      input_name: 'pixel_values'\n    });\n  }\n\n  /**\n   * Update the given beam with the additional predicted token ID.\n   *\n   * @param {any} beam The current beam.\n   * @param {number} newTokenId The new predicted token ID to add to the beam's output sequence.\n   */\n  updateBeam(beam, newTokenId) {\n    beam.output_token_ids = [...beam.output_token_ids, newTokenId];\n  }\n\n  /**\n   * Compute the forward pass of the model on the given input tensors.\n   *\n   * @param {Object} model_inputs The input tensors as an object with keys 'pixel_values' and 'decoder_input_ids'.\n   * @returns {Promise<any>} The output tensor of the model.\n   */\n  async forward(model_inputs) {\n    return await seq2seqForward(this, model_inputs, {\n      add_decoder_pkv: false\n    });\n  }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// CLIP models\nexport class CLIPPreTrainedModel extends PreTrainedModel {}\nexport class CLIPModel extends CLIPPreTrainedModel {}\n\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// GPT2 models\nexport class GPT2PreTrainedModel extends PreTrainedModel {\n  /**\n   * Creates a new instance of the `GPT2PreTrainedModel` class.\n   * @param {Object} config The configuration of the model.\n   * @param {any} session The ONNX session containing the model weights.\n   */\n  constructor(config, session) {\n    super(config, session);\n\n    // config doesn't contain pad_token_id, so we assume it is the eos_token_id\n    this.config.pad_token_id = this.config.eos_token_id;\n    this.num_heads = this.config.n_head;\n    this.num_layers = this.config.n_layer;\n    this.dim_kv = this.config.n_embd / this.num_heads;\n  }\n}\nexport class GPT2Model extends GPT2PreTrainedModel {\n  /**\n   * GPT2Model is not compatible with `.generate()`, as it doesn't have a language model head.\n   * @param  {...any} args \n   * @throws {Error}\n   * @returns {Promise<any>}\n   */\n  async generate() {\n    throw Error(\"The current model class (GPT2Model) is not compatible with `.generate()`, as it doesn't have a language model head. Please use one of the following classes instead: {'GPT2LMHeadModel'}\");\n  }\n}\n\n/**\n * GPT-2 language model head on top of the GPT-2 base model. This model is suitable for text generation tasks.\n * @extends GPT2PreTrainedModel\n */\nexport class GPT2LMHeadModel extends GPT2PreTrainedModel {\n  /**\n   * Initializes and returns the beam for text generation task\n   * @param {Tensor} inputTokenIds The input token ids.\n   * @param {number} numOutputTokens The number of tokens to be generated.\n   * @param {Tensor} inputs_attention_mask Optional input attention mask.\n   * @returns {any} A Beam object representing the initialized beam.\n   */\n  getStartBeams(inputTokenIds, numOutputTokens, inputs_attention_mask) {\n    return decoderStartBeams(this, inputTokenIds, numOutputTokens, inputs_attention_mask);\n  }\n\n  /**\n   * Runs a single step of the beam search generation algorithm.\n   * @param {any} beam The current beam being generated.\n   * @returns {Promise<any>} The updated beam after a single generation step.\n   */\n  async runBeam(beam) {\n    return await decoderRunBeam(this, beam);\n  }\n\n  /**\n   * Updates the given beam with the new generated token id.\n   * @param {any} beam The Beam object representing the beam.\n   * @param {number} newTokenId The new generated token id to be added to the beam.\n   */\n  updateBeam(beam, newTokenId) {\n    return decoderUpdatebeam(beam, newTokenId);\n  }\n\n  /**\n   * Forward pass for the model.\n   * @param {Object} model_inputs The inputs for the model.\n   * @returns {Promise<any>} The output tensor of the model.\n   */\n  async forward(model_inputs) {\n    return await decoderForward(this, model_inputs);\n  }\n}\n// export class GPT2ForSequenceClassification extends GPT2PreTrainedModel {\n// TODO\n// }\n//////////////////////////////////////////////////\nexport class GPTNeoPreTrainedModel extends PreTrainedModel {\n  /**\n   * Creates a new instance of the `GPTNeoPreTrainedModel` class.\n   * @param {Object} config The configuration of the model.\n   * @param {any} session The ONNX session containing the model weights.\n   */\n  constructor(config, session) {\n    super(config, session);\n\n    // config doesn't contain pad_token_id, so we assume it is the eos_token_id\n    this.config.pad_token_id = this.config.eos_token_id;\n    this.num_heads = this.config.num_heads;\n    this.num_layers = this.config.num_layers;\n    this.dim_kv = this.config.hidden_size / this.num_heads;\n  }\n}\nexport class GPTNeoModel extends GPTNeoPreTrainedModel {\n  /**\n   * \n   * @param  {...any} args \n   * @throws {Error}\n   * @returns {Promise<any>}\n   */\n  async generate() {\n    throw Error(\"The current model class (GPTNeoModel) is not compatible with `.generate()`, as it doesn't have a language model head. Please use one of the following classes instead: {'GPTNeoForCausalLM'}\");\n  }\n}\nexport class GPTNeoForCausalLM extends GPTNeoPreTrainedModel {\n  /**\n   * Initializes and returns the beam for text generation task\n   * @param {Tensor} inputTokenIds The input token ids.\n   * @param {number} numOutputTokens The number of tokens to be generated.\n   * @param {Tensor} inputs_attention_mask Optional input attention mask.\n   * @returns {any} A Beam object representing the initialized beam.\n   */\n  getStartBeams(inputTokenIds, numOutputTokens, inputs_attention_mask) {\n    return decoderStartBeams(this, inputTokenIds, numOutputTokens, inputs_attention_mask);\n  }\n\n  /**\n   * Runs a single step of the beam search generation algorithm.\n   * @param {any} beam The current beam being generated.\n   * @returns {Promise<any>} The updated beam after a single generation step.\n   */\n  async runBeam(beam) {\n    return await decoderRunBeam(this, beam);\n  }\n\n  /**\n   * Updates the given beam with the new generated token id.\n   * @param {any} beam The Beam object representing the beam.\n   * @param {number} newTokenId The new generated token id to be added to the beam.\n   */\n  updateBeam(beam, newTokenId) {\n    return decoderUpdatebeam(beam, newTokenId);\n  }\n\n  /**\n   * Forward pass for the model.\n   * @param {Object} model_inputs The inputs for the model.\n   * @returns {Promise<any>} The output tensor of the model.\n   */\n  async forward(model_inputs) {\n    return await decoderForward(this, model_inputs);\n  }\n}\n\n//////////////////////////////////////////////////\n// CodeGen models\nexport class CodeGenPreTrainedModel extends PreTrainedModel {\n  /**\n   * Creates a new instance of the `CodeGenPreTrainedModel` class.\n  * @param {Object} config The model configuration object.\n  * @param {Object} session The ONNX session object.\n  */\n  constructor(config, session) {\n    super(config, session);\n\n    // config doesn't contain pad_token_id, so we assume it is the eos_token_id\n    this.config.pad_token_id = this.config.eos_token_id;\n    this.num_heads = this.config.n_head;\n    this.num_layers = this.config.n_layer;\n    this.dim_kv = this.config.n_embd / this.num_heads;\n  }\n}\n/**\n * CodeGenModel is a class representing a code generation model without a language model head.\n * \n * @extends CodeGenPreTrainedModel\n */\nexport class CodeGenModel extends CodeGenPreTrainedModel {\n  /**\n   * Throws an error indicating that the current model class is not compatible with `.generate()`,\n   * as it doesn't have a language model head.\n   * \n   * @throws {Error} The current model class is not compatible with `.generate()`\n   * \n   * @param  {...any} args Arguments passed to the generate function\n   * @returns {Promise<any>}\n   */\n  async generate() {\n    throw Error(\"The current model class (CodeGenModel) is not compatible with `.generate()`, as it doesn't have a language model head. Please use one of the following classes instead: {'CodeGenForCausalLM'}\");\n  }\n}\n\n/**\n * CodeGenForCausalLM is a class that represents a code generation model based on the GPT-2 architecture. It extends the `CodeGenPreTrainedModel` class.\n * @extends CodeGenPreTrainedModel\n */\nexport class CodeGenForCausalLM extends CodeGenPreTrainedModel {\n  /**\n   * Initializes and returns the beam for text generation task\n   * @param {Tensor} inputTokenIds The input token ids.\n   * @param {number} numOutputTokens The number of tokens to be generated.\n   * @param {Tensor} inputs_attention_mask Optional input attention mask.\n   * @returns {any} A Beam object representing the initialized beam.\n   */\n  getStartBeams(inputTokenIds, numOutputTokens, inputs_attention_mask) {\n    return decoderStartBeams(this, inputTokenIds, numOutputTokens, inputs_attention_mask);\n  }\n\n  /**\n   * Runs a single step of the beam search generation algorithm.\n   * @param {any} beam The current beam being generated.\n   * @returns {Promise<any>} The updated beam after a single generation step.\n   */\n  async runBeam(beam) {\n    return await decoderRunBeam(this, beam);\n  }\n\n  /**\n   * Updates the given beam with the new generated token id.\n   * @param {any} beam The Beam object representing the beam.\n   * @param {number} newTokenId The new generated token id to be added to the beam.\n   */\n  updateBeam(beam, newTokenId) {\n    return decoderUpdatebeam(beam, newTokenId);\n  }\n\n  /**\n   * Forward pass for the model.\n   * @param {Object} model_inputs The inputs for the model.\n   * @returns {Promise<any>} The output tensor of the model.\n   */\n  async forward(model_inputs) {\n    return await decoderForward(this, model_inputs);\n  }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\nexport class ViTPreTrainedModel extends PreTrainedModel {}\nexport class ViTForImageClassification extends ViTPreTrainedModel {\n  /**\n   * @param {any} model_inputs\n   */\n  async _call(model_inputs) {\n    return new SequenceClassifierOutput(await super._call(model_inputs));\n  }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\nexport class DetrPreTrainedModel extends PreTrainedModel {}\nexport class DetrForObjectDetection extends DetrPreTrainedModel {\n  /**\n   * @param {any} model_inputs\n   */\n  async _call(model_inputs) {\n    return new DetrObjectDetectionOutput(await super._call(model_inputs));\n  }\n}\nexport class DetrForSegmentation extends DetrPreTrainedModel {\n  /**\n   * Runs the model with the provided inputs\n   * @param {Object} model_inputs Model inputs\n   * @returns {Promise<DetrSegmentationOutput>} Object containing segmentation outputs\n   */\n  async _call(model_inputs) {\n    return new DetrSegmentationOutput(await super._call(model_inputs));\n  }\n}\nexport class DetrObjectDetectionOutput extends ModelOutput {\n  /**\n   * @param {Object} output The output of the model.\n   * @param {Tensor} output.logits Classification logits (including no-object) for all queries.\n   * @param {Tensor} output.pred_boxes Normalized boxes coordinates for all queries, represented as (center_x, center_y, width, height).\n   * These values are normalized in [0, 1], relative to the size of each individual image in the batch (disregarding possible padding).\n   */\n  constructor(_ref2) {\n    let {\n      logits,\n      pred_boxes\n    } = _ref2;\n    super();\n    this.logits = logits;\n    this.pred_boxes = pred_boxes;\n  }\n}\nexport class DetrSegmentationOutput extends ModelOutput {\n  /**\n   * @param {Object} output The output of the model.\n   * @param {Tensor} output.logits The output logits of the model.\n   * @param {Tensor} output.pred_boxes Predicted boxes.\n   * @param {Tensor} output.pred_masks Predicted masks.\n   */\n  constructor(_ref3) {\n    let {\n      logits,\n      pred_boxes,\n      pred_masks\n    } = _ref3;\n    super();\n    this.logits = logits;\n    this.pred_boxes = pred_boxes;\n    this.pred_masks = pred_masks;\n  }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\nexport class SamPreTrainedModel extends PreTrainedModel {}\nexport class SamModel extends SamPreTrainedModel {\n  /**\n   * @param {Object} model_inputs\n   * @param {Tensor} model_inputs.pixel_values Pixel values as a Tensor with shape `(batch_size, num_channels, height, width)`.\n   * @param {Tensor} model_inputs.input_points Input 2D spatial points with shape `(batch_size, num_points, 2)`. This is used by the prompt encoder to encode the prompt.\n   * @todo Add support for `input_labels`, `input_boxes`, `input_masks`, and `image_embeddings`.\n   */\n  async _call(model_inputs) {\n    return new SamImageSegmentationOutput(await super._call(model_inputs));\n  }\n}\n\n/**\n * Base class for Segment-Anything model's output.\n */\nexport class SamImageSegmentationOutput extends ModelOutput {\n  /**\n   * @param {Object} output The output of the model.\n   * @param {Tensor} output.iou_scores The output logits of the model.\n   * @param {Tensor} output.pred_masks Predicted boxes.\n   */\n  constructor(_ref4) {\n    let {\n      iou_scores,\n      pred_masks\n    } = _ref4;\n    super();\n    this.iou_scores = iou_scores;\n    this.pred_masks = pred_masks;\n  }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// MarianMT models\nexport class MarianPreTrainedModel extends PreTrainedModel {}\n;\nexport class MarianModel extends MarianPreTrainedModel {\n  /**\n   * \n   * @param  {...any} args \n   * @throws {Error}\n   * @returns {Promise<any>}\n   */\n  async generate() {\n    throw Error(\"The current model class (MarianModel) is not compatible with `.generate()`, as it doesn't have a language model head. Please use one of the following classes instead: {'MarianMTModel'}\");\n  }\n}\nexport class MarianMTModel extends MarianPreTrainedModel {\n  /**\n   * Creates a new instance of the `MarianMTModel` class.\n  * @param {Object} config The model configuration object.\n  * @param {Object} session The ONNX session object.\n  * @param {any} decoder_merged_session \n  * @param {any} generation_config \n  */\n  constructor(config, session, decoder_merged_session, generation_config) {\n    super(config, session);\n    this.decoder_merged_session = decoder_merged_session;\n    this.generation_config = generation_config;\n    this.num_decoder_layers = this.config.decoder_layers;\n    this.num_decoder_heads = this.config.decoder_attention_heads;\n    this.decoder_dim_kv = this.config.d_model / this.num_decoder_heads;\n    this.num_encoder_layers = this.config.encoder_layers;\n    this.num_encoder_heads = this.config.encoder_attention_heads;\n    this.encoder_dim_kv = this.config.d_model / this.num_encoder_heads;\n  }\n\n  /**\n   * Initializes and returns the beam for text generation task\n   * @param {any[]} inputs The input token ids.\n   * @param {number} numOutputTokens The number of tokens to be generated.\n   * @returns {any} A Beam object representing the initialized beam.\n   * @param {any[]} args\n   */\n  getStartBeams(inputs, numOutputTokens) {\n    return seq2seqStartBeams(this, inputs, numOutputTokens);\n  }\n\n  /**\n   * Runs a single step of the beam search generation algorithm.\n   * @param {any} beam The current beam being generated.\n   * @returns {Promise<any>} The updated beam after a single generation step.\n   */\n  async runBeam(beam) {\n    return await seq2seqRunBeam(this, beam);\n  }\n\n  /**\n   * @param {any} beam\n   * @param {any} newTokenId\n   */\n  updateBeam(beam, newTokenId) {\n    beam.output_token_ids = [...beam.output_token_ids, newTokenId];\n  }\n\n  /**\n   * @param {any} model_inputs\n   * @returns {Promise<Seq2SeqLMOutput>}\n   */\n  async forward(model_inputs) {\n    return await seq2seqForward(this, model_inputs);\n  }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// M2M100 models\nexport class M2M100PreTrainedModel extends PreTrainedModel {}\n;\nexport class M2M100Model extends M2M100PreTrainedModel {\n  /**\n   * \n   * @param  {...any} args \n   * @throws {Error}\n   * @returns {Promise<any>}\n   */\n  async generate() {\n    throw Error(\"The current model class (M2M100Model) is not compatible with `.generate()`, as it doesn't have a language model head. Please use one of the following classes instead: {'M2M100ForConditionalGeneration'}\");\n  }\n}\nexport class M2M100ForConditionalGeneration extends M2M100PreTrainedModel {\n  /**\n   * Creates a new instance of the `M2M100ForConditionalGeneration` class.\n  * @param {Object} config The model configuration object.\n  * @param {Object} session The ONNX session object.\n  * @param {any} decoder_merged_session \n  * @param {any} generation_config \n  */\n  constructor(config, session, decoder_merged_session, generation_config) {\n    super(config, session);\n    this.decoder_merged_session = decoder_merged_session;\n    this.generation_config = generation_config;\n    this.num_decoder_layers = this.config.decoder_layers;\n    this.num_decoder_heads = this.config.decoder_attention_heads;\n    this.decoder_dim_kv = this.config.d_model / this.num_decoder_heads;\n    this.num_encoder_layers = this.config.encoder_layers;\n    this.num_encoder_heads = this.config.encoder_attention_heads;\n    this.encoder_dim_kv = this.config.d_model / this.num_encoder_heads;\n  }\n\n  /**\n   * Initializes and returns the beam for text generation task\n   * @param {any[]} inputs The input token ids.\n   * @param {number} numOutputTokens The number of tokens to be generated.\n   * @returns {any} A Beam object representing the initialized beam.\n   * @param {any[]} args\n   */\n  getStartBeams(inputs, numOutputTokens) {\n    return seq2seqStartBeams(this, inputs, numOutputTokens);\n  }\n\n  /**\n   * Runs a single step of the beam search generation algorithm.\n   * @param {any} beam The current beam being generated.\n   * @returns {Promise<any>} The updated beam after a single generation step.\n   */\n  async runBeam(beam) {\n    return await seq2seqRunBeam(this, beam);\n  }\n\n  /**\n   * @param {any} beam\n   * @param {any} newTokenId\n   */\n  updateBeam(beam, newTokenId) {\n    beam.output_token_ids = [...beam.output_token_ids, newTokenId];\n  }\n\n  /**\n   * @param {any} model_inputs\n   * @returns {Promise<Seq2SeqLMOutput>}\n   */\n  async forward(model_inputs) {\n    return await seq2seqForward(this, model_inputs);\n  }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// AutoModels, used to simplify construction of PreTrainedModels\n// (uses config to instantiate correct class)\n\n/**\n * Base class of all AutoModels. Contains the `from_pretrained` function\n * which is used to instantiate pretrained models.\n */\nexport class PretrainedMixin {\n  /**\n   * Mapping from model type to model class.\n   * @type {Map<string, Object>[]}\n   */\n  static MODEL_CLASS_MAPPINGS = null;\n\n  /**\n   * Whether to attempt to instantiate the base class (`PretrainedModel`) if \n   * the model type is not found in the mapping.\n   */\n  static BASE_IF_FAIL = false;\n\n  /** @type {PreTrainedModel.from_pretrained} */\n  static async from_pretrained(pretrained_model_name_or_path) {\n    let {\n      quantized = true,\n      progress_callback = null,\n      config = null,\n      cache_dir = null,\n      local_files_only = false,\n      revision = 'main'\n    } = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    let options = {\n      quantized,\n      progress_callback,\n      config,\n      cache_dir,\n      local_files_only,\n      revision\n    };\n    config = await AutoConfig.from_pretrained(pretrained_model_name_or_path, options);\n    if (!this.MODEL_CLASS_MAPPINGS) {\n      throw new Error(\"`MODEL_CLASS_MAPPINGS` not implemented for this type of `AutoClass`: \" + this.name);\n    }\n    let modelClass;\n    for (let MODEL_CLASS_MAPPING of this.MODEL_CLASS_MAPPINGS) {\n      modelClass = MODEL_CLASS_MAPPING.get(config.model_type);\n      if (!modelClass) {\n        continue; // Item not found in this mapping\n      }\n\n      return await modelClass.from_pretrained(pretrained_model_name_or_path, options);\n    }\n    if (this.BASE_IF_FAIL) {\n      console.warn(`Unknown model class \"${config.model_type}\", attempting to construct from base class.`);\n      return await PreTrainedModel.from_pretrained(pretrained_model_name_or_path, options);\n    } else {\n      throw Error(`Unsupported model type: ${config.model_type}`);\n    }\n  }\n}\nconst MODEL_MAPPING_NAMES_ENCODER_ONLY = new Map([['bert', BertModel], ['albert', AlbertModel], ['distilbert', DistilBertModel], ['roberta', RobertaModel], ['clip', CLIPModel], ['mobilebert', MobileBertModel], ['squeezebert', SqueezeBertModel], ['sam', SamModel] // TODO change to encoder-decoder when model is split correctly\n]);\n\nconst MODEL_MAPPING_NAMES_ENCODER_DECODER = new Map([['t5', T5Model], ['mt5', MT5Model], ['bart', BartModel], ['marian', MarianModel], ['whisper', WhisperModel], ['m2m_100', M2M100Model]]);\nconst MODEL_MAPPING_NAMES_DECODER_ONLY = new Map([['gpt2', GPT2Model], ['gpt_neo', GPTNeoModel], ['codegen', CodeGenModel]]);\nconst MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING_NAMES = new Map([['bert', BertForSequenceClassification], ['albert', AlbertForSequenceClassification], ['distilbert', DistilBertForSequenceClassification], ['roberta', RobertaForSequenceClassification], ['bart', BartForSequenceClassification], ['mobilebert', MobileBertForSequenceClassification], ['squeezebert', SqueezeBertForSequenceClassification]]);\nconst MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING_NAMES = new Map([['bert', BertForTokenClassification], ['distilbert', DistilBertForTokenClassification]]);\nconst MODEL_FOR_SEQ_2_SEQ_MAPPING_NAMES = new Map([['t5', T5ForConditionalGeneration], ['mt5', MT5ForConditionalGeneration], ['bart', BartForConditionalGeneration], ['whisper', WhisperForConditionalGeneration], ['marian', MarianMTModel], ['m2m_100', M2M100ForConditionalGeneration]]);\nconst MODEL_WITH_LM_HEAD_MAPPING_NAMES = new Map([['gpt2', GPT2LMHeadModel], ['gpt_neo', GPTNeoForCausalLM], ['codegen', CodeGenForCausalLM]]);\nconst MODEL_FOR_MASKED_LM_MAPPING_NAMES = new Map([['bert', BertForMaskedLM], ['albert', AlbertForMaskedLM], ['distilbert', DistilBertForMaskedLM], ['roberta', RobertaForMaskedLM], ['mobilebert', MobileBertForMaskedLM], ['squeezebert', SqueezeBertForMaskedLM]]);\nconst MODEL_FOR_QUESTION_ANSWERING_MAPPING_NAMES = new Map([['bert', BertForQuestionAnswering], ['albert', AlbertForQuestionAnswering], ['distilbert', DistilBertForQuestionAnswering], ['roberta', RobertaForQuestionAnswering], ['mobilebert', MobileBertForQuestionAnswering], ['squeezebert', SqueezeBertForQuestionAnswering]]);\nconst MODEL_FOR_VISION_2_SEQ_MAPPING_NAMES = new Map([['vision-encoder-decoder', VisionEncoderDecoderModel]]);\nconst MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING_NAMES = new Map([['vit', ViTForImageClassification]]);\nconst MODEL_FOR_OBJECT_DETECTION_MAPPING_NAMES = new Map([['detr', DetrForObjectDetection]]);\nconst MODEL_FOR_IMAGE_SEGMENTATION_MAPPING_NAMES = new Map([['detr', DetrForSegmentation]]);\nconst MODEL_FOR_MASK_GENERATION_MAPPING_NAMES = new Map([['sam', SamModel]]);\nconst MODEL_CLASS_TYPE_MAPPING = [[MODEL_MAPPING_NAMES_ENCODER_ONLY, EncoderOnlyModelType], [MODEL_MAPPING_NAMES_ENCODER_DECODER, EncoderDecoderModelType], [MODEL_MAPPING_NAMES_DECODER_ONLY, DecoderOnlyModelType], [MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING_NAMES, EncoderOnlyModelType], [MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING_NAMES, EncoderOnlyModelType], [MODEL_FOR_SEQ_2_SEQ_MAPPING_NAMES, Seq2SeqModelType], [MODEL_WITH_LM_HEAD_MAPPING_NAMES, DecoderOnlyModelType], [MODEL_FOR_MASKED_LM_MAPPING_NAMES, EncoderOnlyModelType], [MODEL_FOR_QUESTION_ANSWERING_MAPPING_NAMES, EncoderOnlyModelType], [MODEL_FOR_VISION_2_SEQ_MAPPING_NAMES, EncoderDecoderModelType], [MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING_NAMES, EncoderOnlyModelType], [MODEL_FOR_IMAGE_SEGMENTATION_MAPPING_NAMES, EncoderOnlyModelType], [MODEL_FOR_OBJECT_DETECTION_MAPPING_NAMES, EncoderOnlyModelType], [MODEL_FOR_MASK_GENERATION_MAPPING_NAMES, EncoderOnlyModelType]];\nfor (let [mappings, type] of MODEL_CLASS_TYPE_MAPPING) {\n  // @ts-ignore\n  for (let [name, model] of mappings.entries()) {\n    MODEL_TYPE_MAPPING.set(model.name, type);\n    MODEL_CLASS_MAPPING.set(model.name, name);\n  }\n}\n\n/**\n * Helper class which is used to instantiate pretrained models with the `from_pretrained` function.\n * The chosen model class is determined by the type specified in the model config.\n * \n * @example\n * let model = await AutoModel.from_pretrained('bert-base-uncased');\n */\nexport class AutoModel extends PretrainedMixin {\n  static MODEL_CLASS_MAPPINGS = [MODEL_MAPPING_NAMES_ENCODER_ONLY, MODEL_MAPPING_NAMES_ENCODER_DECODER, MODEL_MAPPING_NAMES_DECODER_ONLY];\n  static BASE_IF_FAIL = true;\n}\n\n/**\n * Helper class which is used to instantiate pretrained sequence classification models with the `from_pretrained` function.\n * The chosen model class is determined by the type specified in the model config.\n * \n * @example\n * let model = await AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased-finetuned-sst-2-english');\n */\nexport class AutoModelForSequenceClassification extends PretrainedMixin {\n  static MODEL_CLASS_MAPPINGS = [MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING_NAMES];\n}\n\n/**\n * Helper class which is used to instantiate pretrained token classification models with the `from_pretrained` function.\n * The chosen model class is determined by the type specified in the model config.\n * \n * @example\n * let model = await AutoModelForTokenClassification.from_pretrained('Davlan/distilbert-base-multilingual-cased-ner-hrl');\n */\nexport class AutoModelForTokenClassification extends PretrainedMixin {\n  static MODEL_CLASS_MAPPINGS = [MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING_NAMES];\n}\n\n/**\n * Helper class which is used to instantiate pretrained sequence-to-sequence models with the `from_pretrained` function.\n * The chosen model class is determined by the type specified in the model config.\n * \n * @example\n * let model = await AutoModelForSeq2SeqLM.from_pretrained('t5-small');\n */\nexport class AutoModelForSeq2SeqLM extends PretrainedMixin {\n  static MODEL_CLASS_MAPPINGS = [MODEL_FOR_SEQ_2_SEQ_MAPPING_NAMES];\n}\n\n/**\n * Helper class which is used to instantiate pretrained causal language models with the `from_pretrained` function.\n * The chosen model class is determined by the type specified in the model config.\n * \n * @example\n * let model = await AutoModelForCausalLM.from_pretrained('gpt2');\n */\nexport class AutoModelForCausalLM extends PretrainedMixin {\n  static MODEL_CLASS_MAPPINGS = [MODEL_WITH_LM_HEAD_MAPPING_NAMES];\n}\n\n/**\n * Helper class which is used to instantiate pretrained masked language models with the `from_pretrained` function.\n * The chosen model class is determined by the type specified in the model config.\n * \n * @example\n * let model = await AutoModelForMaskedLM.from_pretrained('bert-base-uncased');\n */\nexport class AutoModelForMaskedLM extends PretrainedMixin {\n  static MODEL_CLASS_MAPPINGS = [MODEL_FOR_MASKED_LM_MAPPING_NAMES];\n}\n\n/**\n * Helper class which is used to instantiate pretrained question answering models with the `from_pretrained` function.\n * The chosen model class is determined by the type specified in the model config.\n * \n * @example\n * let model = await AutoModelForQuestionAnswering.from_pretrained('distilbert-base-cased-distilled-squad');\n */\nexport class AutoModelForQuestionAnswering extends PretrainedMixin {\n  static MODEL_CLASS_MAPPINGS = [MODEL_FOR_QUESTION_ANSWERING_MAPPING_NAMES];\n}\n\n/**\n * Helper class which is used to instantiate pretrained vision-to-sequence models with the `from_pretrained` function.\n * The chosen model class is determined by the type specified in the model config.\n * \n * @example\n * let model = await AutoModelForVision2Seq.from_pretrained('nlpconnect/vit-gpt2-image-captioning');\n */\nexport class AutoModelForVision2Seq extends PretrainedMixin {\n  static MODEL_CLASS_MAPPINGS = [MODEL_FOR_VISION_2_SEQ_MAPPING_NAMES];\n}\n\n/**\n * Helper class which is used to instantiate pretrained image classification models with the `from_pretrained` function.\n * The chosen model class is determined by the type specified in the model config.\n * \n * @example\n * let model = await AutoModelForImageClassification.from_pretrained('google/vit-base-patch16-224');\n */\nexport class AutoModelForImageClassification extends PretrainedMixin {\n  static MODEL_CLASS_MAPPINGS = [MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING_NAMES];\n}\n\n/**\n * Helper class which is used to instantiate pretrained image segmentation models with the `from_pretrained` function.\n * The chosen model class is determined by the type specified in the model config.\n * \n * @example\n * let model = await AutoModelForImageSegmentation.from_pretrained('facebook/detr-resnet-50-panoptic');\n */\nexport class AutoModelForImageSegmentation extends PretrainedMixin {\n  static MODEL_CLASS_MAPPINGS = [MODEL_FOR_IMAGE_SEGMENTATION_MAPPING_NAMES];\n}\n\n/**\n * Helper class which is used to instantiate pretrained object detection models with the `from_pretrained` function.\n * The chosen model class is determined by the type specified in the model config.\n * \n * @example\n * let model = await AutoModelForObjectDetection.from_pretrained('facebook/detr-resnet-50');\n */\nexport class AutoModelForObjectDetection extends PretrainedMixin {\n  static MODEL_CLASS_MAPPINGS = [MODEL_FOR_OBJECT_DETECTION_MAPPING_NAMES];\n}\n\n/**\n * Helper class which is used to instantiate pretrained object detection models with the `from_pretrained` function.\n * The chosen model class is determined by the type specified in the model config.\n * \n * @example\n * let model = await AutoModelForMaskGeneration.from_pretrained('Xenova/sam-vit-base');\n */\nexport class AutoModelForMaskGeneration extends PretrainedMixin {\n  static MODEL_CLASS_MAPPINGS = [MODEL_FOR_MASK_GENERATION_MAPPING_NAMES];\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\nexport class Seq2SeqLMOutput extends ModelOutput {\n  /**\n   * @param {Object} output The output of the model.\n   * @param {Tensor} output.logits The output logits of the model.\n   * @param {Tensor} output.past_key_values An tensor of key/value pairs that represent the previous state of the model.\n   * @param {Tensor} output.encoder_outputs The output of the encoder in a sequence-to-sequence model.\n   */\n  constructor(_ref5) {\n    let {\n      logits,\n      past_key_values,\n      encoder_outputs\n    } = _ref5;\n    super();\n    this.logits = logits;\n    this.past_key_values = past_key_values;\n    this.encoder_outputs = encoder_outputs;\n  }\n}\n\n/**\n * Base class for outputs of sentence classification models.\n */\nexport class SequenceClassifierOutput extends ModelOutput {\n  /**\n   * @param {Object} output The output of the model.\n   * @param {Tensor} output.logits classification (or regression if config.num_labels==1) scores (before SoftMax).\n   */\n  constructor(_ref6) {\n    let {\n      logits\n    } = _ref6;\n    super();\n    this.logits = logits;\n  }\n}\n\n/**\n * Base class for outputs of token classification models.\n */\nexport class TokenClassifierOutput extends ModelOutput {\n  /**\n   * @param {Object} output The output of the model.\n   * @param {Tensor} output.logits Classification scores (before SoftMax).\n   */\n  constructor(_ref7) {\n    let {\n      logits\n    } = _ref7;\n    super();\n    this.logits = logits;\n  }\n}\n\n/**\n * Base class for masked language models outputs.\n */\nexport class MaskedLMOutput extends ModelOutput {\n  /**\n   * @param {Object} output The output of the model.\n   * @param {Tensor} output.logits Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).\n   */\n  constructor(_ref8) {\n    let {\n      logits\n    } = _ref8;\n    super();\n    this.logits = logits;\n  }\n}\n\n/**\n * Base class for outputs of question answering models.\n */\nexport class QuestionAnsweringModelOutput extends ModelOutput {\n  /**\n   * @param {Object} output The output of the model.\n   * @param {Tensor} output.start_logits Span-start scores (before SoftMax).\n   * @param {Tensor} output.end_logits Span-end scores (before SoftMax).\n   */\n  constructor(_ref9) {\n    let {\n      start_logits,\n      end_logits\n    } = _ref9;\n    super();\n    this.start_logits = start_logits;\n    this.end_logits = end_logits;\n  }\n}\n\n/**\n * Base class for causal language model (or autoregressive) outputs.\n */\nexport class CausalLMOutputWithPast extends ModelOutput {\n  /**\n   * @param {Object} output The output of the model.\n   * @param {Tensor} output.logits Prediction scores of the language modeling head (scores for each vocabulary token before softmax).\n   * @param {Tensor} output.past_key_values Contains pre-computed hidden-states (key and values in the self-attention blocks)\n   * that can be used (see `past_key_values` input) to speed up sequential decoding.\n   */\n  constructor(_ref10) {\n    let {\n      logits,\n      past_key_values\n    } = _ref10;\n    super();\n    this.logits = logits;\n    this.past_key_values = past_key_values;\n  }\n}","map":{"version":3,"names":["AutoConfig","Callable","isIntegralNumber","isTypedArray","getModelFile","getModelJSON","LogitsProcessorList","GenerationConfig","ForceTokensLogitsProcessor","ForcedBOSTokenLogitsProcessor","ForcedEOSTokenLogitsProcessor","SuppressTokensAtBeginLogitsProcessor","WhisperTimeStampLogitsProcessor","NoRepeatNGramLogitsProcessor","RepetitionPenaltyLogitsProcessor","Sampler","Tensor","executionProviders","ONNX","InferenceSession","ONNXTensor","ModelType","EncoderOnlyModelType","EncoderDecoderModelType","Seq2SeqModelType","DecoderOnlyModelType","MODEL_TYPE_MAPPING","Map","MODEL_CLASS_MAPPING","forward","self","model_inputs","get","constructor","name","decoderForward","encoderForward","constructSession","pretrained_model_name_or_path","fileName","options","modelFileName","quantized","buffer","create","err","length","console","warn","validateInputs","session","inputs","checkedInputs","missingInputs","inputName","inputNames","undefined","push","Error","join","numInputsProvided","Object","keys","numInputsNeeded","ignored","filter","includes","sessionRun","output","run","replaceTensors","e","error","obj","prop","toI64Tensor","items","Array","isArray","some","x","BigInt64Array","from","flat","map","BigInt","prepareAttentionMask","tokens","pad_token_id","config","eos_token_id","is_pad_token_in_inputs","indexOf","is_pad_token_not_equal_to_eos_token_id","data","dims","fill","boolTensor","value","seq2seqForward","add_decoder_pkv","arguments","encoder_outputs","past_key_values","last_hidden_state","decoderFeeds","input_ids","decoder_input_ids","encoder_hidden_states","use_cache_branch","decoder_merged_session","encoder_attention_mask","attention_mask","addPastKeyValues","decoderResults","logits","getPastKeyValues","Seq2SeqLMOutput","seq2seqStartBeams","inputTokenIds","numOutputTokens","requires_attention_mask","beams","beamId","decoder_start_token_id","start","output_token_ids","done","score","id","seq2seqRunBeam","beam","input_name","slice","encoderFeeds","key","decoderStartBeams","inputs_attention_mask","attn_mask","input","model_input_ids","num_output_tokens","decoderRunBeam","attnMaskData","decoderUpdatebeam","newTokenId","PreTrainedModel","dispose","promises","item","handler","Promise","all","from_pretrained","progress_callback","cache_dir","local_files_only","revision","modelType","info","_call","_get_logits_processor","generation_config","input_ids_seq_length","logits_processor","processors","repetition_penalty","no_repeat_ngram_size","forced_bos_token_id","forced_eos_token_id","max_length","begin_suppress_tokens","begin_index","forced_decoder_ids","extend","_get_generation_config","gen_config","assign","generate","is_encoder_decoder","maxOutputTokens","max_new_tokens","Infinity","useMaxLength","Number","isInteger","sampler","getSampler","getStartBeams","newest_beams","runBeam","sampledTokens","logProb","newBeam","updateBeam","groupBeams","group","sort","a","b","num_beams","callback_function","batch","num_return_sequences","groups","values","pastKeyValues","pkvs","startsWith","newName","replace","hasDecoder","encoder_dims","num_encoder_heads","encoder_dim_kv","i","num_encoder_layers","decoder_dims","num_decoder_heads","decoder_dim_kv","num_decoder_layers","num_heads","dim_kv","num_layers","ModelOutput","BaseModelOutput","_ref","hidden_states","attentions","BertPreTrainedModel","BertModel","BertForMaskedLM","MaskedLMOutput","BertForSequenceClassification","SequenceClassifierOutput","BertForTokenClassification","TokenClassifierOutput","BertForQuestionAnswering","QuestionAnsweringModelOutput","DistilBertPreTrainedModel","DistilBertModel","DistilBertForSequenceClassification","DistilBertForTokenClassification","DistilBertForQuestionAnswering","DistilBertForMaskedLM","MobileBertPreTrainedModel","MobileBertModel","MobileBertForMaskedLM","MobileBertForSequenceClassification","MobileBertForQuestionAnswering","SqueezeBertPreTrainedModel","SqueezeBertModel","SqueezeBertForMaskedLM","SqueezeBertForSequenceClassification","SqueezeBertForQuestionAnswering","AlbertPreTrainedModel","AlbertModel","AlbertForSequenceClassification","AlbertForQuestionAnswering","AlbertForMaskedLM","T5PreTrainedModel","T5Model","T5ForConditionalGeneration","d_kv","MT5PreTrainedModel","MT5Model","MT5ForConditionalGeneration","BartPretrainedModel","BartModel","BartForConditionalGeneration","decoder_layers","decoder_attention_heads","d_model","encoder_layers","encoder_attention_heads","BartForSequenceClassification","RobertaPreTrainedModel","RobertaModel","RobertaForMaskedLM","RobertaForSequenceClassification","RobertaForQuestionAnswering","WhisperPreTrainedModel","WhisperModel","WhisperForConditionalGeneration","return_timestamps","VisionEncoderDecoderModel","decoder","n_layer","n_head","n_embd","CLIPPreTrainedModel","CLIPModel","GPT2PreTrainedModel","GPT2Model","GPT2LMHeadModel","GPTNeoPreTrainedModel","hidden_size","GPTNeoModel","GPTNeoForCausalLM","CodeGenPreTrainedModel","CodeGenModel","CodeGenForCausalLM","ViTPreTrainedModel","ViTForImageClassification","DetrPreTrainedModel","DetrForObjectDetection","DetrObjectDetectionOutput","DetrForSegmentation","DetrSegmentationOutput","_ref2","pred_boxes","_ref3","pred_masks","SamPreTrainedModel","SamModel","SamImageSegmentationOutput","_ref4","iou_scores","MarianPreTrainedModel","MarianModel","MarianMTModel","M2M100PreTrainedModel","M2M100Model","M2M100ForConditionalGeneration","PretrainedMixin","MODEL_CLASS_MAPPINGS","BASE_IF_FAIL","modelClass","model_type","MODEL_MAPPING_NAMES_ENCODER_ONLY","MODEL_MAPPING_NAMES_ENCODER_DECODER","MODEL_MAPPING_NAMES_DECODER_ONLY","MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING_NAMES","MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING_NAMES","MODEL_FOR_SEQ_2_SEQ_MAPPING_NAMES","MODEL_WITH_LM_HEAD_MAPPING_NAMES","MODEL_FOR_MASKED_LM_MAPPING_NAMES","MODEL_FOR_QUESTION_ANSWERING_MAPPING_NAMES","MODEL_FOR_VISION_2_SEQ_MAPPING_NAMES","MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING_NAMES","MODEL_FOR_OBJECT_DETECTION_MAPPING_NAMES","MODEL_FOR_IMAGE_SEGMENTATION_MAPPING_NAMES","MODEL_FOR_MASK_GENERATION_MAPPING_NAMES","MODEL_CLASS_TYPE_MAPPING","mappings","type","model","entries","set","AutoModel","AutoModelForSequenceClassification","AutoModelForTokenClassification","AutoModelForSeq2SeqLM","AutoModelForCausalLM","AutoModelForMaskedLM","AutoModelForQuestionAnswering","AutoModelForVision2Seq","AutoModelForImageClassification","AutoModelForImageSegmentation","AutoModelForObjectDetection","AutoModelForMaskGeneration","_ref5","_ref6","_ref7","_ref8","_ref9","start_logits","end_logits","CausalLMOutputWithPast","_ref10"],"sources":["/Users/phreetech13/Desktop/RealTimeAudioToText/node_modules/@xenova/transformers/src/models.js"],"sourcesContent":["\n/**\n * @file Definitions of all models available in Transformers.js.\n * \n * **Example:** Load and run an `AutoModel`.\n * \n * ```javascript\n * import { AutoModel, AutoTokenizer } from '@xenova/transformers';\n *\n * let tokenizer = await AutoTokenizer.from_pretrained('Xenova/bert-base-uncased');\n * let model = await AutoModel.from_pretrained('Xenova/bert-base-uncased');\n *\n * let inputs = await tokenizer('I love transformers!');\n * let { logits } = await model(inputs);\n * // Tensor {\n * //     data: Float32Array(183132) [-7.117443084716797, -7.107812881469727, -7.092104911804199, ...]\n * //     dims: (3) [1, 6, 30522],\n * //     type: \"float32\",\n * //     size: 183132,\n * // }\n * ```\n * \n * We also provide other `AutoModel`s (listed below), which you can use in the same way as the Python library. For example:\n * \n * **Example:** Load and run a `AutoModelForSeq2SeqLM`.\n * ```javascript\n * import { AutoModelForSeq2SeqLM, AutoTokenizer } from '@xenova/transformers';\n * \n * let tokenizer = await AutoTokenizer.from_pretrained('Xenova/t5-small');\n * let model = await AutoModelForSeq2SeqLM.from_pretrained('Xenova/t5-small');\n *\n * let { input_ids } = await tokenizer('translate English to German: I love transformers!');\n * let outputs = await model.generate(input_ids);\n * let decoded = await tokenizer.decode(outputs[0][0], { skip_special_tokens: true });\n * // 'Ich liebe Transformatoren!'\n * ```\n * \n * @module models\n */\n\nimport {\n    AutoConfig,\n} from './configs.js';\n\nimport {\n    Callable,\n    isIntegralNumber,\n    isTypedArray,\n} from './utils/core.js';\n\nimport {\n    getModelFile,\n    getModelJSON,\n} from './utils/hub.js';\n\nimport {\n    LogitsProcessorList,\n    GenerationConfig,\n    ForceTokensLogitsProcessor,\n    ForcedBOSTokenLogitsProcessor,\n    ForcedEOSTokenLogitsProcessor,\n    SuppressTokensAtBeginLogitsProcessor,\n    WhisperTimeStampLogitsProcessor,\n    NoRepeatNGramLogitsProcessor,\n    RepetitionPenaltyLogitsProcessor,\n\n    Sampler,\n} from './utils/generation.js';\n\nimport {\n    Tensor,\n} from './utils/tensor.js';\n\nimport { executionProviders, ONNX } from './backends/onnx.js';\nconst { InferenceSession, Tensor: ONNXTensor } = ONNX;\n\n/**\n * @typedef {import('./utils/hub.js').PretrainedOptions} PretrainedOptions\n */\n\n\n//////////////////////////////////////////////////\n// Model types: used internally\nclass ModelType { };\n\n// Either encoder-only or encoder-decoder (and will be decided by `model.config.is_encoder_decoder`)\nclass EncoderOnlyModelType extends ModelType { };\nclass EncoderDecoderModelType extends ModelType { };\nclass Seq2SeqModelType extends EncoderDecoderModelType { };\nclass DecoderOnlyModelType extends ModelType { };\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\n// Helper functions\n\n// Will be populated later\nconst MODEL_TYPE_MAPPING = new Map();\nconst MODEL_CLASS_MAPPING = new Map();\n\n/**\n * Helper function to determine which `forward` method to run for a specific model.\n * @param {Object} self The calling object\n * @param {Object} model_inputs The inputs to be sent to the model\n * @returns {Promise<Object>} The model output\n */\nasync function forward(self, model_inputs) {\n    if (MODEL_TYPE_MAPPING.get(self.constructor.name) === DecoderOnlyModelType) {\n        return await decoderForward(self, model_inputs);\n    } else {\n        return await encoderForward(self, model_inputs);\n    }\n}\n\n/**\n * Constructs an InferenceSession using a model file located at the specified path.\n * @param {string} pretrained_model_name_or_path The path to the directory containing the model file.\n * @param {string} fileName The name of the model file.\n * @param {PretrainedOptions} options Additional options for loading the model.\n * @returns {Promise<InferenceSession>} A Promise that resolves to an InferenceSession object.\n * @private\n */\nasync function constructSession(pretrained_model_name_or_path, fileName, options) {\n    // TODO add option for user to force specify their desired execution provider\n    let modelFileName = `onnx/${fileName}${options.quantized ? '_quantized' : ''}.onnx`;\n    let buffer = await getModelFile(pretrained_model_name_or_path, modelFileName, true, options);\n\n    try {\n        return await InferenceSession.create(buffer, {\n            executionProviders,\n        });\n    } catch (err) {\n        // If the execution provided was only wasm, throw the error\n        if (executionProviders.length === 1 && executionProviders[0] === 'wasm') {\n            throw err;\n        }\n\n        console.warn(err);\n        console.warn(\n            'Something went wrong during model construction (most likely a missing operation). ' +\n            'Using `wasm` as a fallback. '\n        )\n        return await InferenceSession.create(buffer, {\n            executionProviders: ['wasm']\n        });\n    }\n}\n\n/**\n * Validate model inputs\n * @param {InferenceSession} session The InferenceSession object that will be run.\n * @param {Object} inputs The inputs to check.\n * @returns {Promise<Object>} A Promise that resolves to the checked inputs.\n * @throws {Error} If any inputs are missing.\n * @private\n */\nasync function validateInputs(session, inputs) {\n    // NOTE: Only create a shallow copy\n    const checkedInputs = {};\n    const missingInputs = [];\n    for (let inputName of session.inputNames) {\n        if (inputs[inputName] === undefined) {\n            missingInputs.push(inputName);\n        } else {\n            checkedInputs[inputName] = inputs[inputName];\n        }\n    }\n    if (missingInputs.length > 0) {\n        throw new Error(\n            `An error occurred during model execution: \"Missing the following inputs: ${missingInputs.join(', ')}.`);\n    }\n\n    const numInputsProvided = Object.keys(inputs).length;\n    const numInputsNeeded = session.inputNames.length;\n    if (numInputsProvided > numInputsNeeded) {\n        // No missing inputs, but too many inputs were provided.\n        // Warn the user and ignore the extra inputs.\n        let ignored = Object.keys(inputs).filter(inputName => !session.inputNames.includes(inputName));\n        console.warn(`WARNING: Too many inputs were provided (${numInputsProvided} > ${numInputsNeeded}). The following inputs will be ignored: \"${ignored.join(', ')}\".`);\n    }\n\n    return checkedInputs;\n}\n\n/**\n * Executes an InferenceSession using the specified inputs.\n * NOTE: `inputs` must contain at least the input names of the model.\n *  - If additional inputs are passed, they will be ignored.\n *  - If inputs are missing, an error will be thrown.\n * \n * @param {InferenceSession} session The InferenceSession object to run.\n * @param {Object} inputs An object that maps input names to input tensors.\n * @returns {Promise<Object>} A Promise that resolves to an object that maps output names to output tensors.\n * @private\n */\nasync function sessionRun(session, inputs) {\n    const checkedInputs = await validateInputs(session, inputs);\n    try {\n        let output = await session.run(checkedInputs);\n        output = replaceTensors(output);\n        return output;\n    } catch (e) {\n        // This usually occurs when the inputs are of the wrong type.\n        console.error(`An error occurred during model execution: \"${e}\".`);\n        console.error('Inputs given to model:', checkedInputs);\n        throw e;\n    }\n}\n\n/**\n * Replaces ONNX Tensor objects with custom Tensor objects to support additional functions.\n * @param {Object} obj The object to replace tensor objects in.\n * @returns {Object} The object with tensor objects replaced by custom Tensor objects.\n * @private\n */\nfunction replaceTensors(obj) {\n    for (let prop in obj) {\n        if (obj[prop] instanceof ONNXTensor) {\n            obj[prop] = new Tensor(obj[prop]);\n        }\n    }\n    return obj;\n}\n\n\n/**\n * Converts an array or Tensor of integers to an int64 Tensor.\n * @param {Array|Tensor} items The input integers to be converted.\n * @returns {Tensor} The int64 Tensor with the converted values.\n * @throws {Error} If the input array is empty or the input is a batched Tensor and not all sequences have the same length.\n * @private\n */\nfunction toI64Tensor(items) {\n    if (items instanceof Tensor) {\n        return items;\n    }\n    // items is an array\n    if (items.length === 0) {\n        throw Error(\"items must be non-empty\");\n    }\n\n    if (Array.isArray(items[0])) {\n        // batched\n        if (items.some(x => x.length !== items[0].length)) {\n            throw Error(\"Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' and/or 'truncation=True' to have batched tensors with the same length.\")\n        }\n\n        return new Tensor('int64',\n            BigInt64Array.from(items.flat().map(x => BigInt(x))),\n            [items.length, items[0].length]\n        );\n    } else {\n        //flat\n        return new Tensor('int64',\n            BigInt64Array.from(items.map(x => BigInt(x))),\n            [1, items.length]\n        );\n    }\n}\n\n/**\n * Prepares an attention mask for a sequence of tokens based on configuration options.\n * @param {Object} self The calling object instance.\n * @param {Tensor} tokens The input tokens.\n * @returns {Tensor} The attention mask tensor.\n * @private\n */\nfunction prepareAttentionMask(self, tokens) {\n\n    // Prepare attention mask\n    let pad_token_id = self.config.pad_token_id ?? null;\n    let eos_token_id = self.config.eos_token_id ?? null;\n    if (isIntegralNumber(eos_token_id)) {\n        eos_token_id = [eos_token_id];\n    }\n\n    let is_pad_token_in_inputs = tokens.indexOf(pad_token_id) !== -1;\n    let is_pad_token_not_equal_to_eos_token_id = (eos_token_id === null) || !eos_token_id.includes(pad_token_id)\n\n    if (is_pad_token_in_inputs && is_pad_token_not_equal_to_eos_token_id) {\n        let data = BigInt64Array.from(\n            // Note: != so that int matches bigint\n            tokens.data.map(x => x != pad_token_id)\n        )\n        return new Tensor('int64', data, tokens.dims)\n    } else {\n        return new Tensor(\n            'int64',\n            new BigInt64Array(tokens.data.length).fill(1n),\n            tokens.dims\n        )\n    }\n}\n\n/**\n * Creates a boolean tensor with a single value.\n * @param {boolean} value The value of the tensor.\n * @returns {Tensor} The boolean tensor.\n * @private\n */\nfunction boolTensor(value) {\n    return new Tensor('bool', [value], [1]);\n}\n\n// JS doesn't support mixins, so we define some reused functions here, and allow \"this\" to be passed in\n/**\n * Perform forward pass on the seq2seq model (both encoder and decoder).\n * @param {Object} self The seq2seq model object.\n * @param {Object} model_inputs The input object for the model containing encoder and decoder inputs.\n * @param {Object} options The options\n * @param {boolean} [options.add_decoder_pkv=true] Flag to add the decoder past key values.\n * @returns {Promise<Seq2SeqLMOutput>} Promise that resolves with the output of the seq2seq model.\n * @private\n */\nasync function seq2seqForward(self, model_inputs, {\n    add_decoder_pkv = true\n} = {}) {\n    let { encoder_outputs, past_key_values } = model_inputs;\n\n    if (!encoder_outputs) {\n        // Encoder outputs are not given, so we must compute them.\n        encoder_outputs = (await encoderForward(self, model_inputs)).last_hidden_state;\n    }\n    let decoderFeeds = {\n        input_ids: model_inputs.decoder_input_ids,\n        encoder_hidden_states: encoder_outputs,\n        use_cache_branch: boolTensor(past_key_values !== null)\n    };\n\n    if (self.decoder_merged_session.inputNames.includes('encoder_attention_mask')) {\n        decoderFeeds.encoder_attention_mask = model_inputs.attention_mask\n    }\n    self.addPastKeyValues(decoderFeeds, past_key_values, add_decoder_pkv);\n\n    const decoderResults = await sessionRun(self.decoder_merged_session, decoderFeeds);\n    let logits = decoderResults.logits;\n    past_key_values = self.getPastKeyValues(decoderResults, past_key_values);\n    return new Seq2SeqLMOutput({ logits, past_key_values, encoder_outputs });\n}\n\n/**\n * Start the beam search process for the seq2seq model.\n * @param {Object} self The seq2seq model object.\n * @param {Object[]} inputTokenIds Array of input token ids for each input sequence.\n * @param {number} numOutputTokens The maximum number of output tokens for the model.\n * @param {boolean} [requires_attention_mask=true] Flag to indicate if the model requires an attention mask.\n * @returns {Object[]} Array of beam search objects.\n * @private\n */\nfunction seq2seqStartBeams(self, inputTokenIds, numOutputTokens, requires_attention_mask = true) {\n    let beams = [];\n    let beamId = 0;\n\n    // decoder_input_ids == output_token_ids\n    let decoder_input_ids = self.config.decoder_start_token_id;\n    if (!Array.isArray(decoder_input_ids)) {\n        decoder_input_ids = [decoder_input_ids];\n    }\n\n    for (let tokens of inputTokenIds) {\n        // TODO: Improve\n        // Currently, just add back batch dimension.\n        // In future, allow for true parallel execution\n        tokens.dims = [1, ...tokens.dims]\n\n        // Create beam\n        let start = {\n            inputs: tokens,\n            encoder_outputs: null,\n            past_key_values: null,\n\n            output_token_ids: decoder_input_ids,\n            done: false,\n            score: 0,\n            id: beamId++ // assign unique id to beams\n        }\n\n        if (requires_attention_mask) {\n            start.attention_mask = prepareAttentionMask(self, tokens);\n        }\n\n        beams.push(start);\n    }\n\n    return beams;\n}\n\n/**\n * Run beam search on the seq2seq model for a single beam.\n * @param {Object} self The seq2seq model object.\n * @param {Object} beam The beam search object for which to run the model.\n * @param {Object} options options\n * @param {string} [options.input_name='input_ids'] The name of the input tensor for the encoder.\n * @returns {Promise<Object>} Promise that resolves with the output of the seq2seq model for the given beam.\n * @private\n */\nasync function seq2seqRunBeam(self, beam, {\n    input_name = 'input_ids',\n} = {}\n) {\n    // 1. Prepare\n    let model_inputs = {\n        [input_name]: beam.inputs,\n        decoder_input_ids: toI64Tensor(beam.output_token_ids.slice(-1)),\n        encoder_outputs: beam.encoder_outputs,\n        past_key_values: beam.past_key_values,\n    }\n    if (beam.attention_mask) {\n        model_inputs.attention_mask = beam.attention_mask\n    }\n\n    // 2. Run\n    let output = await self.forward(model_inputs);\n\n    // 3. Update\n    beam.past_key_values = output.past_key_values;\n    beam.encoder_outputs = output.encoder_outputs;\n\n    return output;\n}\n\n/**\n * Forward pass of an encoder model.\n * @param {Object} self The encoder model.\n * @param {Object} model_inputs The input data to be used for the forward pass.\n * @returns {Promise<Object>} Promise that resolves with an object containing the model's outputs.\n * @private\n */\nasync function encoderForward(self, model_inputs) {\n    let encoderFeeds = {};\n    for (let key of self.session.inputNames) {\n        encoderFeeds[key] = model_inputs[key];\n    }\n    return await sessionRun(self.session, encoderFeeds);\n}\n\n\n/**\n * Forward pass of a decoder model.\n * @param {Object} self The decoder model.\n * @param {Object} model_inputs The input data to be used for the forward pass.\n * @returns {Promise<Object>} Promise that resolves with an object containing the logits and past key values.\n * @private\n */\nasync function decoderForward(self, model_inputs) {\n    let past_key_values = model_inputs.past_key_values;\n    let decoderFeeds = {\n        input_ids: model_inputs.input_ids,\n        attention_mask: model_inputs.attention_mask ?? prepareAttentionMask(self, model_inputs.input_ids),\n        use_cache_branch: boolTensor(past_key_values !== null)\n    }\n\n    self.addPastKeyValues(decoderFeeds, past_key_values);\n\n    let decoderResults = await sessionRun(self.session, decoderFeeds);\n    let logits = decoderResults.logits;\n\n    past_key_values = self.getPastKeyValues(decoderResults, past_key_values);\n    return { logits, past_key_values };\n}\n\n/**\n * Starts the generation of text by initializing the beams for the given input token IDs.\n * @param {Object} self The text generation model object.\n * @param {any} inputTokenIds An array of input token IDs to generate text from.\n * @param {number} numOutputTokens The maximum number of tokens to generate for each beam.\n * @param {Tensor} [inputs_attention_mask] The attention mask tensor for the input token IDs.\n * @returns {Object[]} An array of beams initialized with the given inputs and parameters.\n * @private\n */\nfunction decoderStartBeams(self, inputTokenIds, numOutputTokens, inputs_attention_mask) {\n    let beams = [];\n\n    let beamId = 0;\n    for (let tokens of inputTokenIds) {\n        // TODO: Improve\n        // Currently, just add back batch dimension.\n        // In future, allow for true parallel execution\n        tokens.dims = [1, ...tokens.dims]\n\n        let attn_mask;\n        if (inputs_attention_mask) {\n            attn_mask = inputs_attention_mask[beamId];\n            attn_mask.dims = [1, ...attn_mask.dims]\n\n        } else {\n            attn_mask = prepareAttentionMask(self, tokens)\n        }\n\n        let start = {\n            input: tokens,\n            model_input_ids: tokens,\n            attention_mask: attn_mask,\n            past_key_values: null,\n\n            output_token_ids: [],\n            num_output_tokens: numOutputTokens,\n\n            done: false,\n            score: 0,\n            id: beamId++ // assign unique id to beams\n        }\n\n        beams.push(start);\n    }\n    return beams;\n}\n\n/**\n * Runs a single step of the text generation process for a given beam.\n *\n * @param {Object} self The decoder object.\n * @param {Object} beam The beam to run.\n * @param {Tensor} beam.input The input tensor.\n * @param {Tensor} beam.model_input_ids The input ids to the model.\n * @param {Tensor} beam.attention_mask The attention mask.\n * @param {Object} beam.past_key_values The past key values.\n * @param {number[]} beam.output_token_ids The output token ids.\n * @returns {Promise<Object>} The output of the generation step.\n * @private\n */\nasync function decoderRunBeam(self, beam) {\n    let attnMaskData = new BigInt64Array(beam.input.data.length + beam.output_token_ids.length).fill(1n)\n\n    // 1. Prepare\n    let model_inputs = {\n        input_ids: beam.model_input_ids,\n        attention_mask: new Tensor(\n            'int64',\n            attnMaskData,\n            [1, attnMaskData.length]\n        ),\n        past_key_values: beam.past_key_values,\n    }\n\n    // 2. Run\n    let output = await self.forward(model_inputs);\n\n    // 3. Update\n    beam.past_key_values = output.past_key_values;\n\n    return output;\n}\n\n/**\n * Update a beam with a new token ID.\n * @param {Object} beam The beam to update.\n * @param {number} newTokenId The new token ID to add to the beam's output.\n * @private\n */\nfunction decoderUpdatebeam(beam, newTokenId) {\n    beam.output_token_ids = [...beam.output_token_ids, newTokenId];\n    beam.model_input_ids = new Tensor('int64', [BigInt(newTokenId)], [1, 1]);\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n/**\n * A base class for pre-trained models that provides the model configuration and an ONNX session.\n * @extends Callable\n */\nexport class PreTrainedModel extends Callable {\n\n    /**\n     * Creates a new instance of the `PreTrainedModel` class.\n     * @param {Object} config The model configuration.\n     * @param {any} session session for the model.\n     */\n    constructor(config, session) {\n        super();\n\n        this.config = config;\n        this.session = session;\n    }\n\n    /**\n    * Disposes of all the ONNX sessions that were created during inference.\n    * @returns {Promise<unknown[]>} An array of promises, one for each ONNX session that is being disposed.\n    * @todo Use https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/FinalizationRegistry\n    */\n    async dispose() {\n        let promises = [];\n        for (let key of Object.keys(this)) {\n            let item = this[key];\n            if (item instanceof InferenceSession) {\n                promises.push(item.handler.dispose())\n            }\n        }\n        return await Promise.all(promises);\n    }\n\n    /**\n     * Instantiate one of the model classes of the library from a pretrained model.\n     * \n     * The model class to instantiate is selected based on the `model_type` property of the config object\n     * (either passed as an argument or loaded from `pretrained_model_name_or_path` if possible)\n     * \n     * @param {string} pretrained_model_name_or_path The name or path of the pretrained model. Can be either:\n     * - A string, the *model id* of a pretrained model hosted inside a model repo on huggingface.co.\n     *   Valid model ids can be located at the root-level, like `bert-base-uncased`, or namespaced under a\n     *   user or organization name, like `dbmdz/bert-base-german-cased`.\n     * - A path to a *directory* containing model weights, e.g., `./my_model_directory/`.\n     * @param {PretrainedOptions} options Additional options for loading the model.\n     * \n     * @returns {Promise<PreTrainedModel>} A new instance of the `PreTrainedModel` class.\n     */\n    static async from_pretrained(pretrained_model_name_or_path, {\n        quantized = true,\n        progress_callback = null,\n        config = null,\n        cache_dir = null,\n        local_files_only = false,\n        revision = 'main',\n    } = {}) {\n\n        let options = {\n            quantized,\n            progress_callback,\n            config,\n            cache_dir,\n            local_files_only,\n            revision,\n        }\n\n        let modelType = MODEL_TYPE_MAPPING.get(this.name);\n\n        let info;\n        if (modelType === DecoderOnlyModelType) {\n            info = await Promise.all([\n                AutoConfig.from_pretrained(pretrained_model_name_or_path, options),\n                constructSession(pretrained_model_name_or_path, 'decoder_model_merged', options),\n            ]);\n\n        } else if (modelType === Seq2SeqModelType) {\n            info = await Promise.all([\n                AutoConfig.from_pretrained(pretrained_model_name_or_path, options),\n                constructSession(pretrained_model_name_or_path, 'encoder_model', options),\n                constructSession(pretrained_model_name_or_path, 'decoder_model_merged', options),\n                getModelJSON(pretrained_model_name_or_path, 'generation_config.json', false, options),\n            ]);\n\n        } else if (modelType === EncoderDecoderModelType) {\n            info = await Promise.all([\n                AutoConfig.from_pretrained(pretrained_model_name_or_path, options),\n                constructSession(pretrained_model_name_or_path, 'encoder_model', options),\n                constructSession(pretrained_model_name_or_path, 'decoder_model_merged', options),\n            ]);\n\n        } else if (modelType === EncoderOnlyModelType) {\n            info = await Promise.all([\n                AutoConfig.from_pretrained(pretrained_model_name_or_path, options),\n                constructSession(pretrained_model_name_or_path, 'model', options)\n            ]);\n\n        } else {\n            console.warn('Malformed class definition.', this);\n            throw Error(`Unable to load model: ${pretrained_model_name_or_path}. Please report this bug at https://github.com/xenova/transformers.js/issues/new/choose.`);\n        }\n\n        // @ts-ignore\n        return new this(...info);\n    }\n\n    /**\n     * Runs the model with the provided inputs\n     * @param {Object} model_inputs Object containing input tensors\n     * @returns {Promise<Object>} Object containing output tensors\n     */\n    async _call(model_inputs) {\n        return await this.forward(model_inputs);\n    }\n\n    /**\n     * Forward method for a pretrained model. If not overridden by a subclass, the correct forward method\n     * will be chosen based on the model type.\n     * @param {Object} model_inputs The input data to the model in the format specified in the ONNX model.\n     * @returns {Promise<Object>} The output data from the model in the format specified in the ONNX model.\n     * @throws {Error} This method must be implemented in subclasses.\n     */\n    async forward(model_inputs) {\n        return await forward(this, model_inputs);\n    }\n\n    /**\n     * @param {GenerationConfig} generation_config \n     * @param {number} input_ids_seq_length The starting sequence length for the input ids.\n     * @returns {LogitsProcessorList}\n     */\n    _get_logits_processor(\n        generation_config,\n        input_ids_seq_length,\n        // encoder_input_ids, TODO\n        // prefix_allowed_tokens_fn, TODO\n        logits_processor = null\n    ) {\n        const processors = new LogitsProcessorList();\n\n        // if (generation_config.diversity_penalty !== null && generation_config.diversity_penalty > 0.0) {\n        //     processors.push(new HammingDiversityLogitsProcessor(\n        //         generation_config.diversity_penalty,\n        //         generation_config.num_beams,\n        //         generation_config.num_beam_groups\n        //     ));\n        // }\n\n        // if (generation_config.encoder_repetition_penalty !== null && generation_config.encoder_repetition_penalty !== 1.0) {\n        //     processors.push(new EncoderRepetitionPenaltyLogitsProcessor(\n        //         generation_config.encoder_repetition_penalty,\n        //         encoder_input_ids\n        //     ));\n        // }\n\n        if (generation_config.repetition_penalty !== null && generation_config.repetition_penalty !== 1.0) {\n            processors.push(new RepetitionPenaltyLogitsProcessor(generation_config.repetition_penalty));\n        }\n\n        if (generation_config.no_repeat_ngram_size !== null && generation_config.no_repeat_ngram_size > 0) {\n            processors.push(new NoRepeatNGramLogitsProcessor(generation_config.no_repeat_ngram_size));\n        }\n\n        // if (generation_config.encoder_no_repeat_ngram_size !== null && generation_config.encoder_no_repeat_ngram_size > 0) {\n        //     if (this.config.is_encoder_decoder) {\n        //         processors.push(new EncoderNoRepeatNGramLogitsProcessor(\n        //             generation_config.encoder_no_repeat_ngram_size,\n        //             encoder_input_ids\n        //         ));\n        //     } else {\n        //         throw new Error(\"It's impossible to use `encoder_no_repeat_ngram_size` with decoder-only architecture\");\n        //     }\n        // }\n\n        // if (generation_config.bad_words_ids !== null) {\n        //     processors.push(new NoBadWordsLogitsProcessor(generation_config.bad_words_ids, generation_config.eos_token_id));\n        // }\n\n        // if (generation_config.min_length !== null && generation_config.eos_token_id !== null && generation_config.min_length > 0) {\n        //     processors.push(new MinLengthLogitsProcessor(generation_config.min_length, generation_config.eos_token_id));\n        // }\n\n        // if (generation_config.min_new_tokens !== null && generation_config.eos_token_id !== null && generation_config.min_new_tokens > 0) {\n        //     processors.push(new MinNewTokensLengthLogitsProcessor(\n        //         input_ids_seq_length,\n        //         generation_config.min_new_tokens,\n        //         generation_config.eos_token_id\n        //     ));\n        // }\n\n        // if (prefix_allowed_tokens_fn !== null) {\n        //     processors.push(new PrefixConstrainedLogitsProcessor(\n        //         prefix_allowed_tokens_fn,\n        //         generation_config.num_beams / generation_config.num_beam_groups\n        //     ));\n        // }\n\n\n        if (generation_config.forced_bos_token_id !== null) {\n            processors.push(new ForcedBOSTokenLogitsProcessor(generation_config.forced_bos_token_id));\n        }\n\n        if (generation_config.forced_eos_token_id !== null) {\n            processors.push(new ForcedEOSTokenLogitsProcessor(\n                generation_config.max_length,\n                generation_config.forced_eos_token_id\n            ));\n        }\n\n        // if (generation_config.remove_invalid_values === true) {\n        //     processors.push(new InfNanRemoveLogitsProcessor());\n        // }\n\n        // if (generation_config.exponential_decay_length_penalty !== null) {\n        //     processors.push(new ExponentialDecayLengthPenalty(\n        //         generation_config.exponential_decay_length_penalty,\n        //         generation_config.eos_token_id,\n        //         input_ids_seq_length\n        //     ));\n        // }\n\n        // if (generation_config.suppress_tokens !== null) {\n        //     processors.push(new SuppressTokensLogitsProcessor(generation_config.suppress_tokens));\n        // }\n\n        if (generation_config.begin_suppress_tokens !== null) {\n            let begin_index = (input_ids_seq_length > 1 || generation_config.forced_bos_token_id === null)\n                ? input_ids_seq_length\n                : input_ids_seq_length + 1;\n\n            if (generation_config.forced_decoder_ids !== null) {\n                // generation starts after the last token that is forced\n                begin_index += generation_config.forced_decoder_ids[generation_config.forced_decoder_ids.length - 1][0];\n            }\n            processors.push(new SuppressTokensAtBeginLogitsProcessor(generation_config.begin_suppress_tokens, begin_index));\n        }\n\n        if (generation_config.forced_decoder_ids !== null) {\n            processors.push(new ForceTokensLogitsProcessor(generation_config.forced_decoder_ids));\n        }\n\n        if (logits_processor !== null) {\n            processors.extend(logits_processor)\n        }\n\n        // `LogitNormalization` should always be the last logit processor, when present\n        // if (generation_config.renormalize_logits === true) {\n        //     processors.push(new LogitNormalization());\n        // }\n\n        return processors;\n    }\n\n    /**\n   * This function merges multiple generation configs together to form a final generation config to be used by the model for text generation.\n   * It first creates an empty `GenerationConfig` object, then it applies the model's own `generation_config` property to it. Finally, if a `generation_config` object was passed in the arguments, it overwrites the corresponding properties in the final config with those of the passed config object.\n   *\n   * @param {GenerationConfig} generation_config A `GenerationConfig` object containing generation parameters.\n   * @returns {GenerationConfig} The final generation config object to be used by the model for text generation.\n   */\n    _get_generation_config(generation_config) {\n        // Create empty generation config (contains defaults)\n        let gen_config = new GenerationConfig();\n\n        // Apply model's generation config, if it exists\n        if ('generation_config' in this) {\n            Object.assign(gen_config, this.generation_config);\n        }\n\n        // Finally, use any generation config specified by the user\n        // when calling `generate`\n        if (generation_config !== null) {\n            Object.assign(gen_config, generation_config);\n        }\n        return gen_config;\n    }\n\n    /**\n     * @typedef {import('./utils/maths.js').TypedArray} TypedArray\n     */\n\n    /**\n     * Generates text based on the given inputs and generation configuration using the model.\n     * @param {Tensor|Array|TypedArray} inputs An array of input token IDs.\n     * @param {Object|null} generation_config The generation configuration to use. If null, default configuration will be used.\n     * @param {Object|null} logits_processor An optional logits processor to use. If null, a new LogitsProcessorList instance will be created.\n     * @param {Object} options options\n     * @param {Object} [options.inputs_attention_mask=null] An optional attention mask for the inputs.\n     * @returns {Promise<number[][]>} An array of generated output sequences, where each sequence is an array of token IDs.\n     * @throws {Error} Throws an error if the inputs array is empty.\n     */\n    async generate(\n        inputs,\n        generation_config = null,\n        logits_processor = null,\n        {\n            inputs_attention_mask = null\n        } = {},\n    ) {\n\n        if (!(inputs instanceof Tensor) && !isTypedArray(inputs) && !Array.isArray(inputs)) {\n            throw Error(`\\`inputs\\` must be a Tensor, TypedArray, or Array, but is \"${inputs.constructor.name}\".`);\n        }\n\n        let input_ids_seq_length;\n\n        // Prepare `input_ids` which will be used for auto-regressive generation\n        // TODO: Update to align with HF transformers' implementation\n        if (this.config.is_encoder_decoder) {\n            // Generating from the encoder outputs\n            input_ids_seq_length = 0;\n\n        } else {\n            input_ids_seq_length = inputs instanceof Tensor ? inputs.dims[0] : inputs.length;\n\n            // decoder-only\n            if (input_ids_seq_length === 0) {\n                throw Error(\"Must supply a non-empty array of input token ids.\")\n            }\n        }\n\n        // Update generation config with defaults\n        generation_config = this._get_generation_config(generation_config);\n\n        logits_processor = logits_processor ?? new LogitsProcessorList()\n\n        // Update logits processor\n        logits_processor = this._get_logits_processor(\n            generation_config,\n            input_ids_seq_length,\n            logits_processor\n        )\n\n        // TODO implement early_stopping\n        // https://huggingface.co/blog/how-to-generate\n\n        let numOutputTokens = 1;\n        const maxOutputTokens = numOutputTokens + (generation_config.max_new_tokens ?? Infinity);\n\n        // Only use max length if max_new_tokens is not provided\n        const useMaxLength = Number.isInteger(generation_config.max_length) && (generation_config.max_new_tokens ?? null) === null;\n        let sampler = Sampler.getSampler(generation_config);\n\n        // @ts-ignore\n        let beams = this.getStartBeams(inputs, numOutputTokens, inputs_attention_mask);\n\n        while (beams.some(x => !x.done) && numOutputTokens < maxOutputTokens) {\n            let newest_beams = [];\n            for (let beam of beams) {\n                if (beam.done) {\n                    // Add this beam back into the pool\n                    newest_beams.push(beam);\n                    continue\n                }\n                if (useMaxLength && beam.output_token_ids.length >= generation_config.max_length) {\n                    // Set this beam to done and add it back into the pool\n                    beam.done = true;\n                    newest_beams.push(beam);\n                    continue\n                }\n\n                // @ts-ignore\n                let output = await this.runBeam(beam);\n\n                // Logits are of the form [batch_size, out_seq_length, vocab_size]\n                // In most cases, this will be [batch_size, 1, vocab_size]\n                // So, we select the last token's logits:\n                // (equivalent to `logits = outputs.logits[:, -1, :]`)\n                let logits = output.logits.slice(null, -1, null);\n\n                // Apply logits processor\n                logits_processor(beam.output_token_ids, logits);\n\n                let sampledTokens = sampler(logits);\n                for (let [newTokenId, logProb] of sampledTokens) {\n                    // use previous beam as a starting point\n                    let newBeam = { ...beam };\n\n                    // update new beam\n                    // @ts-ignore\n                    this.updateBeam(newBeam, newTokenId);\n\n                    newBeam.score += logProb;\n\n                    if (newTokenId === this.config.eos_token_id) {\n                        newBeam.done = true;\n                    }\n                    newest_beams.push(newBeam);\n                }\n            }\n            ++numOutputTokens;\n\n            // Next, we get the best beams, per ID\n            newest_beams = this.groupBeams(newest_beams).map(\n                group => group\n                    .sort((a, b) => b.score - a.score)      // sort by score\n                    .slice(0, generation_config.num_beams)  // remove outside beam width\n            );\n\n            // Flatten beams\n            beams = newest_beams.flat();\n\n            // Run callback\n            if (generation_config.callback_function) {\n                generation_config.callback_function(beams);\n            }\n        }\n\n        // TODO: Ensure that we can return non-batched outputs\n\n        return this.groupBeams(beams).map(\n            batch => {\n                if (generation_config.num_return_sequences > 1) {\n                    return batch.slice(0, generation_config.num_return_sequences).map(x => x.output_token_ids);\n                } else {\n                    return [batch[0].output_token_ids];\n                }\n            }\n        ).flat(); // Flatten across batches (depth=1)\n    }\n\n    /**\n     * Groups an array of beam objects by their ids.\n     *\n     * @param {Array} beams The array of beam objects to group.\n     * @returns {Array} An array of arrays, where each inner array contains beam objects with the same id.\n     */\n    groupBeams(beams) {\n        // Group beams by their ids\n        const groups = Object.create(null);\n        for (const obj of beams) {\n            if (groups[obj.id] === undefined) {\n                groups[obj.id] = [obj];\n            } else {\n                groups[obj.id].push(obj);\n            }\n        }\n\n        return Object.values(groups);\n    }\n\n    /**\n     * Returns an object containing past key values from the given decoder results object.\n     *\n     * @param {Object} decoderResults The decoder results object.\n     * @param {Object} pastKeyValues The previous past key values.\n     * @returns {Object} An object containing past key values.\n     */\n    getPastKeyValues(decoderResults, pastKeyValues) {\n\n        const pkvs = Object.create(null);\n\n        for (const name in decoderResults) {\n            if (name.startsWith('present')) {\n                let newName = name.replace('present', 'past_key_values');\n\n                if (pastKeyValues !== null && name.includes('encoder')) {\n                    // Optimization introduced by optimum to reuse past key values. So, we just replace the constant\n                    // outputs with the previous past key values.\n                    // https://github.com/huggingface/optimum/blob/0bf2c05fb7e1182b52d21b703cfc95fd9e4ea3dc/optimum/onnxruntime/base.py#L677-L704\n                    pkvs[newName] = pastKeyValues[newName];\n                } else {\n                    pkvs[newName] = decoderResults[name];\n                }\n            }\n        }\n        return pkvs;\n    }\n\n    /**\n     * Adds past key values to the decoder feeds object. If pastKeyValues is null, creates new tensors for past key values.\n     *\n     * @param {Object} decoderFeeds The decoder feeds object to add past key values to.\n     * @param {Object} pastKeyValues An object containing past key values.\n     * @param {boolean} [hasDecoder=false] Whether the model has a decoder.\n     */\n    addPastKeyValues(decoderFeeds, pastKeyValues, hasDecoder = false) {\n        if (pastKeyValues) {\n            Object.assign(decoderFeeds, pastKeyValues)\n        } else {\n            // TODO support batches (i.e., batch_size > 1)\n            if (hasDecoder) {\n                // @ts-ignore\n                let encoder_dims = [1, this.num_encoder_heads, 0, this.encoder_dim_kv];\n                // @ts-ignore\n                for (let i = 0; i < this.num_encoder_layers; ++i) {\n                    decoderFeeds[`past_key_values.${i}.encoder.key`] = new Tensor('float32', [], encoder_dims)\n                    decoderFeeds[`past_key_values.${i}.encoder.value`] = new Tensor('float32', [], encoder_dims)\n                }\n\n                // @ts-ignore\n                let decoder_dims = [1, this.num_decoder_heads, 0, this.decoder_dim_kv];\n                // @ts-ignore\n                for (let i = 0; i < this.num_decoder_layers; ++i) {\n                    decoderFeeds[`past_key_values.${i}.decoder.key`] = new Tensor('float32', [], decoder_dims)\n                    decoderFeeds[`past_key_values.${i}.decoder.value`] = new Tensor('float32', [], decoder_dims)\n                }\n\n            } else {\n                // @ts-ignore\n                let dims = [1, this.num_heads, 0, this.dim_kv]\n                // @ts-ignore\n                for (let i = 0; i < this.num_layers; ++i) {\n                    decoderFeeds[`past_key_values.${i}.key`] = new Tensor('float32', [], dims)\n                    decoderFeeds[`past_key_values.${i}.value`] = new Tensor('float32', [], dims)\n                }\n            }\n        }\n    }\n}\n//////////////////////////////////////////////////\n// Base model output class\nexport class ModelOutput { }\n\n/**\n * Base class for model's outputs, with potential hidden states and attentions.\n */\nexport class BaseModelOutput extends ModelOutput {\n    /**\n     * @param {Object} output The output of the model.\n     * @param {Tensor} output.last_hidden_state Sequence of hidden-states at the output of the last layer of the model.\n     * @param {Tensor} [output.hidden_states] Hidden-states of the model at the output of each layer plus the optional initial embedding outputs.\n     * @param {Tensor} [output.attentions] Attentions weights after the attention softmax, used to compute the weighted average in the self-attention heads.\n     */\n    constructor({ last_hidden_state, hidden_states = null, attentions = null }) {\n        super();\n        this.last_hidden_state = last_hidden_state;\n        this.hidden_states = hidden_states;\n        this.attentions = attentions;\n    }\n}\n//////////////////////////////////////////////////\n// Bert models\nexport class BertPreTrainedModel extends PreTrainedModel { }\nexport class BertModel extends BertPreTrainedModel { }\n\n/**\n * BertForMaskedLM is a class representing a BERT model for masked language modeling.\n * @extends BertPreTrainedModel\n */\nexport class BertForMaskedLM extends BertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<MaskedLMOutput>} An object containing the model's output logits for masked language modeling.\n     */\n    async _call(model_inputs) {\n        return new MaskedLMOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * BertForSequenceClassification is a class representing a BERT model for sequence classification.\n * @extends BertPreTrainedModel\n */\nexport class BertForSequenceClassification extends BertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.\n     */\n    async _call(model_inputs) {\n        return new SequenceClassifierOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * BertForTokenClassification is a class representing a BERT model for token classification.\n * @extends BertPreTrainedModel\n */\nexport class BertForTokenClassification extends BertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.\n     */\n    async _call(model_inputs) {\n        return new TokenClassifierOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * BertForQuestionAnswering is a class representing a BERT model for question answering.\n * @extends BertPreTrainedModel\n */\nexport class BertForQuestionAnswering extends BertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<QuestionAnsweringModelOutput>} An object containing the model's output logits for question answering.\n     */\n    async _call(model_inputs) {\n        return new QuestionAnsweringModelOutput(await super._call(model_inputs));\n    }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// DistilBert models\nexport class DistilBertPreTrainedModel extends PreTrainedModel { }\nexport class DistilBertModel extends DistilBertPreTrainedModel { }\n\n/**\n * DistilBertForSequenceClassification is a class representing a DistilBERT model for sequence classification.\n * @extends DistilBertPreTrainedModel\n */\nexport class DistilBertForSequenceClassification extends DistilBertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.\n     */\n    async _call(model_inputs) {\n        return new SequenceClassifierOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * DistilBertForTokenClassification is a class representing a DistilBERT model for token classification.\n * @extends DistilBertPreTrainedModel\n */\nexport class DistilBertForTokenClassification extends DistilBertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.\n     */\n    async _call(model_inputs) {\n        return new TokenClassifierOutput(await super._call(model_inputs));\n    }\n}\n\n\n/**\n * DistilBertForQuestionAnswering is a class representing a DistilBERT model for question answering.\n * @extends DistilBertPreTrainedModel\n */\nexport class DistilBertForQuestionAnswering extends DistilBertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<QuestionAnsweringModelOutput>} An object containing the model's output logits for question answering.\n     */\n    async _call(model_inputs) {\n        return new QuestionAnsweringModelOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * DistilBertForMaskedLM is a class representing a DistilBERT model for masking task.\n * @extends DistilBertPreTrainedModel\n */\nexport class DistilBertForMaskedLM extends DistilBertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<MaskedLMOutput>} returned object\n     */\n    async _call(model_inputs) {\n        return new MaskedLMOutput(await super._call(model_inputs));\n    }\n}\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\n// MobileBert models\nexport class MobileBertPreTrainedModel extends PreTrainedModel { }\nexport class MobileBertModel extends MobileBertPreTrainedModel { }\n\n/**\n * MobileBertForMaskedLM is a class representing a MobileBERT model for masking task.\n * @extends MobileBertPreTrainedModel\n */\nexport class MobileBertForMaskedLM extends MobileBertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<MaskedLMOutput>} returned object\n     */\n    async _call(model_inputs) {\n        return new MaskedLMOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * @extends MobileBertPreTrainedModel\n */\nexport class MobileBertForSequenceClassification extends MobileBertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<SequenceClassifierOutput>} returned object\n     */\n    async _call(model_inputs) {\n        return new SequenceClassifierOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * @extends MobileBertPreTrainedModel\n */\nexport class MobileBertForQuestionAnswering extends MobileBertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<QuestionAnsweringModelOutput>} returned object\n     */\n    async _call(model_inputs) {\n        return new QuestionAnsweringModelOutput(await super._call(model_inputs));\n    }\n}\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\n// SqueezeBert models\nexport class SqueezeBertPreTrainedModel extends PreTrainedModel { }\nexport class SqueezeBertModel extends SqueezeBertPreTrainedModel { }\nexport class SqueezeBertForMaskedLM extends SqueezeBertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<MaskedLMOutput>} returned object\n     */\n    async _call(model_inputs) {\n        return new MaskedLMOutput(await super._call(model_inputs));\n    }\n}\nexport class SqueezeBertForSequenceClassification extends SqueezeBertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<SequenceClassifierOutput>} returned object\n     */\n    async _call(model_inputs) {\n        return new SequenceClassifierOutput(await super._call(model_inputs));\n    }\n}\nexport class SqueezeBertForQuestionAnswering extends SqueezeBertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<QuestionAnsweringModelOutput>} returned object\n     */\n    async _call(model_inputs) {\n        return new QuestionAnsweringModelOutput(await super._call(model_inputs));\n    }\n}\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\n// Albert models\nexport class AlbertPreTrainedModel extends PreTrainedModel { }\nexport class AlbertModel extends AlbertPreTrainedModel { }\nexport class AlbertForSequenceClassification extends AlbertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<SequenceClassifierOutput>} returned object\n     */\n    async _call(model_inputs) {\n        return new SequenceClassifierOutput(await super._call(model_inputs));\n    }\n}\nexport class AlbertForQuestionAnswering extends AlbertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<QuestionAnsweringModelOutput>} returned object\n     */\n    async _call(model_inputs) {\n        return new QuestionAnsweringModelOutput(await super._call(model_inputs));\n    }\n}\nexport class AlbertForMaskedLM extends AlbertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<MaskedLMOutput>} returned object\n     */\n    async _call(model_inputs) {\n        return new MaskedLMOutput(await super._call(model_inputs));\n    }\n}\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\n// T5 models\nexport class T5PreTrainedModel extends PreTrainedModel { };\n\nexport class T5Model extends T5PreTrainedModel {\n    /**\n     * Generates text based on the provided arguments.\n     * @throws {Error} Throws an error as the current model class (T5Model) is not compatible with `.generate()`.\n     * @returns {Promise<any>}\n     * @param {any[]} args\n     */\n    async generate(...args) {\n        throw Error(\n            \"The current model class (T5Model) is not compatible with `.generate()`, as it doesn't have a language model head. Please use one of the following classes instead: {'T5ForConditionalGeneration'}\"\n        )\n    }\n}\n\n/**\n * T5Model is a class representing a T5 model for conditional generation.\n * @extends T5PreTrainedModel\n */\nexport class T5ForConditionalGeneration extends T5PreTrainedModel {\n\n    /**\n     * Creates a new instance of the `T5ForConditionalGeneration` class.\n     * @param {Object} config The model configuration.\n     * @param {any} session session for the model.\n     * @param {any} decoder_merged_session session for the decoder.\n     * @param {GenerationConfig} generation_config The generation configuration.\n     */\n    constructor(config, session, decoder_merged_session, generation_config) {\n        super(config, session);\n        this.decoder_merged_session = decoder_merged_session;\n        this.generation_config = generation_config;\n\n        this.num_decoder_layers = this.config.num_decoder_layers;\n        this.num_decoder_heads = this.config.num_heads;\n        this.decoder_dim_kv = this.config.d_kv;\n\n        this.num_encoder_layers = this.config.num_layers;\n        this.num_encoder_heads = this.config.num_heads;\n        this.encoder_dim_kv = this.config.d_kv;\n    }\n\n    /**\n     * Generates the start beams for a given set of inputs and output length.\n     * @param {number[][]} inputs The input token IDs.\n     * @param {number} numOutputTokens The desired output length.\n     * @returns {Array} The start beams.\n     */\n    getStartBeams(inputs, numOutputTokens, ...args) {\n        return seq2seqStartBeams(this, inputs, numOutputTokens);\n    }\n\n    /**\n     * Runs a single step of the beam search generation algorithm.\n     * @param {any} beam The current beam being generated.\n     * @returns {Promise<any>} The updated beam after a single generation step.\n     */\n    async runBeam(beam) {\n        return await seq2seqRunBeam(this, beam);\n    }\n\n    /**\n     * Updates the given beam with a new token ID.\n     * @param {any} beam The current beam.\n     * @param {number} newTokenId The new token ID to add to the output sequence.\n     */\n    updateBeam(beam, newTokenId) {\n        beam.output_token_ids = [...beam.output_token_ids, newTokenId];\n    }\n\n    /**\n     * Runs the forward pass of the model for a given set of inputs.\n     * @param {Object} model_inputs The model inputs.\n     * @returns {Promise<Object>} The model output.\n     */\n    async forward(model_inputs) {\n        return await seq2seqForward(this, model_inputs);\n    }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// MT5 models\nexport class MT5PreTrainedModel extends PreTrainedModel { };\n\nexport class MT5Model extends MT5PreTrainedModel {\n    /**\n     * \n     * @param  {...any} args\n     * @returns {Promise<any>}\n     * @throws {Error}\n     */\n    async generate(...args) {\n        throw Error(\n            \"The current model class (MT5Model) is not compatible with `.generate()`, as it doesn't have a language model head. Please use one of the following classes instead: {'MT5ForConditionalGeneration'}\"\n        )\n    }\n}\n\n/**\n * A class representing a conditional sequence-to-sequence model based on the MT5 architecture.\n *\n * @extends MT5PreTrainedModel\n */\nexport class MT5ForConditionalGeneration extends MT5PreTrainedModel {\n\n    /**\n     * Creates a new instance of the `MT5ForConditionalGeneration` class.\n     * @param {any} config The model configuration.\n     * @param {any} session The ONNX session containing the encoder weights.\n     * @param {any} decoder_merged_session The ONNX session containing the merged decoder weights.\n     * @param {GenerationConfig} generation_config The generation configuration.\n     */\n    constructor(config, session, decoder_merged_session, generation_config) {\n        super(config, session);\n        this.decoder_merged_session = decoder_merged_session;\n        this.generation_config = generation_config;\n\n        this.num_decoder_layers = this.config.num_decoder_layers;\n        this.num_decoder_heads = this.config.num_heads;\n        this.decoder_dim_kv = this.config.d_kv;\n\n        this.num_encoder_layers = this.config.num_layers;\n        this.num_encoder_heads = this.config.num_heads;\n        this.encoder_dim_kv = this.config.d_kv;\n    }\n\n    /**\n   * Generates the start beams for the given input tokens and output sequence length.\n   *\n   * @param {any[]} inputs The input sequence.\n   * @param {number} numOutputTokens The desired length of the output sequence.\n   * @param {...*} args Additional arguments to pass to the `seq2seqStartBeams` function.\n   * @returns {any[]} An array of `Beam` objects representing the start beams.\n   */\n    getStartBeams(inputs, numOutputTokens, ...args) {\n        return seq2seqStartBeams(this, inputs, numOutputTokens);\n    }\n\n    /**\n     * Runs a single step of the beam search generation algorithm.\n     * @param {any} beam The current beam being generated.\n     * @returns {Promise<any>} The updated beam after a single generation step.\n     */\n    async runBeam(beam) {\n        return await seq2seqRunBeam(this, beam);\n    }\n\n    /**\n     * Updates the given beam with the new predicted token.\n     * @param {any} beam The beam to update.\n     * @param {number} newTokenId The index of the predicted token.\n    */\n    updateBeam(beam, newTokenId) {\n        beam.output_token_ids = [...beam.output_token_ids, newTokenId];\n    }\n\n    /**\n    * Runs the forward pass of the model on the given inputs.\n    * @param {any} model_inputs The model inputs.\n    * @returns {Promise<any>} A Promise that resolves to the model outputs.\n    */\n    async forward(model_inputs) {\n        return await seq2seqForward(this, model_inputs);\n    }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// Bart models\nexport class BartPretrainedModel extends PreTrainedModel { };\n\n/**\n * BART encoder and decoder model.\n * \n * @hideconstructor\n * @extends BartPretrainedModel\n */\nexport class BartModel extends BartPretrainedModel {\n    /**\n     * Throws an error because the current model class (BartModel) is not compatible with `.generate()`.\n     * \n     * @throws {Error} The current model class (BartModel) is not compatible with `.generate()`.\n     * @returns {Promise<any>}\n     */\n    async generate(...args) {\n        throw Error(\n            \"The current model class (BartModel) is not compatible with `.generate()`, as it doesn't have a language model head. Please use one of the following classes instead: {'BartForConditionalGeneration'}\"\n        )\n    }\n}\n\n/**\n * BART model with a language model head for conditional generation.\n * @extends BartPretrainedModel\n */\nexport class BartForConditionalGeneration extends BartPretrainedModel {\n\n    /**\n     * Creates a new instance of the `BartForConditionalGeneration` class.\n     * @param {Object} config The configuration object for the Bart model.\n     * @param {Object} session The ONNX session used to execute the model.\n     * @param {Object} decoder_merged_session The ONNX session used to execute the decoder.\n     * @param {Object} generation_config The generation configuration object.\n     */\n    constructor(config, session, decoder_merged_session, generation_config) {\n        super(config, session);\n        this.decoder_merged_session = decoder_merged_session;\n        this.generation_config = generation_config;\n\n        this.num_decoder_layers = this.config.decoder_layers;\n        this.num_decoder_heads = this.config.decoder_attention_heads;\n        this.decoder_dim_kv = this.config.d_model / this.num_decoder_heads;\n\n        this.num_encoder_layers = this.config.encoder_layers;\n        this.num_encoder_heads = this.config.encoder_attention_heads;\n        this.encoder_dim_kv = this.config.d_model / this.num_encoder_heads;\n    }\n\n    /**\n     * Returns the initial beam for generating output text.\n     * @param {Object} inputs The input object containing the encoded input text.\n     * @param {number} numOutputTokens The maximum number of output tokens to generate.\n     * @param  {...any} args Additional arguments to pass to the sequence-to-sequence generation function.\n     * @returns {any} The initial beam for generating output text.\n     */\n    getStartBeams(inputs, numOutputTokens, ...args) {\n        return seq2seqStartBeams(this, inputs, numOutputTokens);\n    }\n\n    /**\n     * Runs a single step of the beam search generation algorithm.\n     * @param {any} beam The current beam being generated.\n     * @returns {Promise<any>} The updated beam after a single generation step.\n     */\n    async runBeam(beam) {\n        return await seq2seqRunBeam(this, beam);\n    }\n\n    /**\n     * Updates the beam by appending the newly generated token ID to the list of output token IDs.\n     * @param {any} beam The current beam being generated.\n     * @param {number} newTokenId The ID of the newly generated token to append to the list of output token IDs.\n     */\n    updateBeam(beam, newTokenId) {\n        beam.output_token_ids = [...beam.output_token_ids, newTokenId];\n    }\n\n    /**\n     * Runs the forward pass of the model for a given set of inputs.\n     * @param {Object} model_inputs The model inputs.\n     * @returns {Promise<Object>} The model output.\n     */\n    async forward(model_inputs) {\n        return await seq2seqForward(this, model_inputs);\n    }\n}\n\nexport class BartForSequenceClassification extends BartPretrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.\n     */\n    async _call(model_inputs) {\n        return new SequenceClassifierOutput(await super._call(model_inputs));\n    }\n}\n\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// Roberta models\nexport class RobertaPreTrainedModel extends PreTrainedModel { }\nexport class RobertaModel extends RobertaPreTrainedModel { }\n\n/**\n * RobertaForMaskedLM class for performing masked language modeling on Roberta models.\n * @extends RobertaPreTrainedModel\n */\nexport class RobertaForMaskedLM extends RobertaPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<MaskedLMOutput>} returned object\n     */\n    async _call(model_inputs) {\n        return new MaskedLMOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * RobertaForSequenceClassification class for performing sequence classification on Roberta models.\n * @extends RobertaPreTrainedModel\n */\nexport class RobertaForSequenceClassification extends RobertaPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<SequenceClassifierOutput>} returned object\n     */\n    async _call(model_inputs) {\n        return new SequenceClassifierOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * RobertaForQuestionAnswering class for performing question answering on Roberta models.\n * @extends RobertaPreTrainedModel\n */\nexport class RobertaForQuestionAnswering extends RobertaPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<QuestionAnsweringModelOutput>} returned object\n     */\n    async _call(model_inputs) {\n        return new QuestionAnsweringModelOutput(await super._call(model_inputs));\n    }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// T5 models\nexport class WhisperPreTrainedModel extends PreTrainedModel { };\n\n/**\n * WhisperModel class for training Whisper models without a language model head.\n * @extends WhisperPreTrainedModel\n */\nexport class WhisperModel extends WhisperPreTrainedModel {\n    /**\n     * Throws an error when attempting to generate output since this model doesn't have a language model head.\n     * @throws Error\n     * @returns {Promise<any>}\n     * @param {any[]} args\n     */\n    async generate(...args) {\n        throw Error(\n            \"The current model class (WhisperModel) is not compatible with `.generate()`, as it doesn't have a language model head. Please use one of the following classes instead: {'WhisperForConditionalGeneration'}\"\n        )\n    }\n}\n\n/**\n * WhisperForConditionalGeneration class for generating conditional outputs from Whisper models.\n * @extends WhisperPreTrainedModel\n */\nexport class WhisperForConditionalGeneration extends WhisperPreTrainedModel {\n\n    /**\n     * Creates a new instance of the `WhisperForConditionalGeneration` class.\n     * @param {Object} config Configuration object for the model.\n     * @param {Object} session ONNX Session object for the model.\n     * @param {Object} decoder_merged_session ONNX Session object for the decoder.\n     * @param {Object} generation_config Configuration object for the generation process.\n     */\n    constructor(config, session, decoder_merged_session, generation_config) {\n        super(config, session);\n        this.decoder_merged_session = decoder_merged_session;\n        this.generation_config = generation_config;\n\n        this.num_decoder_layers = this.config.decoder_layers;\n        this.num_decoder_heads = this.config.decoder_attention_heads;\n        this.decoder_dim_kv = this.config.d_model / this.num_decoder_heads;\n\n        this.num_encoder_layers = this.config.encoder_layers;\n        this.num_encoder_heads = this.config.encoder_attention_heads;\n        this.encoder_dim_kv = this.config.d_model / this.num_encoder_heads;\n\n\n    }\n\n    /**\n     * Generates outputs based on input and generation configuration.\n     * @param {Object} inputs Input data for the model.\n     * @param {Object} generation_config Configuration object for the generation process.\n     * @param {Object} logits_processor Optional logits processor object.\n     * @returns {Promise<Object>} Promise object represents the generated outputs.\n     */\n    async generate(\n        inputs,\n        generation_config = null,\n        logits_processor = null,\n    ) {\n        // Create generation config object\n        generation_config = this._get_generation_config(generation_config);\n\n\n        // Whisper has additional options for returning timestamps\n        generation_config.return_timestamps ??= false;\n\n        // TODO add language and task\n\n        if (generation_config.return_timestamps) {\n            logits_processor = [new WhisperTimeStampLogitsProcessor(generation_config)]\n        }\n\n        return super.generate(inputs, generation_config, logits_processor)\n    }\n\n    /**\n     * Gets the start beams for generating outputs.\n     * @param {Array} inputTokenIds Array of input token IDs.\n     * @param {number} numOutputTokens Number of output tokens to generate.\n     * @returns {Array} Array of start beams.\n     */\n    getStartBeams(inputTokenIds, numOutputTokens, ...args) {\n        // arguments ignored in this case\n        return seq2seqStartBeams(this, inputTokenIds, numOutputTokens, false);\n    }\n\n    /**\n     * Runs a single step of the beam search generation algorithm.\n     * @param {any} beam The current beam being generated.\n     * @returns {Promise<any>} The updated beam after a single generation step.\n     */\n    async runBeam(beam) {\n        return await seq2seqRunBeam(this, beam, {\n            input_name: 'input_features',\n        });\n    }\n\n    /**\n     * Updates the beam by appending the newly generated token ID to the list of output token IDs.\n     * @param {any} beam The current beam being generated.\n     * @param {number} newTokenId The ID of the newly generated token to append to the list of output token IDs.\n     */\n    updateBeam(beam, newTokenId) {\n        beam.output_token_ids = [...beam.output_token_ids, newTokenId];\n    }\n\n    /**\n     * Runs the forward pass of the model for a given set of inputs.\n     * @param {Object} model_inputs The model inputs.\n     * @returns {Promise<Object>} The model output.\n     */\n    async forward(model_inputs) {\n        return await seq2seqForward(this, model_inputs);\n    }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n/**\n * Vision Encoder-Decoder model based on OpenAI's GPT architecture for image captioning and other vision tasks\n * @extends PreTrainedModel\n */\nexport class VisionEncoderDecoderModel extends PreTrainedModel {\n    /**\n     * Creates a new instance of the `VisionEncoderDecoderModel` class.\n     * @param {Object} config The configuration object specifying the hyperparameters and other model settings.\n     * @param {Object} session The ONNX session containing the encoder model.\n     * @param {any} decoder_merged_session The ONNX session containing the merged decoder model.\n     */\n    constructor(config, session, decoder_merged_session) {\n        super(config, session);\n        this.decoder_merged_session = decoder_merged_session;\n\n        this.num_layers = this.config.decoder.n_layer;\n        this.num_heads = this.config.decoder.n_head;\n        this.dim_kv = this.config.decoder.n_embd / this.num_heads;\n    }\n\n    /**\n     * Generate beam search outputs for the given input pixels and number of output tokens.\n     *\n     * @param {array} inputs The input pixels as a Tensor.\n     * @param {number} numOutputTokens The number of output tokens to generate.\n     * @param {...*} args Optional additional arguments to pass to seq2seqStartBeams.\n     * @returns {any} An array of Beam objects representing the top-K output sequences.\n     */\n    getStartBeams(inputs, numOutputTokens, ...args) {\n        return seq2seqStartBeams(this, inputs, numOutputTokens);\n    }\n\n    /**\n     * Runs a single step of the beam search generation algorithm.\n     * @param {any} beam The current beam being generated.\n     * @returns {Promise<any>} The updated beam after a single generation step.\n     */\n    async runBeam(beam) {\n        return seq2seqRunBeam(this, beam, {\n            input_name: 'pixel_values',\n        });\n    }\n\n    /**\n     * Update the given beam with the additional predicted token ID.\n     *\n     * @param {any} beam The current beam.\n     * @param {number} newTokenId The new predicted token ID to add to the beam's output sequence.\n     */\n    updateBeam(beam, newTokenId) {\n        beam.output_token_ids = [...beam.output_token_ids, newTokenId];\n    }\n\n    /**\n     * Compute the forward pass of the model on the given input tensors.\n     *\n     * @param {Object} model_inputs The input tensors as an object with keys 'pixel_values' and 'decoder_input_ids'.\n     * @returns {Promise<any>} The output tensor of the model.\n     */\n    async forward(model_inputs) {\n        return await seq2seqForward(this, model_inputs, {\n            add_decoder_pkv: false\n        })\n    }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// CLIP models\nexport class CLIPPreTrainedModel extends PreTrainedModel { }\nexport class CLIPModel extends CLIPPreTrainedModel {\n\n}\n\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// GPT2 models\nexport class GPT2PreTrainedModel extends PreTrainedModel {\n    /**\n     * Creates a new instance of the `GPT2PreTrainedModel` class.\n     * @param {Object} config The configuration of the model.\n     * @param {any} session The ONNX session containing the model weights.\n     */\n    constructor(config, session) {\n        super(config, session);\n\n        // config doesn't contain pad_token_id, so we assume it is the eos_token_id\n        this.config.pad_token_id = this.config.eos_token_id\n\n        this.num_heads = this.config.n_head\n        this.num_layers = this.config.n_layer\n        this.dim_kv = this.config.n_embd / this.num_heads;\n    }\n}\n\nexport class GPT2Model extends GPT2PreTrainedModel {\n\n    /**\n     * GPT2Model is not compatible with `.generate()`, as it doesn't have a language model head.\n     * @param  {...any} args \n     * @throws {Error}\n     * @returns {Promise<any>}\n     */\n    async generate(...args) {\n        throw Error(\n            \"The current model class (GPT2Model) is not compatible with `.generate()`, as it doesn't have a language model head. Please use one of the following classes instead: {'GPT2LMHeadModel'}\"\n        )\n    }\n}\n\n/**\n * GPT-2 language model head on top of the GPT-2 base model. This model is suitable for text generation tasks.\n * @extends GPT2PreTrainedModel\n */\nexport class GPT2LMHeadModel extends GPT2PreTrainedModel {\n\n    /**\n     * Initializes and returns the beam for text generation task\n     * @param {Tensor} inputTokenIds The input token ids.\n     * @param {number} numOutputTokens The number of tokens to be generated.\n     * @param {Tensor} inputs_attention_mask Optional input attention mask.\n     * @returns {any} A Beam object representing the initialized beam.\n     */\n    getStartBeams(inputTokenIds, numOutputTokens, inputs_attention_mask) {\n        return decoderStartBeams(this, inputTokenIds, numOutputTokens, inputs_attention_mask)\n    }\n\n    /**\n     * Runs a single step of the beam search generation algorithm.\n     * @param {any} beam The current beam being generated.\n     * @returns {Promise<any>} The updated beam after a single generation step.\n     */\n    async runBeam(beam) {\n        return await decoderRunBeam(this, beam);\n    }\n\n    /**\n     * Updates the given beam with the new generated token id.\n     * @param {any} beam The Beam object representing the beam.\n     * @param {number} newTokenId The new generated token id to be added to the beam.\n     */\n    updateBeam(beam, newTokenId) {\n        return decoderUpdatebeam(beam, newTokenId);\n    }\n\n    /**\n     * Forward pass for the model.\n     * @param {Object} model_inputs The inputs for the model.\n     * @returns {Promise<any>} The output tensor of the model.\n     */\n    async forward(model_inputs) {\n        return await decoderForward(this, model_inputs);\n    }\n\n}\n// export class GPT2ForSequenceClassification extends GPT2PreTrainedModel {\n// TODO\n// }\n//////////////////////////////////////////////////\nexport class GPTNeoPreTrainedModel extends PreTrainedModel {\n    /**\n     * Creates a new instance of the `GPTNeoPreTrainedModel` class.\n     * @param {Object} config The configuration of the model.\n     * @param {any} session The ONNX session containing the model weights.\n     */\n    constructor(config, session) {\n        super(config, session);\n\n        // config doesn't contain pad_token_id, so we assume it is the eos_token_id\n        this.config.pad_token_id = this.config.eos_token_id\n\n        this.num_heads = this.config.num_heads;\n        this.num_layers = this.config.num_layers;\n        this.dim_kv = this.config.hidden_size / this.num_heads;\n    }\n}\nexport class GPTNeoModel extends GPTNeoPreTrainedModel {\n    /**\n     * \n     * @param  {...any} args \n     * @throws {Error}\n     * @returns {Promise<any>}\n     */\n    async generate(...args) {\n        throw Error(\n            \"The current model class (GPTNeoModel) is not compatible with `.generate()`, as it doesn't have a language model head. Please use one of the following classes instead: {'GPTNeoForCausalLM'}\"\n        )\n    }\n}\n\nexport class GPTNeoForCausalLM extends GPTNeoPreTrainedModel {\n\n    /**\n     * Initializes and returns the beam for text generation task\n     * @param {Tensor} inputTokenIds The input token ids.\n     * @param {number} numOutputTokens The number of tokens to be generated.\n     * @param {Tensor} inputs_attention_mask Optional input attention mask.\n     * @returns {any} A Beam object representing the initialized beam.\n     */\n    getStartBeams(inputTokenIds, numOutputTokens, inputs_attention_mask) {\n        return decoderStartBeams(this, inputTokenIds, numOutputTokens, inputs_attention_mask)\n    }\n\n    /**\n     * Runs a single step of the beam search generation algorithm.\n     * @param {any} beam The current beam being generated.\n     * @returns {Promise<any>} The updated beam after a single generation step.\n     */\n    async runBeam(beam) {\n        return await decoderRunBeam(this, beam);\n    }\n\n    /**\n     * Updates the given beam with the new generated token id.\n     * @param {any} beam The Beam object representing the beam.\n     * @param {number} newTokenId The new generated token id to be added to the beam.\n     */\n    updateBeam(beam, newTokenId) {\n        return decoderUpdatebeam(beam, newTokenId);\n    }\n\n    /**\n     * Forward pass for the model.\n     * @param {Object} model_inputs The inputs for the model.\n     * @returns {Promise<any>} The output tensor of the model.\n     */\n    async forward(model_inputs) {\n        return await decoderForward(this, model_inputs);\n    }\n}\n\n//////////////////////////////////////////////////\n// CodeGen models\nexport class CodeGenPreTrainedModel extends PreTrainedModel {\n    /**\n     * Creates a new instance of the `CodeGenPreTrainedModel` class.\n    * @param {Object} config The model configuration object.\n    * @param {Object} session The ONNX session object.\n    */\n    constructor(config, session) {\n        super(config, session);\n\n        // config doesn't contain pad_token_id, so we assume it is the eos_token_id\n        this.config.pad_token_id = this.config.eos_token_id\n\n        this.num_heads = this.config.n_head\n        this.num_layers = this.config.n_layer\n        this.dim_kv = this.config.n_embd / this.num_heads;\n    }\n}\n/**\n * CodeGenModel is a class representing a code generation model without a language model head.\n * \n * @extends CodeGenPreTrainedModel\n */\nexport class CodeGenModel extends CodeGenPreTrainedModel {\n    /**\n     * Throws an error indicating that the current model class is not compatible with `.generate()`,\n     * as it doesn't have a language model head.\n     * \n     * @throws {Error} The current model class is not compatible with `.generate()`\n     * \n     * @param  {...any} args Arguments passed to the generate function\n     * @returns {Promise<any>}\n     */\n    async generate(...args) {\n        throw Error(\n            \"The current model class (CodeGenModel) is not compatible with `.generate()`, as it doesn't have a language model head. Please use one of the following classes instead: {'CodeGenForCausalLM'}\"\n        )\n    }\n}\n\n/**\n * CodeGenForCausalLM is a class that represents a code generation model based on the GPT-2 architecture. It extends the `CodeGenPreTrainedModel` class.\n * @extends CodeGenPreTrainedModel\n */\nexport class CodeGenForCausalLM extends CodeGenPreTrainedModel {\n\n    /**\n     * Initializes and returns the beam for text generation task\n     * @param {Tensor} inputTokenIds The input token ids.\n     * @param {number} numOutputTokens The number of tokens to be generated.\n     * @param {Tensor} inputs_attention_mask Optional input attention mask.\n     * @returns {any} A Beam object representing the initialized beam.\n     */\n    getStartBeams(inputTokenIds, numOutputTokens, inputs_attention_mask) {\n        return decoderStartBeams(this, inputTokenIds, numOutputTokens, inputs_attention_mask)\n    }\n\n    /**\n     * Runs a single step of the beam search generation algorithm.\n     * @param {any} beam The current beam being generated.\n     * @returns {Promise<any>} The updated beam after a single generation step.\n     */\n    async runBeam(beam) {\n        return await decoderRunBeam(this, beam);\n    }\n\n    /**\n     * Updates the given beam with the new generated token id.\n     * @param {any} beam The Beam object representing the beam.\n     * @param {number} newTokenId The new generated token id to be added to the beam.\n     */\n    updateBeam(beam, newTokenId) {\n        return decoderUpdatebeam(beam, newTokenId);\n    }\n\n    /**\n     * Forward pass for the model.\n     * @param {Object} model_inputs The inputs for the model.\n     * @returns {Promise<any>} The output tensor of the model.\n     */\n    async forward(model_inputs) {\n        return await decoderForward(this, model_inputs);\n    }\n\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\nexport class ViTPreTrainedModel extends PreTrainedModel { }\nexport class ViTForImageClassification extends ViTPreTrainedModel {\n    /**\n     * @param {any} model_inputs\n     */\n    async _call(model_inputs) {\n        return new SequenceClassifierOutput(await super._call(model_inputs));\n    }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\nexport class DetrPreTrainedModel extends PreTrainedModel { }\nexport class DetrForObjectDetection extends DetrPreTrainedModel {\n    /**\n     * @param {any} model_inputs\n     */\n    async _call(model_inputs) {\n        return new DetrObjectDetectionOutput(await super._call(model_inputs));\n    }\n}\n\nexport class DetrForSegmentation extends DetrPreTrainedModel {\n    /**\n     * Runs the model with the provided inputs\n     * @param {Object} model_inputs Model inputs\n     * @returns {Promise<DetrSegmentationOutput>} Object containing segmentation outputs\n     */\n    async _call(model_inputs) {\n        return new DetrSegmentationOutput(await super._call(model_inputs));\n    }\n}\n\nexport class DetrObjectDetectionOutput extends ModelOutput {\n    /**\n     * @param {Object} output The output of the model.\n     * @param {Tensor} output.logits Classification logits (including no-object) for all queries.\n     * @param {Tensor} output.pred_boxes Normalized boxes coordinates for all queries, represented as (center_x, center_y, width, height).\n     * These values are normalized in [0, 1], relative to the size of each individual image in the batch (disregarding possible padding).\n     */\n    constructor({ logits, pred_boxes }) {\n        super();\n        this.logits = logits;\n        this.pred_boxes = pred_boxes;\n    }\n}\n\nexport class DetrSegmentationOutput extends ModelOutput {\n    /**\n     * @param {Object} output The output of the model.\n     * @param {Tensor} output.logits The output logits of the model.\n     * @param {Tensor} output.pred_boxes Predicted boxes.\n     * @param {Tensor} output.pred_masks Predicted masks.\n     */\n    constructor({ logits, pred_boxes, pred_masks }) {\n        super();\n        this.logits = logits;\n        this.pred_boxes = pred_boxes;\n        this.pred_masks = pred_masks;\n    }\n}\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\nexport class SamPreTrainedModel extends PreTrainedModel { }\nexport class SamModel extends SamPreTrainedModel {\n    /**\n     * @param {Object} model_inputs\n     * @param {Tensor} model_inputs.pixel_values Pixel values as a Tensor with shape `(batch_size, num_channels, height, width)`.\n     * @param {Tensor} model_inputs.input_points Input 2D spatial points with shape `(batch_size, num_points, 2)`. This is used by the prompt encoder to encode the prompt.\n     * @todo Add support for `input_labels`, `input_boxes`, `input_masks`, and `image_embeddings`.\n     */\n    async _call(model_inputs) {\n        return new SamImageSegmentationOutput(await super._call(model_inputs));\n    }\n}\n\n\n/**\n * Base class for Segment-Anything model's output.\n */\nexport class SamImageSegmentationOutput extends ModelOutput {\n    /**\n     * @param {Object} output The output of the model.\n     * @param {Tensor} output.iou_scores The output logits of the model.\n     * @param {Tensor} output.pred_masks Predicted boxes.\n     */\n    constructor({ iou_scores, pred_masks }) {\n        super();\n        this.iou_scores = iou_scores;\n        this.pred_masks = pred_masks;\n    }\n}\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\n// MarianMT models\nexport class MarianPreTrainedModel extends PreTrainedModel { };\n\nexport class MarianModel extends MarianPreTrainedModel {\n    /**\n     * \n     * @param  {...any} args \n     * @throws {Error}\n     * @returns {Promise<any>}\n     */\n    async generate(...args) {\n        throw Error(\n            \"The current model class (MarianModel) is not compatible with `.generate()`, as it doesn't have a language model head. Please use one of the following classes instead: {'MarianMTModel'}\"\n        )\n    }\n}\n\nexport class MarianMTModel extends MarianPreTrainedModel {\n\n    /**\n     * Creates a new instance of the `MarianMTModel` class.\n    * @param {Object} config The model configuration object.\n    * @param {Object} session The ONNX session object.\n    * @param {any} decoder_merged_session \n    * @param {any} generation_config \n    */\n    constructor(config, session, decoder_merged_session, generation_config) {\n        super(config, session);\n        this.decoder_merged_session = decoder_merged_session;\n        this.generation_config = generation_config;\n\n        this.num_decoder_layers = this.config.decoder_layers;\n        this.num_decoder_heads = this.config.decoder_attention_heads;\n        this.decoder_dim_kv = this.config.d_model / this.num_decoder_heads;\n\n        this.num_encoder_layers = this.config.encoder_layers;\n        this.num_encoder_heads = this.config.encoder_attention_heads;\n        this.encoder_dim_kv = this.config.d_model / this.num_encoder_heads;\n    }\n\n    /**\n     * Initializes and returns the beam for text generation task\n     * @param {any[]} inputs The input token ids.\n     * @param {number} numOutputTokens The number of tokens to be generated.\n     * @returns {any} A Beam object representing the initialized beam.\n     * @param {any[]} args\n     */\n    getStartBeams(inputs, numOutputTokens, ...args) {\n        return seq2seqStartBeams(this, inputs, numOutputTokens);\n    }\n\n    /**\n     * Runs a single step of the beam search generation algorithm.\n     * @param {any} beam The current beam being generated.\n     * @returns {Promise<any>} The updated beam after a single generation step.\n     */\n    async runBeam(beam) {\n        return await seq2seqRunBeam(this, beam);\n    }\n\n    /**\n     * @param {any} beam\n     * @param {any} newTokenId\n     */\n    updateBeam(beam, newTokenId) {\n        beam.output_token_ids = [...beam.output_token_ids, newTokenId];\n    }\n\n    /**\n     * @param {any} model_inputs\n     * @returns {Promise<Seq2SeqLMOutput>}\n     */\n    async forward(model_inputs) {\n        return await seq2seqForward(this, model_inputs);\n    }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// M2M100 models\nexport class M2M100PreTrainedModel extends PreTrainedModel { };\n\nexport class M2M100Model extends M2M100PreTrainedModel {\n    /**\n     * \n     * @param  {...any} args \n     * @throws {Error}\n     * @returns {Promise<any>}\n     */\n    async generate(...args) {\n        throw Error(\n            \"The current model class (M2M100Model) is not compatible with `.generate()`, as it doesn't have a language model head. Please use one of the following classes instead: {'M2M100ForConditionalGeneration'}\"\n        )\n    }\n}\n\nexport class M2M100ForConditionalGeneration extends M2M100PreTrainedModel {\n\n    /**\n     * Creates a new instance of the `M2M100ForConditionalGeneration` class.\n    * @param {Object} config The model configuration object.\n    * @param {Object} session The ONNX session object.\n    * @param {any} decoder_merged_session \n    * @param {any} generation_config \n    */\n    constructor(config, session, decoder_merged_session, generation_config) {\n        super(config, session);\n        this.decoder_merged_session = decoder_merged_session;\n        this.generation_config = generation_config;\n\n        this.num_decoder_layers = this.config.decoder_layers;\n        this.num_decoder_heads = this.config.decoder_attention_heads;\n        this.decoder_dim_kv = this.config.d_model / this.num_decoder_heads;\n\n        this.num_encoder_layers = this.config.encoder_layers;\n        this.num_encoder_heads = this.config.encoder_attention_heads;\n        this.encoder_dim_kv = this.config.d_model / this.num_encoder_heads;\n    }\n\n\n    /**\n     * Initializes and returns the beam for text generation task\n     * @param {any[]} inputs The input token ids.\n     * @param {number} numOutputTokens The number of tokens to be generated.\n     * @returns {any} A Beam object representing the initialized beam.\n     * @param {any[]} args\n     */\n    getStartBeams(inputs, numOutputTokens, ...args) {\n        return seq2seqStartBeams(this, inputs, numOutputTokens);\n    }\n\n    /**\n     * Runs a single step of the beam search generation algorithm.\n     * @param {any} beam The current beam being generated.\n     * @returns {Promise<any>} The updated beam after a single generation step.\n     */\n    async runBeam(beam) {\n        return await seq2seqRunBeam(this, beam);\n    }\n\n    /**\n     * @param {any} beam\n     * @param {any} newTokenId\n     */\n    updateBeam(beam, newTokenId) {\n        beam.output_token_ids = [...beam.output_token_ids, newTokenId];\n    }\n\n    /**\n     * @param {any} model_inputs\n     * @returns {Promise<Seq2SeqLMOutput>}\n     */\n    async forward(model_inputs) {\n        return await seq2seqForward(this, model_inputs);\n    }\n}\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\n// AutoModels, used to simplify construction of PreTrainedModels\n// (uses config to instantiate correct class)\n\n/**\n * Base class of all AutoModels. Contains the `from_pretrained` function\n * which is used to instantiate pretrained models.\n */\nexport class PretrainedMixin {\n    /**\n     * Mapping from model type to model class.\n     * @type {Map<string, Object>[]}\n     */\n    static MODEL_CLASS_MAPPINGS = null;\n\n    /**\n     * Whether to attempt to instantiate the base class (`PretrainedModel`) if \n     * the model type is not found in the mapping.\n     */\n    static BASE_IF_FAIL = false;\n\n\n    /** @type {PreTrainedModel.from_pretrained} */\n    static async from_pretrained(pretrained_model_name_or_path, {\n        quantized = true,\n        progress_callback = null,\n        config = null,\n        cache_dir = null,\n        local_files_only = false,\n        revision = 'main',\n    } = {}) {\n\n        let options = {\n            quantized,\n            progress_callback,\n            config,\n            cache_dir,\n            local_files_only,\n            revision,\n        }\n        config = await AutoConfig.from_pretrained(pretrained_model_name_or_path, options);\n\n        if (!this.MODEL_CLASS_MAPPINGS) {\n            throw new Error(\"`MODEL_CLASS_MAPPINGS` not implemented for this type of `AutoClass`: \" + this.name);\n        }\n\n        let modelClass;\n        for (let MODEL_CLASS_MAPPING of this.MODEL_CLASS_MAPPINGS) {\n            modelClass = MODEL_CLASS_MAPPING.get(config.model_type);\n            if (!modelClass) {\n                continue; // Item not found in this mapping\n            }\n\n            return await modelClass.from_pretrained(pretrained_model_name_or_path, options);\n        }\n\n        if (this.BASE_IF_FAIL) {\n            console.warn(`Unknown model class \"${config.model_type}\", attempting to construct from base class.`);\n            return await PreTrainedModel.from_pretrained(pretrained_model_name_or_path, options);\n        } else {\n            throw Error(`Unsupported model type: ${config.model_type}`)\n        }\n    }\n}\n\nconst MODEL_MAPPING_NAMES_ENCODER_ONLY = new Map([\n    ['bert', BertModel],\n    ['albert', AlbertModel],\n    ['distilbert', DistilBertModel],\n    ['roberta', RobertaModel],\n    ['clip', CLIPModel],\n    ['mobilebert', MobileBertModel],\n    ['squeezebert', SqueezeBertModel],\n\n    ['sam', SamModel], // TODO change to encoder-decoder when model is split correctly\n]);\n\nconst MODEL_MAPPING_NAMES_ENCODER_DECODER = new Map([\n    ['t5', T5Model],\n    ['mt5', MT5Model],\n    ['bart', BartModel],\n    ['marian', MarianModel],\n    ['whisper', WhisperModel],\n    ['m2m_100', M2M100Model],\n]);\n\n\nconst MODEL_MAPPING_NAMES_DECODER_ONLY = new Map([\n    ['gpt2', GPT2Model],\n    ['gpt_neo', GPTNeoModel],\n    ['codegen', CodeGenModel],\n]);\n\nconst MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING_NAMES = new Map([\n    ['bert', BertForSequenceClassification],\n    ['albert', AlbertForSequenceClassification],\n    ['distilbert', DistilBertForSequenceClassification],\n    ['roberta', RobertaForSequenceClassification],\n    ['bart', BartForSequenceClassification],\n    ['mobilebert', MobileBertForSequenceClassification],\n    ['squeezebert', SqueezeBertForSequenceClassification],\n]);\n\nconst MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING_NAMES = new Map([\n    ['bert', BertForTokenClassification],\n    ['distilbert', DistilBertForTokenClassification],\n]);\n\nconst MODEL_FOR_SEQ_2_SEQ_MAPPING_NAMES = new Map([\n    ['t5', T5ForConditionalGeneration],\n    ['mt5', MT5ForConditionalGeneration],\n    ['bart', BartForConditionalGeneration],\n    ['whisper', WhisperForConditionalGeneration],\n    ['marian', MarianMTModel],\n    ['m2m_100', M2M100ForConditionalGeneration],\n]);\n\nconst MODEL_WITH_LM_HEAD_MAPPING_NAMES = new Map([\n    ['gpt2', GPT2LMHeadModel],\n    ['gpt_neo', GPTNeoForCausalLM],\n    ['codegen', CodeGenForCausalLM],\n]);\n\nconst MODEL_FOR_MASKED_LM_MAPPING_NAMES = new Map([\n    ['bert', BertForMaskedLM],\n    ['albert', AlbertForMaskedLM],\n    ['distilbert', DistilBertForMaskedLM],\n    ['roberta', RobertaForMaskedLM],\n    ['mobilebert', MobileBertForMaskedLM],\n    ['squeezebert', SqueezeBertForMaskedLM],\n]);\n\nconst MODEL_FOR_QUESTION_ANSWERING_MAPPING_NAMES = new Map([\n    ['bert', BertForQuestionAnswering],\n    ['albert', AlbertForQuestionAnswering],\n    ['distilbert', DistilBertForQuestionAnswering],\n    ['roberta', RobertaForQuestionAnswering],\n    ['mobilebert', MobileBertForQuestionAnswering],\n    ['squeezebert', SqueezeBertForQuestionAnswering],\n]);\n\nconst MODEL_FOR_VISION_2_SEQ_MAPPING_NAMES = new Map([\n    ['vision-encoder-decoder', VisionEncoderDecoderModel],\n]);\n\nconst MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING_NAMES = new Map([\n    ['vit', ViTForImageClassification],\n]);\n\nconst MODEL_FOR_OBJECT_DETECTION_MAPPING_NAMES = new Map([\n    ['detr', DetrForObjectDetection],\n]);\n\nconst MODEL_FOR_IMAGE_SEGMENTATION_MAPPING_NAMES = new Map([\n    ['detr', DetrForSegmentation],\n]);\n\nconst MODEL_FOR_MASK_GENERATION_MAPPING_NAMES = new Map([\n    ['sam', SamModel],\n]);\n\nconst MODEL_CLASS_TYPE_MAPPING = [\n    [MODEL_MAPPING_NAMES_ENCODER_ONLY, EncoderOnlyModelType],\n    [MODEL_MAPPING_NAMES_ENCODER_DECODER, EncoderDecoderModelType],\n    [MODEL_MAPPING_NAMES_DECODER_ONLY, DecoderOnlyModelType],\n    [MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING_NAMES, EncoderOnlyModelType],\n    [MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING_NAMES, EncoderOnlyModelType],\n    [MODEL_FOR_SEQ_2_SEQ_MAPPING_NAMES, Seq2SeqModelType],\n    [MODEL_WITH_LM_HEAD_MAPPING_NAMES, DecoderOnlyModelType],\n    [MODEL_FOR_MASKED_LM_MAPPING_NAMES, EncoderOnlyModelType],\n    [MODEL_FOR_QUESTION_ANSWERING_MAPPING_NAMES, EncoderOnlyModelType],\n    [MODEL_FOR_VISION_2_SEQ_MAPPING_NAMES, EncoderDecoderModelType],\n    [MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING_NAMES, EncoderOnlyModelType],\n    [MODEL_FOR_IMAGE_SEGMENTATION_MAPPING_NAMES, EncoderOnlyModelType],\n    [MODEL_FOR_OBJECT_DETECTION_MAPPING_NAMES, EncoderOnlyModelType],\n    [MODEL_FOR_MASK_GENERATION_MAPPING_NAMES, EncoderOnlyModelType],\n];\n\nfor (let [mappings, type] of MODEL_CLASS_TYPE_MAPPING) {\n    // @ts-ignore\n    for (let [name, model] of mappings.entries()) {\n        MODEL_TYPE_MAPPING.set(model.name, type);\n        MODEL_CLASS_MAPPING.set(model.name, name);\n    }\n}\n\n/**\n * Helper class which is used to instantiate pretrained models with the `from_pretrained` function.\n * The chosen model class is determined by the type specified in the model config.\n * \n * @example\n * let model = await AutoModel.from_pretrained('bert-base-uncased');\n */\nexport class AutoModel extends PretrainedMixin {\n    static MODEL_CLASS_MAPPINGS = [MODEL_MAPPING_NAMES_ENCODER_ONLY, MODEL_MAPPING_NAMES_ENCODER_DECODER, MODEL_MAPPING_NAMES_DECODER_ONLY];\n    static BASE_IF_FAIL = true;\n}\n\n/**\n * Helper class which is used to instantiate pretrained sequence classification models with the `from_pretrained` function.\n * The chosen model class is determined by the type specified in the model config.\n * \n * @example\n * let model = await AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased-finetuned-sst-2-english');\n */\nexport class AutoModelForSequenceClassification extends PretrainedMixin {\n    static MODEL_CLASS_MAPPINGS = [MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING_NAMES];\n}\n\n/**\n * Helper class which is used to instantiate pretrained token classification models with the `from_pretrained` function.\n * The chosen model class is determined by the type specified in the model config.\n * \n * @example\n * let model = await AutoModelForTokenClassification.from_pretrained('Davlan/distilbert-base-multilingual-cased-ner-hrl');\n */\nexport class AutoModelForTokenClassification extends PretrainedMixin {\n    static MODEL_CLASS_MAPPINGS = [MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING_NAMES];\n}\n\n/**\n * Helper class which is used to instantiate pretrained sequence-to-sequence models with the `from_pretrained` function.\n * The chosen model class is determined by the type specified in the model config.\n * \n * @example\n * let model = await AutoModelForSeq2SeqLM.from_pretrained('t5-small');\n */\nexport class AutoModelForSeq2SeqLM extends PretrainedMixin {\n    static MODEL_CLASS_MAPPINGS = [MODEL_FOR_SEQ_2_SEQ_MAPPING_NAMES];\n}\n\n/**\n * Helper class which is used to instantiate pretrained causal language models with the `from_pretrained` function.\n * The chosen model class is determined by the type specified in the model config.\n * \n * @example\n * let model = await AutoModelForCausalLM.from_pretrained('gpt2');\n */\nexport class AutoModelForCausalLM extends PretrainedMixin {\n    static MODEL_CLASS_MAPPINGS = [MODEL_WITH_LM_HEAD_MAPPING_NAMES];\n}\n\n/**\n * Helper class which is used to instantiate pretrained masked language models with the `from_pretrained` function.\n * The chosen model class is determined by the type specified in the model config.\n * \n * @example\n * let model = await AutoModelForMaskedLM.from_pretrained('bert-base-uncased');\n */\nexport class AutoModelForMaskedLM extends PretrainedMixin {\n    static MODEL_CLASS_MAPPINGS = [MODEL_FOR_MASKED_LM_MAPPING_NAMES];\n}\n\n/**\n * Helper class which is used to instantiate pretrained question answering models with the `from_pretrained` function.\n * The chosen model class is determined by the type specified in the model config.\n * \n * @example\n * let model = await AutoModelForQuestionAnswering.from_pretrained('distilbert-base-cased-distilled-squad');\n */\nexport class AutoModelForQuestionAnswering extends PretrainedMixin {\n    static MODEL_CLASS_MAPPINGS = [MODEL_FOR_QUESTION_ANSWERING_MAPPING_NAMES];\n}\n\n/**\n * Helper class which is used to instantiate pretrained vision-to-sequence models with the `from_pretrained` function.\n * The chosen model class is determined by the type specified in the model config.\n * \n * @example\n * let model = await AutoModelForVision2Seq.from_pretrained('nlpconnect/vit-gpt2-image-captioning');\n */\nexport class AutoModelForVision2Seq extends PretrainedMixin {\n    static MODEL_CLASS_MAPPINGS = [MODEL_FOR_VISION_2_SEQ_MAPPING_NAMES];\n}\n\n/**\n * Helper class which is used to instantiate pretrained image classification models with the `from_pretrained` function.\n * The chosen model class is determined by the type specified in the model config.\n * \n * @example\n * let model = await AutoModelForImageClassification.from_pretrained('google/vit-base-patch16-224');\n */\nexport class AutoModelForImageClassification extends PretrainedMixin {\n    static MODEL_CLASS_MAPPINGS = [MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING_NAMES];\n}\n\n/**\n * Helper class which is used to instantiate pretrained image segmentation models with the `from_pretrained` function.\n * The chosen model class is determined by the type specified in the model config.\n * \n * @example\n * let model = await AutoModelForImageSegmentation.from_pretrained('facebook/detr-resnet-50-panoptic');\n */\nexport class AutoModelForImageSegmentation extends PretrainedMixin {\n    static MODEL_CLASS_MAPPINGS = [MODEL_FOR_IMAGE_SEGMENTATION_MAPPING_NAMES];\n}\n\n/**\n * Helper class which is used to instantiate pretrained object detection models with the `from_pretrained` function.\n * The chosen model class is determined by the type specified in the model config.\n * \n * @example\n * let model = await AutoModelForObjectDetection.from_pretrained('facebook/detr-resnet-50');\n */\nexport class AutoModelForObjectDetection extends PretrainedMixin {\n    static MODEL_CLASS_MAPPINGS = [MODEL_FOR_OBJECT_DETECTION_MAPPING_NAMES];\n}\n\n/**\n * Helper class which is used to instantiate pretrained object detection models with the `from_pretrained` function.\n * The chosen model class is determined by the type specified in the model config.\n * \n * @example\n * let model = await AutoModelForMaskGeneration.from_pretrained('Xenova/sam-vit-base');\n */\nexport class AutoModelForMaskGeneration extends PretrainedMixin {\n    static MODEL_CLASS_MAPPINGS = [MODEL_FOR_MASK_GENERATION_MAPPING_NAMES];\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\nexport class Seq2SeqLMOutput extends ModelOutput {\n    /**\n     * @param {Object} output The output of the model.\n     * @param {Tensor} output.logits The output logits of the model.\n     * @param {Tensor} output.past_key_values An tensor of key/value pairs that represent the previous state of the model.\n     * @param {Tensor} output.encoder_outputs The output of the encoder in a sequence-to-sequence model.\n     */\n    constructor({ logits, past_key_values, encoder_outputs }) {\n        super();\n        this.logits = logits;\n        this.past_key_values = past_key_values;\n        this.encoder_outputs = encoder_outputs;\n    }\n}\n\n/**\n * Base class for outputs of sentence classification models.\n */\nexport class SequenceClassifierOutput extends ModelOutput {\n    /**\n     * @param {Object} output The output of the model.\n     * @param {Tensor} output.logits classification (or regression if config.num_labels==1) scores (before SoftMax).\n     */\n    constructor({ logits }) {\n        super();\n        this.logits = logits;\n    }\n}\n\n/**\n * Base class for outputs of token classification models.\n */\nexport class TokenClassifierOutput extends ModelOutput {\n    /**\n     * @param {Object} output The output of the model.\n     * @param {Tensor} output.logits Classification scores (before SoftMax).\n     */\n    constructor({ logits }) {\n        super();\n        this.logits = logits;\n    }\n}\n\n/**\n * Base class for masked language models outputs.\n */\nexport class MaskedLMOutput extends ModelOutput {\n    /**\n     * @param {Object} output The output of the model.\n     * @param {Tensor} output.logits Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).\n     */\n    constructor({ logits }) {\n        super();\n        this.logits = logits;\n    }\n}\n\n/**\n * Base class for outputs of question answering models.\n */\nexport class QuestionAnsweringModelOutput extends ModelOutput {\n    /**\n     * @param {Object} output The output of the model.\n     * @param {Tensor} output.start_logits Span-start scores (before SoftMax).\n     * @param {Tensor} output.end_logits Span-end scores (before SoftMax).\n     */\n    constructor({ start_logits, end_logits }) {\n        super();\n        this.start_logits = start_logits;\n        this.end_logits = end_logits;\n    }\n}\n\n\n/**\n * Base class for causal language model (or autoregressive) outputs.\n */\nexport class CausalLMOutputWithPast extends ModelOutput {\n    /**\n     * @param {Object} output The output of the model.\n     * @param {Tensor} output.logits Prediction scores of the language modeling head (scores for each vocabulary token before softmax).\n     * @param {Tensor} output.past_key_values Contains pre-computed hidden-states (key and values in the self-attention blocks)\n     * that can be used (see `past_key_values` input) to speed up sequential decoding.\n     */\n    constructor({ logits, past_key_values }) {\n        super();\n        this.logits = logits;\n        this.past_key_values = past_key_values;\n    }\n}"],"mappings":"AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,SACIA,UAAU,QACP,cAAc;AAErB,SACIC,QAAQ,EACRC,gBAAgB,EAChBC,YAAY,QACT,iBAAiB;AAExB,SACIC,YAAY,EACZC,YAAY,QACT,gBAAgB;AAEvB,SACIC,mBAAmB,EACnBC,gBAAgB,EAChBC,0BAA0B,EAC1BC,6BAA6B,EAC7BC,6BAA6B,EAC7BC,oCAAoC,EACpCC,+BAA+B,EAC/BC,4BAA4B,EAC5BC,gCAAgC,EAEhCC,OAAO,QACJ,uBAAuB;AAE9B,SACIC,MAAM,QACH,mBAAmB;AAE1B,SAASC,kBAAkB,EAAEC,IAAI,QAAQ,oBAAoB;AAC7D,MAAM;EAAEC,gBAAgB;EAAEH,MAAM,EAAEI;AAAW,CAAC,GAAGF,IAAI;;AAErD;AACA;AACA;;AAGA;AACA;AACA,MAAMG,SAAS,CAAC;AAAG;;AAEnB;AACA,MAAMC,oBAAoB,SAASD,SAAS,CAAC;AAAG;AAChD,MAAME,uBAAuB,SAASF,SAAS,CAAC;AAAG;AACnD,MAAMG,gBAAgB,SAASD,uBAAuB,CAAC;AAAG;AAC1D,MAAME,oBAAoB,SAASJ,SAAS,CAAC;AAAG;AAChD;;AAGA;AACA;;AAEA;AACA,MAAMK,kBAAkB,GAAG,IAAIC,GAAG,CAAC,CAAC;AACpC,MAAMC,mBAAmB,GAAG,IAAID,GAAG,CAAC,CAAC;;AAErC;AACA;AACA;AACA;AACA;AACA;AACA,eAAeE,OAAOA,CAACC,IAAI,EAAEC,YAAY,EAAE;EACvC,IAAIL,kBAAkB,CAACM,GAAG,CAACF,IAAI,CAACG,WAAW,CAACC,IAAI,CAAC,KAAKT,oBAAoB,EAAE;IACxE,OAAO,MAAMU,cAAc,CAACL,IAAI,EAAEC,YAAY,CAAC;EACnD,CAAC,MAAM;IACH,OAAO,MAAMK,cAAc,CAACN,IAAI,EAAEC,YAAY,CAAC;EACnD;AACJ;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAeM,gBAAgBA,CAACC,6BAA6B,EAAEC,QAAQ,EAAEC,OAAO,EAAE;EAC9E;EACA,IAAIC,aAAa,GAAI,QAAOF,QAAS,GAAEC,OAAO,CAACE,SAAS,GAAG,YAAY,GAAG,EAAG,OAAM;EACnF,IAAIC,MAAM,GAAG,MAAMvC,YAAY,CAACkC,6BAA6B,EAAEG,aAAa,EAAE,IAAI,EAAED,OAAO,CAAC;EAE5F,IAAI;IACA,OAAO,MAAMrB,gBAAgB,CAACyB,MAAM,CAACD,MAAM,EAAE;MACzC1B;IACJ,CAAC,CAAC;EACN,CAAC,CAAC,OAAO4B,GAAG,EAAE;IACV;IACA,IAAI5B,kBAAkB,CAAC6B,MAAM,KAAK,CAAC,IAAI7B,kBAAkB,CAAC,CAAC,CAAC,KAAK,MAAM,EAAE;MACrE,MAAM4B,GAAG;IACb;IAEAE,OAAO,CAACC,IAAI,CAACH,GAAG,CAAC;IACjBE,OAAO,CAACC,IAAI,CACR,oFAAoF,GACpF,8BACJ,CAAC;IACD,OAAO,MAAM7B,gBAAgB,CAACyB,MAAM,CAACD,MAAM,EAAE;MACzC1B,kBAAkB,EAAE,CAAC,MAAM;IAC/B,CAAC,CAAC;EACN;AACJ;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAegC,cAAcA,CAACC,OAAO,EAAEC,MAAM,EAAE;EAC3C;EACA,MAAMC,aAAa,GAAG,CAAC,CAAC;EACxB,MAAMC,aAAa,GAAG,EAAE;EACxB,KAAK,IAAIC,SAAS,IAAIJ,OAAO,CAACK,UAAU,EAAE;IACtC,IAAIJ,MAAM,CAACG,SAAS,CAAC,KAAKE,SAAS,EAAE;MACjCH,aAAa,CAACI,IAAI,CAACH,SAAS,CAAC;IACjC,CAAC,MAAM;MACHF,aAAa,CAACE,SAAS,CAAC,GAAGH,MAAM,CAACG,SAAS,CAAC;IAChD;EACJ;EACA,IAAID,aAAa,CAACP,MAAM,GAAG,CAAC,EAAE;IAC1B,MAAM,IAAIY,KAAK,CACV,4EAA2EL,aAAa,CAACM,IAAI,CAAC,IAAI,CAAE,GAAE,CAAC;EAChH;EAEA,MAAMC,iBAAiB,GAAGC,MAAM,CAACC,IAAI,CAACX,MAAM,CAAC,CAACL,MAAM;EACpD,MAAMiB,eAAe,GAAGb,OAAO,CAACK,UAAU,CAACT,MAAM;EACjD,IAAIc,iBAAiB,GAAGG,eAAe,EAAE;IACrC;IACA;IACA,IAAIC,OAAO,GAAGH,MAAM,CAACC,IAAI,CAACX,MAAM,CAAC,CAACc,MAAM,CAACX,SAAS,IAAI,CAACJ,OAAO,CAACK,UAAU,CAACW,QAAQ,CAACZ,SAAS,CAAC,CAAC;IAC9FP,OAAO,CAACC,IAAI,CAAE,2CAA0CY,iBAAkB,MAAKG,eAAgB,6CAA4CC,OAAO,CAACL,IAAI,CAAC,IAAI,CAAE,IAAG,CAAC;EACtK;EAEA,OAAOP,aAAa;AACxB;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAee,UAAUA,CAACjB,OAAO,EAAEC,MAAM,EAAE;EACvC,MAAMC,aAAa,GAAG,MAAMH,cAAc,CAACC,OAAO,EAAEC,MAAM,CAAC;EAC3D,IAAI;IACA,IAAIiB,MAAM,GAAG,MAAMlB,OAAO,CAACmB,GAAG,CAACjB,aAAa,CAAC;IAC7CgB,MAAM,GAAGE,cAAc,CAACF,MAAM,CAAC;IAC/B,OAAOA,MAAM;EACjB,CAAC,CAAC,OAAOG,CAAC,EAAE;IACR;IACAxB,OAAO,CAACyB,KAAK,CAAE,8CAA6CD,CAAE,IAAG,CAAC;IAClExB,OAAO,CAACyB,KAAK,CAAC,wBAAwB,EAAEpB,aAAa,CAAC;IACtD,MAAMmB,CAAC;EACX;AACJ;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,SAASD,cAAcA,CAACG,GAAG,EAAE;EACzB,KAAK,IAAIC,IAAI,IAAID,GAAG,EAAE;IAClB,IAAIA,GAAG,CAACC,IAAI,CAAC,YAAYtD,UAAU,EAAE;MACjCqD,GAAG,CAACC,IAAI,CAAC,GAAG,IAAI1D,MAAM,CAACyD,GAAG,CAACC,IAAI,CAAC,CAAC;IACrC;EACJ;EACA,OAAOD,GAAG;AACd;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASE,WAAWA,CAACC,KAAK,EAAE;EACxB,IAAIA,KAAK,YAAY5D,MAAM,EAAE;IACzB,OAAO4D,KAAK;EAChB;EACA;EACA,IAAIA,KAAK,CAAC9B,MAAM,KAAK,CAAC,EAAE;IACpB,MAAMY,KAAK,CAAC,yBAAyB,CAAC;EAC1C;EAEA,IAAImB,KAAK,CAACC,OAAO,CAACF,KAAK,CAAC,CAAC,CAAC,CAAC,EAAE;IACzB;IACA,IAAIA,KAAK,CAACG,IAAI,CAACC,CAAC,IAAIA,CAAC,CAAClC,MAAM,KAAK8B,KAAK,CAAC,CAAC,CAAC,CAAC9B,MAAM,CAAC,EAAE;MAC/C,MAAMY,KAAK,CAAC,4KAA4K,CAAC;IAC7L;IAEA,OAAO,IAAI1C,MAAM,CAAC,OAAO,EACrBiE,aAAa,CAACC,IAAI,CAACN,KAAK,CAACO,IAAI,CAAC,CAAC,CAACC,GAAG,CAACJ,CAAC,IAAIK,MAAM,CAACL,CAAC,CAAC,CAAC,CAAC,EACpD,CAACJ,KAAK,CAAC9B,MAAM,EAAE8B,KAAK,CAAC,CAAC,CAAC,CAAC9B,MAAM,CAClC,CAAC;EACL,CAAC,MAAM;IACH;IACA,OAAO,IAAI9B,MAAM,CAAC,OAAO,EACrBiE,aAAa,CAACC,IAAI,CAACN,KAAK,CAACQ,GAAG,CAACJ,CAAC,IAAIK,MAAM,CAACL,CAAC,CAAC,CAAC,CAAC,EAC7C,CAAC,CAAC,EAAEJ,KAAK,CAAC9B,MAAM,CACpB,CAAC;EACL;AACJ;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASwC,oBAAoBA,CAACxD,IAAI,EAAEyD,MAAM,EAAE;EAExC;EACA,IAAIC,YAAY,GAAG1D,IAAI,CAAC2D,MAAM,CAACD,YAAY,IAAI,IAAI;EACnD,IAAIE,YAAY,GAAG5D,IAAI,CAAC2D,MAAM,CAACC,YAAY,IAAI,IAAI;EACnD,IAAIxF,gBAAgB,CAACwF,YAAY,CAAC,EAAE;IAChCA,YAAY,GAAG,CAACA,YAAY,CAAC;EACjC;EAEA,IAAIC,sBAAsB,GAAGJ,MAAM,CAACK,OAAO,CAACJ,YAAY,CAAC,KAAK,CAAC,CAAC;EAChE,IAAIK,sCAAsC,GAAIH,YAAY,KAAK,IAAI,IAAK,CAACA,YAAY,CAACxB,QAAQ,CAACsB,YAAY,CAAC;EAE5G,IAAIG,sBAAsB,IAAIE,sCAAsC,EAAE;IAClE,IAAIC,IAAI,GAAGb,aAAa,CAACC,IAAI;IACzB;IACAK,MAAM,CAACO,IAAI,CAACV,GAAG,CAACJ,CAAC,IAAIA,CAAC,IAAIQ,YAAY,CAC1C,CAAC;IACD,OAAO,IAAIxE,MAAM,CAAC,OAAO,EAAE8E,IAAI,EAAEP,MAAM,CAACQ,IAAI,CAAC;EACjD,CAAC,MAAM;IACH,OAAO,IAAI/E,MAAM,CACb,OAAO,EACP,IAAIiE,aAAa,CAACM,MAAM,CAACO,IAAI,CAAChD,MAAM,CAAC,CAACkD,IAAI,CAAC,EAAE,CAAC,EAC9CT,MAAM,CAACQ,IACX,CAAC;EACL;AACJ;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,SAASE,UAAUA,CAACC,KAAK,EAAE;EACvB,OAAO,IAAIlF,MAAM,CAAC,MAAM,EAAE,CAACkF,KAAK,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;AAC3C;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAeC,cAAcA,CAACrE,IAAI,EAAEC,YAAY,EAExC;EAAA,IAF0C;IAC9CqE,eAAe,GAAG;EACtB,CAAC,GAAAC,SAAA,CAAAvD,MAAA,QAAAuD,SAAA,QAAA7C,SAAA,GAAA6C,SAAA,MAAG,CAAC,CAAC;EACF,IAAI;IAAEC,eAAe;IAAEC;EAAgB,CAAC,GAAGxE,YAAY;EAEvD,IAAI,CAACuE,eAAe,EAAE;IAClB;IACAA,eAAe,GAAG,CAAC,MAAMlE,cAAc,CAACN,IAAI,EAAEC,YAAY,CAAC,EAAEyE,iBAAiB;EAClF;EACA,IAAIC,YAAY,GAAG;IACfC,SAAS,EAAE3E,YAAY,CAAC4E,iBAAiB;IACzCC,qBAAqB,EAAEN,eAAe;IACtCO,gBAAgB,EAAEZ,UAAU,CAACM,eAAe,KAAK,IAAI;EACzD,CAAC;EAED,IAAIzE,IAAI,CAACgF,sBAAsB,CAACvD,UAAU,CAACW,QAAQ,CAAC,wBAAwB,CAAC,EAAE;IAC3EuC,YAAY,CAACM,sBAAsB,GAAGhF,YAAY,CAACiF,cAAc;EACrE;EACAlF,IAAI,CAACmF,gBAAgB,CAACR,YAAY,EAAEF,eAAe,EAAEH,eAAe,CAAC;EAErE,MAAMc,cAAc,GAAG,MAAM/C,UAAU,CAACrC,IAAI,CAACgF,sBAAsB,EAAEL,YAAY,CAAC;EAClF,IAAIU,MAAM,GAAGD,cAAc,CAACC,MAAM;EAClCZ,eAAe,GAAGzE,IAAI,CAACsF,gBAAgB,CAACF,cAAc,EAAEX,eAAe,CAAC;EACxE,OAAO,IAAIc,eAAe,CAAC;IAAEF,MAAM;IAAEZ,eAAe;IAAED;EAAgB,CAAC,CAAC;AAC5E;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASgB,iBAAiBA,CAACxF,IAAI,EAAEyF,aAAa,EAAEC,eAAe,EAAkC;EAAA,IAAhCC,uBAAuB,GAAApB,SAAA,CAAAvD,MAAA,QAAAuD,SAAA,QAAA7C,SAAA,GAAA6C,SAAA,MAAG,IAAI;EAC3F,IAAIqB,KAAK,GAAG,EAAE;EACd,IAAIC,MAAM,GAAG,CAAC;;EAEd;EACA,IAAIhB,iBAAiB,GAAG7E,IAAI,CAAC2D,MAAM,CAACmC,sBAAsB;EAC1D,IAAI,CAAC/C,KAAK,CAACC,OAAO,CAAC6B,iBAAiB,CAAC,EAAE;IACnCA,iBAAiB,GAAG,CAACA,iBAAiB,CAAC;EAC3C;EAEA,KAAK,IAAIpB,MAAM,IAAIgC,aAAa,EAAE;IAC9B;IACA;IACA;IACAhC,MAAM,CAACQ,IAAI,GAAG,CAAC,CAAC,EAAE,GAAGR,MAAM,CAACQ,IAAI,CAAC;;IAEjC;IACA,IAAI8B,KAAK,GAAG;MACR1E,MAAM,EAAEoC,MAAM;MACde,eAAe,EAAE,IAAI;MACrBC,eAAe,EAAE,IAAI;MAErBuB,gBAAgB,EAAEnB,iBAAiB;MACnCoB,IAAI,EAAE,KAAK;MACXC,KAAK,EAAE,CAAC;MACRC,EAAE,EAAEN,MAAM,EAAE,CAAC;IACjB,CAAC;;IAED,IAAIF,uBAAuB,EAAE;MACzBI,KAAK,CAACb,cAAc,GAAG1B,oBAAoB,CAACxD,IAAI,EAAEyD,MAAM,CAAC;IAC7D;IAEAmC,KAAK,CAACjE,IAAI,CAACoE,KAAK,CAAC;EACrB;EAEA,OAAOH,KAAK;AAChB;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAeQ,cAAcA,CAACpG,IAAI,EAAEqG,IAAI,EAGtC;EAAA,IAHwC;IACtCC,UAAU,GAAG;EACjB,CAAC,GAAA/B,SAAA,CAAAvD,MAAA,QAAAuD,SAAA,QAAA7C,SAAA,GAAA6C,SAAA,MAAG,CAAC,CAAC;EAEF;EACA,IAAItE,YAAY,GAAG;IACf,CAACqG,UAAU,GAAGD,IAAI,CAAChF,MAAM;IACzBwD,iBAAiB,EAAEhC,WAAW,CAACwD,IAAI,CAACL,gBAAgB,CAACO,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;IAC/D/B,eAAe,EAAE6B,IAAI,CAAC7B,eAAe;IACrCC,eAAe,EAAE4B,IAAI,CAAC5B;EAC1B,CAAC;EACD,IAAI4B,IAAI,CAACnB,cAAc,EAAE;IACrBjF,YAAY,CAACiF,cAAc,GAAGmB,IAAI,CAACnB,cAAc;EACrD;;EAEA;EACA,IAAI5C,MAAM,GAAG,MAAMtC,IAAI,CAACD,OAAO,CAACE,YAAY,CAAC;;EAE7C;EACAoG,IAAI,CAAC5B,eAAe,GAAGnC,MAAM,CAACmC,eAAe;EAC7C4B,IAAI,CAAC7B,eAAe,GAAGlC,MAAM,CAACkC,eAAe;EAE7C,OAAOlC,MAAM;AACjB;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAehC,cAAcA,CAACN,IAAI,EAAEC,YAAY,EAAE;EAC9C,IAAIuG,YAAY,GAAG,CAAC,CAAC;EACrB,KAAK,IAAIC,GAAG,IAAIzG,IAAI,CAACoB,OAAO,CAACK,UAAU,EAAE;IACrC+E,YAAY,CAACC,GAAG,CAAC,GAAGxG,YAAY,CAACwG,GAAG,CAAC;EACzC;EACA,OAAO,MAAMpE,UAAU,CAACrC,IAAI,CAACoB,OAAO,EAAEoF,YAAY,CAAC;AACvD;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAenG,cAAcA,CAACL,IAAI,EAAEC,YAAY,EAAE;EAC9C,IAAIwE,eAAe,GAAGxE,YAAY,CAACwE,eAAe;EAClD,IAAIE,YAAY,GAAG;IACfC,SAAS,EAAE3E,YAAY,CAAC2E,SAAS;IACjCM,cAAc,EAAEjF,YAAY,CAACiF,cAAc,IAAI1B,oBAAoB,CAACxD,IAAI,EAAEC,YAAY,CAAC2E,SAAS,CAAC;IACjGG,gBAAgB,EAAEZ,UAAU,CAACM,eAAe,KAAK,IAAI;EACzD,CAAC;EAEDzE,IAAI,CAACmF,gBAAgB,CAACR,YAAY,EAAEF,eAAe,CAAC;EAEpD,IAAIW,cAAc,GAAG,MAAM/C,UAAU,CAACrC,IAAI,CAACoB,OAAO,EAAEuD,YAAY,CAAC;EACjE,IAAIU,MAAM,GAAGD,cAAc,CAACC,MAAM;EAElCZ,eAAe,GAAGzE,IAAI,CAACsF,gBAAgB,CAACF,cAAc,EAAEX,eAAe,CAAC;EACxE,OAAO;IAAEY,MAAM;IAAEZ;EAAgB,CAAC;AACtC;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASiC,iBAAiBA,CAAC1G,IAAI,EAAEyF,aAAa,EAAEC,eAAe,EAAEiB,qBAAqB,EAAE;EACpF,IAAIf,KAAK,GAAG,EAAE;EAEd,IAAIC,MAAM,GAAG,CAAC;EACd,KAAK,IAAIpC,MAAM,IAAIgC,aAAa,EAAE;IAC9B;IACA;IACA;IACAhC,MAAM,CAACQ,IAAI,GAAG,CAAC,CAAC,EAAE,GAAGR,MAAM,CAACQ,IAAI,CAAC;IAEjC,IAAI2C,SAAS;IACb,IAAID,qBAAqB,EAAE;MACvBC,SAAS,GAAGD,qBAAqB,CAACd,MAAM,CAAC;MACzCe,SAAS,CAAC3C,IAAI,GAAG,CAAC,CAAC,EAAE,GAAG2C,SAAS,CAAC3C,IAAI,CAAC;IAE3C,CAAC,MAAM;MACH2C,SAAS,GAAGpD,oBAAoB,CAACxD,IAAI,EAAEyD,MAAM,CAAC;IAClD;IAEA,IAAIsC,KAAK,GAAG;MACRc,KAAK,EAAEpD,MAAM;MACbqD,eAAe,EAAErD,MAAM;MACvByB,cAAc,EAAE0B,SAAS;MACzBnC,eAAe,EAAE,IAAI;MAErBuB,gBAAgB,EAAE,EAAE;MACpBe,iBAAiB,EAAErB,eAAe;MAElCO,IAAI,EAAE,KAAK;MACXC,KAAK,EAAE,CAAC;MACRC,EAAE,EAAEN,MAAM,EAAE,CAAC;IACjB,CAAC;;IAEDD,KAAK,CAACjE,IAAI,CAACoE,KAAK,CAAC;EACrB;EACA,OAAOH,KAAK;AAChB;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAeoB,cAAcA,CAAChH,IAAI,EAAEqG,IAAI,EAAE;EACtC,IAAIY,YAAY,GAAG,IAAI9D,aAAa,CAACkD,IAAI,CAACQ,KAAK,CAAC7C,IAAI,CAAChD,MAAM,GAAGqF,IAAI,CAACL,gBAAgB,CAAChF,MAAM,CAAC,CAACkD,IAAI,CAAC,EAAE,CAAC;;EAEpG;EACA,IAAIjE,YAAY,GAAG;IACf2E,SAAS,EAAEyB,IAAI,CAACS,eAAe;IAC/B5B,cAAc,EAAE,IAAIhG,MAAM,CACtB,OAAO,EACP+H,YAAY,EACZ,CAAC,CAAC,EAAEA,YAAY,CAACjG,MAAM,CAC3B,CAAC;IACDyD,eAAe,EAAE4B,IAAI,CAAC5B;EAC1B,CAAC;;EAED;EACA,IAAInC,MAAM,GAAG,MAAMtC,IAAI,CAACD,OAAO,CAACE,YAAY,CAAC;;EAE7C;EACAoG,IAAI,CAAC5B,eAAe,GAAGnC,MAAM,CAACmC,eAAe;EAE7C,OAAOnC,MAAM;AACjB;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS4E,iBAAiBA,CAACb,IAAI,EAAEc,UAAU,EAAE;EACzCd,IAAI,CAACL,gBAAgB,GAAG,CAAC,GAAGK,IAAI,CAACL,gBAAgB,EAAEmB,UAAU,CAAC;EAC9Dd,IAAI,CAACS,eAAe,GAAG,IAAI5H,MAAM,CAAC,OAAO,EAAE,CAACqE,MAAM,CAAC4D,UAAU,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;AAC5E;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMC,eAAe,SAASjJ,QAAQ,CAAC;EAE1C;AACJ;AACA;AACA;AACA;EACIgC,WAAWA,CAACwD,MAAM,EAAEvC,OAAO,EAAE;IACzB,KAAK,CAAC,CAAC;IAEP,IAAI,CAACuC,MAAM,GAAGA,MAAM;IACpB,IAAI,CAACvC,OAAO,GAAGA,OAAO;EAC1B;;EAEA;AACJ;AACA;AACA;AACA;EACI,MAAMiG,OAAOA,CAAA,EAAG;IACZ,IAAIC,QAAQ,GAAG,EAAE;IACjB,KAAK,IAAIb,GAAG,IAAI1E,MAAM,CAACC,IAAI,CAAC,IAAI,CAAC,EAAE;MAC/B,IAAIuF,IAAI,GAAG,IAAI,CAACd,GAAG,CAAC;MACpB,IAAIc,IAAI,YAAYlI,gBAAgB,EAAE;QAClCiI,QAAQ,CAAC3F,IAAI,CAAC4F,IAAI,CAACC,OAAO,CAACH,OAAO,CAAC,CAAC,CAAC;MACzC;IACJ;IACA,OAAO,MAAMI,OAAO,CAACC,GAAG,CAACJ,QAAQ,CAAC;EACtC;;EAEA;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACI,aAAaK,eAAeA,CAACnH,6BAA6B,EAOlD;IAAA,IAPoD;MACxDI,SAAS,GAAG,IAAI;MAChBgH,iBAAiB,GAAG,IAAI;MACxBjE,MAAM,GAAG,IAAI;MACbkE,SAAS,GAAG,IAAI;MAChBC,gBAAgB,GAAG,KAAK;MACxBC,QAAQ,GAAG;IACf,CAAC,GAAAxD,SAAA,CAAAvD,MAAA,QAAAuD,SAAA,QAAA7C,SAAA,GAAA6C,SAAA,MAAG,CAAC,CAAC;IAEF,IAAI7D,OAAO,GAAG;MACVE,SAAS;MACTgH,iBAAiB;MACjBjE,MAAM;MACNkE,SAAS;MACTC,gBAAgB;MAChBC;IACJ,CAAC;IAED,IAAIC,SAAS,GAAGpI,kBAAkB,CAACM,GAAG,CAAC,IAAI,CAACE,IAAI,CAAC;IAEjD,IAAI6H,IAAI;IACR,IAAID,SAAS,KAAKrI,oBAAoB,EAAE;MACpCsI,IAAI,GAAG,MAAMR,OAAO,CAACC,GAAG,CAAC,CACrBxJ,UAAU,CAACyJ,eAAe,CAACnH,6BAA6B,EAAEE,OAAO,CAAC,EAClEH,gBAAgB,CAACC,6BAA6B,EAAE,sBAAsB,EAAEE,OAAO,CAAC,CACnF,CAAC;IAEN,CAAC,MAAM,IAAIsH,SAAS,KAAKtI,gBAAgB,EAAE;MACvCuI,IAAI,GAAG,MAAMR,OAAO,CAACC,GAAG,CAAC,CACrBxJ,UAAU,CAACyJ,eAAe,CAACnH,6BAA6B,EAAEE,OAAO,CAAC,EAClEH,gBAAgB,CAACC,6BAA6B,EAAE,eAAe,EAAEE,OAAO,CAAC,EACzEH,gBAAgB,CAACC,6BAA6B,EAAE,sBAAsB,EAAEE,OAAO,CAAC,EAChFnC,YAAY,CAACiC,6BAA6B,EAAE,wBAAwB,EAAE,KAAK,EAAEE,OAAO,CAAC,CACxF,CAAC;IAEN,CAAC,MAAM,IAAIsH,SAAS,KAAKvI,uBAAuB,EAAE;MAC9CwI,IAAI,GAAG,MAAMR,OAAO,CAACC,GAAG,CAAC,CACrBxJ,UAAU,CAACyJ,eAAe,CAACnH,6BAA6B,EAAEE,OAAO,CAAC,EAClEH,gBAAgB,CAACC,6BAA6B,EAAE,eAAe,EAAEE,OAAO,CAAC,EACzEH,gBAAgB,CAACC,6BAA6B,EAAE,sBAAsB,EAAEE,OAAO,CAAC,CACnF,CAAC;IAEN,CAAC,MAAM,IAAIsH,SAAS,KAAKxI,oBAAoB,EAAE;MAC3CyI,IAAI,GAAG,MAAMR,OAAO,CAACC,GAAG,CAAC,CACrBxJ,UAAU,CAACyJ,eAAe,CAACnH,6BAA6B,EAAEE,OAAO,CAAC,EAClEH,gBAAgB,CAACC,6BAA6B,EAAE,OAAO,EAAEE,OAAO,CAAC,CACpE,CAAC;IAEN,CAAC,MAAM;MACHO,OAAO,CAACC,IAAI,CAAC,6BAA6B,EAAE,IAAI,CAAC;MACjD,MAAMU,KAAK,CAAE,yBAAwBpB,6BAA8B,0FAAyF,CAAC;IACjK;;IAEA;IACA,OAAO,IAAI,IAAI,CAAC,GAAGyH,IAAI,CAAC;EAC5B;;EAEA;AACJ;AACA;AACA;AACA;EACI,MAAMC,KAAKA,CAACjI,YAAY,EAAE;IACtB,OAAO,MAAM,IAAI,CAACF,OAAO,CAACE,YAAY,CAAC;EAC3C;;EAEA;AACJ;AACA;AACA;AACA;AACA;AACA;EACI,MAAMF,OAAOA,CAACE,YAAY,EAAE;IACxB,OAAO,MAAMF,OAAO,CAAC,IAAI,EAAEE,YAAY,CAAC;EAC5C;;EAEA;AACJ;AACA;AACA;AACA;EACIkI,qBAAqBA,CACjBC,iBAAiB,EACjBC,oBAAoB,EAItB;IAAA,IADEC,gBAAgB,GAAA/D,SAAA,CAAAvD,MAAA,QAAAuD,SAAA,QAAA7C,SAAA,GAAA6C,SAAA,MAAG,IAAI;IAEvB,MAAMgE,UAAU,GAAG,IAAI/J,mBAAmB,CAAC,CAAC;;IAE5C;IACA;IACA;IACA;IACA;IACA;IACA;;IAEA;IACA;IACA;IACA;IACA;IACA;;IAEA,IAAI4J,iBAAiB,CAACI,kBAAkB,KAAK,IAAI,IAAIJ,iBAAiB,CAACI,kBAAkB,KAAK,GAAG,EAAE;MAC/FD,UAAU,CAAC5G,IAAI,CAAC,IAAI3C,gCAAgC,CAACoJ,iBAAiB,CAACI,kBAAkB,CAAC,CAAC;IAC/F;IAEA,IAAIJ,iBAAiB,CAACK,oBAAoB,KAAK,IAAI,IAAIL,iBAAiB,CAACK,oBAAoB,GAAG,CAAC,EAAE;MAC/FF,UAAU,CAAC5G,IAAI,CAAC,IAAI5C,4BAA4B,CAACqJ,iBAAiB,CAACK,oBAAoB,CAAC,CAAC;IAC7F;;IAEA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;;IAEA;IACA;IACA;;IAEA;IACA;IACA;;IAEA;IACA;IACA;IACA;IACA;IACA;IACA;;IAEA;IACA;IACA;IACA;IACA;IACA;;IAGA,IAAIL,iBAAiB,CAACM,mBAAmB,KAAK,IAAI,EAAE;MAChDH,UAAU,CAAC5G,IAAI,CAAC,IAAIhD,6BAA6B,CAACyJ,iBAAiB,CAACM,mBAAmB,CAAC,CAAC;IAC7F;IAEA,IAAIN,iBAAiB,CAACO,mBAAmB,KAAK,IAAI,EAAE;MAChDJ,UAAU,CAAC5G,IAAI,CAAC,IAAI/C,6BAA6B,CAC7CwJ,iBAAiB,CAACQ,UAAU,EAC5BR,iBAAiB,CAACO,mBACtB,CAAC,CAAC;IACN;;IAEA;IACA;IACA;;IAEA;IACA;IACA;IACA;IACA;IACA;IACA;;IAEA;IACA;IACA;;IAEA,IAAIP,iBAAiB,CAACS,qBAAqB,KAAK,IAAI,EAAE;MAClD,IAAIC,WAAW,GAAIT,oBAAoB,GAAG,CAAC,IAAID,iBAAiB,CAACM,mBAAmB,KAAK,IAAI,GACvFL,oBAAoB,GACpBA,oBAAoB,GAAG,CAAC;MAE9B,IAAID,iBAAiB,CAACW,kBAAkB,KAAK,IAAI,EAAE;QAC/C;QACAD,WAAW,IAAIV,iBAAiB,CAACW,kBAAkB,CAACX,iBAAiB,CAACW,kBAAkB,CAAC/H,MAAM,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC;MAC3G;MACAuH,UAAU,CAAC5G,IAAI,CAAC,IAAI9C,oCAAoC,CAACuJ,iBAAiB,CAACS,qBAAqB,EAAEC,WAAW,CAAC,CAAC;IACnH;IAEA,IAAIV,iBAAiB,CAACW,kBAAkB,KAAK,IAAI,EAAE;MAC/CR,UAAU,CAAC5G,IAAI,CAAC,IAAIjD,0BAA0B,CAAC0J,iBAAiB,CAACW,kBAAkB,CAAC,CAAC;IACzF;IAEA,IAAIT,gBAAgB,KAAK,IAAI,EAAE;MAC3BC,UAAU,CAACS,MAAM,CAACV,gBAAgB,CAAC;IACvC;;IAEA;IACA;IACA;IACA;;IAEA,OAAOC,UAAU;EACrB;;EAEA;AACJ;AACA;AACA;AACA;AACA;AACA;EACIU,sBAAsBA,CAACb,iBAAiB,EAAE;IACtC;IACA,IAAIc,UAAU,GAAG,IAAIzK,gBAAgB,CAAC,CAAC;;IAEvC;IACA,IAAI,mBAAmB,IAAI,IAAI,EAAE;MAC7BsD,MAAM,CAACoH,MAAM,CAACD,UAAU,EAAE,IAAI,CAACd,iBAAiB,CAAC;IACrD;;IAEA;IACA;IACA,IAAIA,iBAAiB,KAAK,IAAI,EAAE;MAC5BrG,MAAM,CAACoH,MAAM,CAACD,UAAU,EAAEd,iBAAiB,CAAC;IAChD;IACA,OAAOc,UAAU;EACrB;;EAEA;AACJ;AACA;;EAEI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACI,MAAME,QAAQA,CACV/H,MAAM,EAMR;IAAA,IALE+G,iBAAiB,GAAA7D,SAAA,CAAAvD,MAAA,QAAAuD,SAAA,QAAA7C,SAAA,GAAA6C,SAAA,MAAG,IAAI;IAAA,IACxB+D,gBAAgB,GAAA/D,SAAA,CAAAvD,MAAA,QAAAuD,SAAA,QAAA7C,SAAA,GAAA6C,SAAA,MAAG,IAAI;IAAA,IACvB;MACIoC,qBAAqB,GAAG;IAC5B,CAAC,GAAApC,SAAA,CAAAvD,MAAA,QAAAuD,SAAA,QAAA7C,SAAA,GAAA6C,SAAA,MAAG,CAAC,CAAC;IAGN,IAAI,EAAElD,MAAM,YAAYnC,MAAM,CAAC,IAAI,CAACb,YAAY,CAACgD,MAAM,CAAC,IAAI,CAAC0B,KAAK,CAACC,OAAO,CAAC3B,MAAM,CAAC,EAAE;MAChF,MAAMO,KAAK,CAAE,8DAA6DP,MAAM,CAAClB,WAAW,CAACC,IAAK,IAAG,CAAC;IAC1G;IAEA,IAAIiI,oBAAoB;;IAExB;IACA;IACA,IAAI,IAAI,CAAC1E,MAAM,CAAC0F,kBAAkB,EAAE;MAChC;MACAhB,oBAAoB,GAAG,CAAC;IAE5B,CAAC,MAAM;MACHA,oBAAoB,GAAGhH,MAAM,YAAYnC,MAAM,GAAGmC,MAAM,CAAC4C,IAAI,CAAC,CAAC,CAAC,GAAG5C,MAAM,CAACL,MAAM;;MAEhF;MACA,IAAIqH,oBAAoB,KAAK,CAAC,EAAE;QAC5B,MAAMzG,KAAK,CAAC,mDAAmD,CAAC;MACpE;IACJ;;IAEA;IACAwG,iBAAiB,GAAG,IAAI,CAACa,sBAAsB,CAACb,iBAAiB,CAAC;IAElEE,gBAAgB,GAAGA,gBAAgB,IAAI,IAAI9J,mBAAmB,CAAC,CAAC;;IAEhE;IACA8J,gBAAgB,GAAG,IAAI,CAACH,qBAAqB,CACzCC,iBAAiB,EACjBC,oBAAoB,EACpBC,gBACJ,CAAC;;IAED;IACA;;IAEA,IAAI5C,eAAe,GAAG,CAAC;IACvB,MAAM4D,eAAe,GAAG5D,eAAe,IAAI0C,iBAAiB,CAACmB,cAAc,IAAIC,QAAQ,CAAC;;IAExF;IACA,MAAMC,YAAY,GAAGC,MAAM,CAACC,SAAS,CAACvB,iBAAiB,CAACQ,UAAU,CAAC,IAAI,CAACR,iBAAiB,CAACmB,cAAc,IAAI,IAAI,MAAM,IAAI;IAC1H,IAAIK,OAAO,GAAG3K,OAAO,CAAC4K,UAAU,CAACzB,iBAAiB,CAAC;;IAEnD;IACA,IAAIxC,KAAK,GAAG,IAAI,CAACkE,aAAa,CAACzI,MAAM,EAAEqE,eAAe,EAAEiB,qBAAqB,CAAC;IAE9E,OAAOf,KAAK,CAAC3C,IAAI,CAACC,CAAC,IAAI,CAACA,CAAC,CAAC+C,IAAI,CAAC,IAAIP,eAAe,GAAG4D,eAAe,EAAE;MAClE,IAAIS,YAAY,GAAG,EAAE;MACrB,KAAK,IAAI1D,IAAI,IAAIT,KAAK,EAAE;QACpB,IAAIS,IAAI,CAACJ,IAAI,EAAE;UACX;UACA8D,YAAY,CAACpI,IAAI,CAAC0E,IAAI,CAAC;UACvB;QACJ;QACA,IAAIoD,YAAY,IAAIpD,IAAI,CAACL,gBAAgB,CAAChF,MAAM,IAAIoH,iBAAiB,CAACQ,UAAU,EAAE;UAC9E;UACAvC,IAAI,CAACJ,IAAI,GAAG,IAAI;UAChB8D,YAAY,CAACpI,IAAI,CAAC0E,IAAI,CAAC;UACvB;QACJ;;QAEA;QACA,IAAI/D,MAAM,GAAG,MAAM,IAAI,CAAC0H,OAAO,CAAC3D,IAAI,CAAC;;QAErC;QACA;QACA;QACA;QACA,IAAIhB,MAAM,GAAG/C,MAAM,CAAC+C,MAAM,CAACkB,KAAK,CAAC,IAAI,EAAE,CAAC,CAAC,EAAE,IAAI,CAAC;;QAEhD;QACA+B,gBAAgB,CAACjC,IAAI,CAACL,gBAAgB,EAAEX,MAAM,CAAC;QAE/C,IAAI4E,aAAa,GAAGL,OAAO,CAACvE,MAAM,CAAC;QACnC,KAAK,IAAI,CAAC8B,UAAU,EAAE+C,OAAO,CAAC,IAAID,aAAa,EAAE;UAC7C;UACA,IAAIE,OAAO,GAAG;YAAE,GAAG9D;UAAK,CAAC;;UAEzB;UACA;UACA,IAAI,CAAC+D,UAAU,CAACD,OAAO,EAAEhD,UAAU,CAAC;UAEpCgD,OAAO,CAACjE,KAAK,IAAIgE,OAAO;UAExB,IAAI/C,UAAU,KAAK,IAAI,CAACxD,MAAM,CAACC,YAAY,EAAE;YACzCuG,OAAO,CAAClE,IAAI,GAAG,IAAI;UACvB;UACA8D,YAAY,CAACpI,IAAI,CAACwI,OAAO,CAAC;QAC9B;MACJ;MACA,EAAEzE,eAAe;;MAEjB;MACAqE,YAAY,GAAG,IAAI,CAACM,UAAU,CAACN,YAAY,CAAC,CAACzG,GAAG,CAC5CgH,KAAK,IAAIA,KAAK,CACTC,IAAI,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKA,CAAC,CAACvE,KAAK,GAAGsE,CAAC,CAACtE,KAAK,CAAC,CAAM;MAAA,CACvCK,KAAK,CAAC,CAAC,EAAE6B,iBAAiB,CAACsC,SAAS,CAAC,CAAE;MAChD,CAAC;;MAED;MACA9E,KAAK,GAAGmE,YAAY,CAAC1G,IAAI,CAAC,CAAC;;MAE3B;MACA,IAAI+E,iBAAiB,CAACuC,iBAAiB,EAAE;QACrCvC,iBAAiB,CAACuC,iBAAiB,CAAC/E,KAAK,CAAC;MAC9C;IACJ;;IAEA;;IAEA,OAAO,IAAI,CAACyE,UAAU,CAACzE,KAAK,CAAC,CAACtC,GAAG,CAC7BsH,KAAK,IAAI;MACL,IAAIxC,iBAAiB,CAACyC,oBAAoB,GAAG,CAAC,EAAE;QAC5C,OAAOD,KAAK,CAACrE,KAAK,CAAC,CAAC,EAAE6B,iBAAiB,CAACyC,oBAAoB,CAAC,CAACvH,GAAG,CAACJ,CAAC,IAAIA,CAAC,CAAC8C,gBAAgB,CAAC;MAC9F,CAAC,MAAM;QACH,OAAO,CAAC4E,KAAK,CAAC,CAAC,CAAC,CAAC5E,gBAAgB,CAAC;MACtC;IACJ,CACJ,CAAC,CAAC3C,IAAI,CAAC,CAAC,CAAC,CAAC;EACd;;EAEA;AACJ;AACA;AACA;AACA;AACA;EACIgH,UAAUA,CAACzE,KAAK,EAAE;IACd;IACA,MAAMkF,MAAM,GAAG/I,MAAM,CAACjB,MAAM,CAAC,IAAI,CAAC;IAClC,KAAK,MAAM6B,GAAG,IAAIiD,KAAK,EAAE;MACrB,IAAIkF,MAAM,CAACnI,GAAG,CAACwD,EAAE,CAAC,KAAKzE,SAAS,EAAE;QAC9BoJ,MAAM,CAACnI,GAAG,CAACwD,EAAE,CAAC,GAAG,CAACxD,GAAG,CAAC;MAC1B,CAAC,MAAM;QACHmI,MAAM,CAACnI,GAAG,CAACwD,EAAE,CAAC,CAACxE,IAAI,CAACgB,GAAG,CAAC;MAC5B;IACJ;IAEA,OAAOZ,MAAM,CAACgJ,MAAM,CAACD,MAAM,CAAC;EAChC;;EAEA;AACJ;AACA;AACA;AACA;AACA;AACA;EACIxF,gBAAgBA,CAACF,cAAc,EAAE4F,aAAa,EAAE;IAE5C,MAAMC,IAAI,GAAGlJ,MAAM,CAACjB,MAAM,CAAC,IAAI,CAAC;IAEhC,KAAK,MAAMV,IAAI,IAAIgF,cAAc,EAAE;MAC/B,IAAIhF,IAAI,CAAC8K,UAAU,CAAC,SAAS,CAAC,EAAE;QAC5B,IAAIC,OAAO,GAAG/K,IAAI,CAACgL,OAAO,CAAC,SAAS,EAAE,iBAAiB,CAAC;QAExD,IAAIJ,aAAa,KAAK,IAAI,IAAI5K,IAAI,CAACgC,QAAQ,CAAC,SAAS,CAAC,EAAE;UACpD;UACA;UACA;UACA6I,IAAI,CAACE,OAAO,CAAC,GAAGH,aAAa,CAACG,OAAO,CAAC;QAC1C,CAAC,MAAM;UACHF,IAAI,CAACE,OAAO,CAAC,GAAG/F,cAAc,CAAChF,IAAI,CAAC;QACxC;MACJ;IACJ;IACA,OAAO6K,IAAI;EACf;;EAEA;AACJ;AACA;AACA;AACA;AACA;AACA;EACI9F,gBAAgBA,CAACR,YAAY,EAAEqG,aAAa,EAAsB;IAAA,IAApBK,UAAU,GAAA9G,SAAA,CAAAvD,MAAA,QAAAuD,SAAA,QAAA7C,SAAA,GAAA6C,SAAA,MAAG,KAAK;IAC5D,IAAIyG,aAAa,EAAE;MACfjJ,MAAM,CAACoH,MAAM,CAACxE,YAAY,EAAEqG,aAAa,CAAC;IAC9C,CAAC,MAAM;MACH;MACA,IAAIK,UAAU,EAAE;QACZ;QACA,IAAIC,YAAY,GAAG,CAAC,CAAC,EAAE,IAAI,CAACC,iBAAiB,EAAE,CAAC,EAAE,IAAI,CAACC,cAAc,CAAC;QACtE;QACA,KAAK,IAAIC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG,IAAI,CAACC,kBAAkB,EAAE,EAAED,CAAC,EAAE;UAC9C9G,YAAY,CAAE,mBAAkB8G,CAAE,cAAa,CAAC,GAAG,IAAIvM,MAAM,CAAC,SAAS,EAAE,EAAE,EAAEoM,YAAY,CAAC;UAC1F3G,YAAY,CAAE,mBAAkB8G,CAAE,gBAAe,CAAC,GAAG,IAAIvM,MAAM,CAAC,SAAS,EAAE,EAAE,EAAEoM,YAAY,CAAC;QAChG;;QAEA;QACA,IAAIK,YAAY,GAAG,CAAC,CAAC,EAAE,IAAI,CAACC,iBAAiB,EAAE,CAAC,EAAE,IAAI,CAACC,cAAc,CAAC;QACtE;QACA,KAAK,IAAIJ,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG,IAAI,CAACK,kBAAkB,EAAE,EAAEL,CAAC,EAAE;UAC9C9G,YAAY,CAAE,mBAAkB8G,CAAE,cAAa,CAAC,GAAG,IAAIvM,MAAM,CAAC,SAAS,EAAE,EAAE,EAAEyM,YAAY,CAAC;UAC1FhH,YAAY,CAAE,mBAAkB8G,CAAE,gBAAe,CAAC,GAAG,IAAIvM,MAAM,CAAC,SAAS,EAAE,EAAE,EAAEyM,YAAY,CAAC;QAChG;MAEJ,CAAC,MAAM;QACH;QACA,IAAI1H,IAAI,GAAG,CAAC,CAAC,EAAE,IAAI,CAAC8H,SAAS,EAAE,CAAC,EAAE,IAAI,CAACC,MAAM,CAAC;QAC9C;QACA,KAAK,IAAIP,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG,IAAI,CAACQ,UAAU,EAAE,EAAER,CAAC,EAAE;UACtC9G,YAAY,CAAE,mBAAkB8G,CAAE,MAAK,CAAC,GAAG,IAAIvM,MAAM,CAAC,SAAS,EAAE,EAAE,EAAE+E,IAAI,CAAC;UAC1EU,YAAY,CAAE,mBAAkB8G,CAAE,QAAO,CAAC,GAAG,IAAIvM,MAAM,CAAC,SAAS,EAAE,EAAE,EAAE+E,IAAI,CAAC;QAChF;MACJ;IACJ;EACJ;AACJ;AACA;AACA;AACA,OAAO,MAAMiI,WAAW,CAAC;;AAEzB;AACA;AACA;AACA,OAAO,MAAMC,eAAe,SAASD,WAAW,CAAC;EAC7C;AACJ;AACA;AACA;AACA;AACA;EACI/L,WAAWA,CAAAiM,IAAA,EAAiE;IAAA,IAAhE;MAAE1H,iBAAiB;MAAE2H,aAAa,GAAG,IAAI;MAAEC,UAAU,GAAG;IAAK,CAAC,GAAAF,IAAA;IACtE,KAAK,CAAC,CAAC;IACP,IAAI,CAAC1H,iBAAiB,GAAGA,iBAAiB;IAC1C,IAAI,CAAC2H,aAAa,GAAGA,aAAa;IAClC,IAAI,CAACC,UAAU,GAAGA,UAAU;EAChC;AACJ;AACA;AACA;AACA,OAAO,MAAMC,mBAAmB,SAASnF,eAAe,CAAC;AACzD,OAAO,MAAMoF,SAAS,SAASD,mBAAmB,CAAC;;AAEnD;AACA;AACA;AACA;AACA,OAAO,MAAME,eAAe,SAASF,mBAAmB,CAAC;EACrD;AACJ;AACA;AACA;AACA;AACA;EACI,MAAMrE,KAAKA,CAACjI,YAAY,EAAE;IACtB,OAAO,IAAIyM,cAAc,CAAC,MAAM,KAAK,CAACxE,KAAK,CAACjI,YAAY,CAAC,CAAC;EAC9D;AACJ;;AAEA;AACA;AACA;AACA;AACA,OAAO,MAAM0M,6BAA6B,SAASJ,mBAAmB,CAAC;EACnE;AACJ;AACA;AACA;AACA;AACA;EACI,MAAMrE,KAAKA,CAACjI,YAAY,EAAE;IACtB,OAAO,IAAI2M,wBAAwB,CAAC,MAAM,KAAK,CAAC1E,KAAK,CAACjI,YAAY,CAAC,CAAC;EACxE;AACJ;;AAEA;AACA;AACA;AACA;AACA,OAAO,MAAM4M,0BAA0B,SAASN,mBAAmB,CAAC;EAChE;AACJ;AACA;AACA;AACA;AACA;EACI,MAAMrE,KAAKA,CAACjI,YAAY,EAAE;IACtB,OAAO,IAAI6M,qBAAqB,CAAC,MAAM,KAAK,CAAC5E,KAAK,CAACjI,YAAY,CAAC,CAAC;EACrE;AACJ;;AAEA;AACA;AACA;AACA;AACA,OAAO,MAAM8M,wBAAwB,SAASR,mBAAmB,CAAC;EAC9D;AACJ;AACA;AACA;AACA;AACA;EACI,MAAMrE,KAAKA,CAACjI,YAAY,EAAE;IACtB,OAAO,IAAI+M,4BAA4B,CAAC,MAAM,KAAK,CAAC9E,KAAK,CAACjI,YAAY,CAAC,CAAC;EAC5E;AACJ;AACA;;AAEA;AACA;AACA,OAAO,MAAMgN,yBAAyB,SAAS7F,eAAe,CAAC;AAC/D,OAAO,MAAM8F,eAAe,SAASD,yBAAyB,CAAC;;AAE/D;AACA;AACA;AACA;AACA,OAAO,MAAME,mCAAmC,SAASF,yBAAyB,CAAC;EAC/E;AACJ;AACA;AACA;AACA;AACA;EACI,MAAM/E,KAAKA,CAACjI,YAAY,EAAE;IACtB,OAAO,IAAI2M,wBAAwB,CAAC,MAAM,KAAK,CAAC1E,KAAK,CAACjI,YAAY,CAAC,CAAC;EACxE;AACJ;;AAEA;AACA;AACA;AACA;AACA,OAAO,MAAMmN,gCAAgC,SAASH,yBAAyB,CAAC;EAC5E;AACJ;AACA;AACA;AACA;AACA;EACI,MAAM/E,KAAKA,CAACjI,YAAY,EAAE;IACtB,OAAO,IAAI6M,qBAAqB,CAAC,MAAM,KAAK,CAAC5E,KAAK,CAACjI,YAAY,CAAC,CAAC;EACrE;AACJ;;AAGA;AACA;AACA;AACA;AACA,OAAO,MAAMoN,8BAA8B,SAASJ,yBAAyB,CAAC;EAC1E;AACJ;AACA;AACA;AACA;AACA;EACI,MAAM/E,KAAKA,CAACjI,YAAY,EAAE;IACtB,OAAO,IAAI+M,4BAA4B,CAAC,MAAM,KAAK,CAAC9E,KAAK,CAACjI,YAAY,CAAC,CAAC;EAC5E;AACJ;;AAEA;AACA;AACA;AACA;AACA,OAAO,MAAMqN,qBAAqB,SAASL,yBAAyB,CAAC;EACjE;AACJ;AACA;AACA;AACA;AACA;EACI,MAAM/E,KAAKA,CAACjI,YAAY,EAAE;IACtB,OAAO,IAAIyM,cAAc,CAAC,MAAM,KAAK,CAACxE,KAAK,CAACjI,YAAY,CAAC,CAAC;EAC9D;AACJ;AACA;;AAGA;AACA;AACA,OAAO,MAAMsN,yBAAyB,SAASnG,eAAe,CAAC;AAC/D,OAAO,MAAMoG,eAAe,SAASD,yBAAyB,CAAC;;AAE/D;AACA;AACA;AACA;AACA,OAAO,MAAME,qBAAqB,SAASF,yBAAyB,CAAC;EACjE;AACJ;AACA;AACA;AACA;AACA;EACI,MAAMrF,KAAKA,CAACjI,YAAY,EAAE;IACtB,OAAO,IAAIyM,cAAc,CAAC,MAAM,KAAK,CAACxE,KAAK,CAACjI,YAAY,CAAC,CAAC;EAC9D;AACJ;;AAEA;AACA;AACA;AACA,OAAO,MAAMyN,mCAAmC,SAASH,yBAAyB,CAAC;EAC/E;AACJ;AACA;AACA;AACA;AACA;EACI,MAAMrF,KAAKA,CAACjI,YAAY,EAAE;IACtB,OAAO,IAAI2M,wBAAwB,CAAC,MAAM,KAAK,CAAC1E,KAAK,CAACjI,YAAY,CAAC,CAAC;EACxE;AACJ;;AAEA;AACA;AACA;AACA,OAAO,MAAM0N,8BAA8B,SAASJ,yBAAyB,CAAC;EAC1E;AACJ;AACA;AACA;AACA;AACA;EACI,MAAMrF,KAAKA,CAACjI,YAAY,EAAE;IACtB,OAAO,IAAI+M,4BAA4B,CAAC,MAAM,KAAK,CAAC9E,KAAK,CAACjI,YAAY,CAAC,CAAC;EAC5E;AACJ;AACA;;AAGA;AACA;AACA,OAAO,MAAM2N,0BAA0B,SAASxG,eAAe,CAAC;AAChE,OAAO,MAAMyG,gBAAgB,SAASD,0BAA0B,CAAC;AACjE,OAAO,MAAME,sBAAsB,SAASF,0BAA0B,CAAC;EACnE;AACJ;AACA;AACA;AACA;AACA;EACI,MAAM1F,KAAKA,CAACjI,YAAY,EAAE;IACtB,OAAO,IAAIyM,cAAc,CAAC,MAAM,KAAK,CAACxE,KAAK,CAACjI,YAAY,CAAC,CAAC;EAC9D;AACJ;AACA,OAAO,MAAM8N,oCAAoC,SAASH,0BAA0B,CAAC;EACjF;AACJ;AACA;AACA;AACA;AACA;EACI,MAAM1F,KAAKA,CAACjI,YAAY,EAAE;IACtB,OAAO,IAAI2M,wBAAwB,CAAC,MAAM,KAAK,CAAC1E,KAAK,CAACjI,YAAY,CAAC,CAAC;EACxE;AACJ;AACA,OAAO,MAAM+N,+BAA+B,SAASJ,0BAA0B,CAAC;EAC5E;AACJ;AACA;AACA;AACA;AACA;EACI,MAAM1F,KAAKA,CAACjI,YAAY,EAAE;IACtB,OAAO,IAAI+M,4BAA4B,CAAC,MAAM,KAAK,CAAC9E,KAAK,CAACjI,YAAY,CAAC,CAAC;EAC5E;AACJ;AACA;;AAGA;AACA;AACA,OAAO,MAAMgO,qBAAqB,SAAS7G,eAAe,CAAC;AAC3D,OAAO,MAAM8G,WAAW,SAASD,qBAAqB,CAAC;AACvD,OAAO,MAAME,+BAA+B,SAASF,qBAAqB,CAAC;EACvE;AACJ;AACA;AACA;AACA;AACA;EACI,MAAM/F,KAAKA,CAACjI,YAAY,EAAE;IACtB,OAAO,IAAI2M,wBAAwB,CAAC,MAAM,KAAK,CAAC1E,KAAK,CAACjI,YAAY,CAAC,CAAC;EACxE;AACJ;AACA,OAAO,MAAMmO,0BAA0B,SAASH,qBAAqB,CAAC;EAClE;AACJ;AACA;AACA;AACA;AACA;EACI,MAAM/F,KAAKA,CAACjI,YAAY,EAAE;IACtB,OAAO,IAAI+M,4BAA4B,CAAC,MAAM,KAAK,CAAC9E,KAAK,CAACjI,YAAY,CAAC,CAAC;EAC5E;AACJ;AACA,OAAO,MAAMoO,iBAAiB,SAASJ,qBAAqB,CAAC;EACzD;AACJ;AACA;AACA;AACA;AACA;EACI,MAAM/F,KAAKA,CAACjI,YAAY,EAAE;IACtB,OAAO,IAAIyM,cAAc,CAAC,MAAM,KAAK,CAACxE,KAAK,CAACjI,YAAY,CAAC,CAAC;EAC9D;AACJ;AACA;;AAGA;AACA;AACA,OAAO,MAAMqO,iBAAiB,SAASlH,eAAe,CAAC;AAAG;AAE1D,OAAO,MAAMmH,OAAO,SAASD,iBAAiB,CAAC;EAC3C;AACJ;AACA;AACA;AACA;AACA;EACI,MAAMlF,QAAQA,CAAA,EAAU;IACpB,MAAMxH,KAAK,CACP,mMACJ,CAAC;EACL;AACJ;;AAEA;AACA;AACA;AACA;AACA,OAAO,MAAM4M,0BAA0B,SAASF,iBAAiB,CAAC;EAE9D;AACJ;AACA;AACA;AACA;AACA;AACA;EACInO,WAAWA,CAACwD,MAAM,EAAEvC,OAAO,EAAE4D,sBAAsB,EAAEoD,iBAAiB,EAAE;IACpE,KAAK,CAACzE,MAAM,EAAEvC,OAAO,CAAC;IACtB,IAAI,CAAC4D,sBAAsB,GAAGA,sBAAsB;IACpD,IAAI,CAACoD,iBAAiB,GAAGA,iBAAiB;IAE1C,IAAI,CAAC0D,kBAAkB,GAAG,IAAI,CAACnI,MAAM,CAACmI,kBAAkB;IACxD,IAAI,CAACF,iBAAiB,GAAG,IAAI,CAACjI,MAAM,CAACoI,SAAS;IAC9C,IAAI,CAACF,cAAc,GAAG,IAAI,CAAClI,MAAM,CAAC8K,IAAI;IAEtC,IAAI,CAAC/C,kBAAkB,GAAG,IAAI,CAAC/H,MAAM,CAACsI,UAAU;IAChD,IAAI,CAACV,iBAAiB,GAAG,IAAI,CAAC5H,MAAM,CAACoI,SAAS;IAC9C,IAAI,CAACP,cAAc,GAAG,IAAI,CAAC7H,MAAM,CAAC8K,IAAI;EAC1C;;EAEA;AACJ;AACA;AACA;AACA;AACA;EACI3E,aAAaA,CAACzI,MAAM,EAAEqE,eAAe,EAAW;IAC5C,OAAOF,iBAAiB,CAAC,IAAI,EAAEnE,MAAM,EAAEqE,eAAe,CAAC;EAC3D;;EAEA;AACJ;AACA;AACA;AACA;EACI,MAAMsE,OAAOA,CAAC3D,IAAI,EAAE;IAChB,OAAO,MAAMD,cAAc,CAAC,IAAI,EAAEC,IAAI,CAAC;EAC3C;;EAEA;AACJ;AACA;AACA;AACA;EACI+D,UAAUA,CAAC/D,IAAI,EAAEc,UAAU,EAAE;IACzBd,IAAI,CAACL,gBAAgB,GAAG,CAAC,GAAGK,IAAI,CAACL,gBAAgB,EAAEmB,UAAU,CAAC;EAClE;;EAEA;AACJ;AACA;AACA;AACA;EACI,MAAMpH,OAAOA,CAACE,YAAY,EAAE;IACxB,OAAO,MAAMoE,cAAc,CAAC,IAAI,EAAEpE,YAAY,CAAC;EACnD;AACJ;AACA;;AAEA;AACA;AACA,OAAO,MAAMyO,kBAAkB,SAAStH,eAAe,CAAC;AAAG;AAE3D,OAAO,MAAMuH,QAAQ,SAASD,kBAAkB,CAAC;EAC7C;AACJ;AACA;AACA;AACA;AACA;EACI,MAAMtF,QAAQA,CAAA,EAAU;IACpB,MAAMxH,KAAK,CACP,qMACJ,CAAC;EACL;AACJ;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMgN,2BAA2B,SAASF,kBAAkB,CAAC;EAEhE;AACJ;AACA;AACA;AACA;AACA;AACA;EACIvO,WAAWA,CAACwD,MAAM,EAAEvC,OAAO,EAAE4D,sBAAsB,EAAEoD,iBAAiB,EAAE;IACpE,KAAK,CAACzE,MAAM,EAAEvC,OAAO,CAAC;IACtB,IAAI,CAAC4D,sBAAsB,GAAGA,sBAAsB;IACpD,IAAI,CAACoD,iBAAiB,GAAGA,iBAAiB;IAE1C,IAAI,CAAC0D,kBAAkB,GAAG,IAAI,CAACnI,MAAM,CAACmI,kBAAkB;IACxD,IAAI,CAACF,iBAAiB,GAAG,IAAI,CAACjI,MAAM,CAACoI,SAAS;IAC9C,IAAI,CAACF,cAAc,GAAG,IAAI,CAAClI,MAAM,CAAC8K,IAAI;IAEtC,IAAI,CAAC/C,kBAAkB,GAAG,IAAI,CAAC/H,MAAM,CAACsI,UAAU;IAChD,IAAI,CAACV,iBAAiB,GAAG,IAAI,CAAC5H,MAAM,CAACoI,SAAS;IAC9C,IAAI,CAACP,cAAc,GAAG,IAAI,CAAC7H,MAAM,CAAC8K,IAAI;EAC1C;;EAEA;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;EACI3E,aAAaA,CAACzI,MAAM,EAAEqE,eAAe,EAAW;IAC5C,OAAOF,iBAAiB,CAAC,IAAI,EAAEnE,MAAM,EAAEqE,eAAe,CAAC;EAC3D;;EAEA;AACJ;AACA;AACA;AACA;EACI,MAAMsE,OAAOA,CAAC3D,IAAI,EAAE;IAChB,OAAO,MAAMD,cAAc,CAAC,IAAI,EAAEC,IAAI,CAAC;EAC3C;;EAEA;AACJ;AACA;AACA;AACA;EACI+D,UAAUA,CAAC/D,IAAI,EAAEc,UAAU,EAAE;IACzBd,IAAI,CAACL,gBAAgB,GAAG,CAAC,GAAGK,IAAI,CAACL,gBAAgB,EAAEmB,UAAU,CAAC;EAClE;;EAEA;AACJ;AACA;AACA;AACA;EACI,MAAMpH,OAAOA,CAACE,YAAY,EAAE;IACxB,OAAO,MAAMoE,cAAc,CAAC,IAAI,EAAEpE,YAAY,CAAC;EACnD;AACJ;AACA;;AAEA;AACA;AACA,OAAO,MAAM4O,mBAAmB,SAASzH,eAAe,CAAC;AAAG;;AAE5D;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAM0H,SAAS,SAASD,mBAAmB,CAAC;EAC/C;AACJ;AACA;AACA;AACA;AACA;EACI,MAAMzF,QAAQA,CAAA,EAAU;IACpB,MAAMxH,KAAK,CACP,uMACJ,CAAC;EACL;AACJ;;AAEA;AACA;AACA;AACA;AACA,OAAO,MAAMmN,4BAA4B,SAASF,mBAAmB,CAAC;EAElE;AACJ;AACA;AACA;AACA;AACA;AACA;EACI1O,WAAWA,CAACwD,MAAM,EAAEvC,OAAO,EAAE4D,sBAAsB,EAAEoD,iBAAiB,EAAE;IACpE,KAAK,CAACzE,MAAM,EAAEvC,OAAO,CAAC;IACtB,IAAI,CAAC4D,sBAAsB,GAAGA,sBAAsB;IACpD,IAAI,CAACoD,iBAAiB,GAAGA,iBAAiB;IAE1C,IAAI,CAAC0D,kBAAkB,GAAG,IAAI,CAACnI,MAAM,CAACqL,cAAc;IACpD,IAAI,CAACpD,iBAAiB,GAAG,IAAI,CAACjI,MAAM,CAACsL,uBAAuB;IAC5D,IAAI,CAACpD,cAAc,GAAG,IAAI,CAAClI,MAAM,CAACuL,OAAO,GAAG,IAAI,CAACtD,iBAAiB;IAElE,IAAI,CAACF,kBAAkB,GAAG,IAAI,CAAC/H,MAAM,CAACwL,cAAc;IACpD,IAAI,CAAC5D,iBAAiB,GAAG,IAAI,CAAC5H,MAAM,CAACyL,uBAAuB;IAC5D,IAAI,CAAC5D,cAAc,GAAG,IAAI,CAAC7H,MAAM,CAACuL,OAAO,GAAG,IAAI,CAAC3D,iBAAiB;EACtE;;EAEA;AACJ;AACA;AACA;AACA;AACA;AACA;EACIzB,aAAaA,CAACzI,MAAM,EAAEqE,eAAe,EAAW;IAC5C,OAAOF,iBAAiB,CAAC,IAAI,EAAEnE,MAAM,EAAEqE,eAAe,CAAC;EAC3D;;EAEA;AACJ;AACA;AACA;AACA;EACI,MAAMsE,OAAOA,CAAC3D,IAAI,EAAE;IAChB,OAAO,MAAMD,cAAc,CAAC,IAAI,EAAEC,IAAI,CAAC;EAC3C;;EAEA;AACJ;AACA;AACA;AACA;EACI+D,UAAUA,CAAC/D,IAAI,EAAEc,UAAU,EAAE;IACzBd,IAAI,CAACL,gBAAgB,GAAG,CAAC,GAAGK,IAAI,CAACL,gBAAgB,EAAEmB,UAAU,CAAC;EAClE;;EAEA;AACJ;AACA;AACA;AACA;EACI,MAAMpH,OAAOA,CAACE,YAAY,EAAE;IACxB,OAAO,MAAMoE,cAAc,CAAC,IAAI,EAAEpE,YAAY,CAAC;EACnD;AACJ;AAEA,OAAO,MAAMoP,6BAA6B,SAASR,mBAAmB,CAAC;EACnE;AACJ;AACA;AACA;AACA;AACA;EACI,MAAM3G,KAAKA,CAACjI,YAAY,EAAE;IACtB,OAAO,IAAI2M,wBAAwB,CAAC,MAAM,KAAK,CAAC1E,KAAK,CAACjI,YAAY,CAAC,CAAC;EACxE;AACJ;;AAEA;;AAEA;AACA;AACA,OAAO,MAAMqP,sBAAsB,SAASlI,eAAe,CAAC;AAC5D,OAAO,MAAMmI,YAAY,SAASD,sBAAsB,CAAC;;AAEzD;AACA;AACA;AACA;AACA,OAAO,MAAME,kBAAkB,SAASF,sBAAsB,CAAC;EAC3D;AACJ;AACA;AACA;AACA;AACA;EACI,MAAMpH,KAAKA,CAACjI,YAAY,EAAE;IACtB,OAAO,IAAIyM,cAAc,CAAC,MAAM,KAAK,CAACxE,KAAK,CAACjI,YAAY,CAAC,CAAC;EAC9D;AACJ;;AAEA;AACA;AACA;AACA;AACA,OAAO,MAAMwP,gCAAgC,SAASH,sBAAsB,CAAC;EACzE;AACJ;AACA;AACA;AACA;AACA;EACI,MAAMpH,KAAKA,CAACjI,YAAY,EAAE;IACtB,OAAO,IAAI2M,wBAAwB,CAAC,MAAM,KAAK,CAAC1E,KAAK,CAACjI,YAAY,CAAC,CAAC;EACxE;AACJ;;AAEA;AACA;AACA;AACA;AACA,OAAO,MAAMyP,2BAA2B,SAASJ,sBAAsB,CAAC;EACpE;AACJ;AACA;AACA;AACA;AACA;EACI,MAAMpH,KAAKA,CAACjI,YAAY,EAAE;IACtB,OAAO,IAAI+M,4BAA4B,CAAC,MAAM,KAAK,CAAC9E,KAAK,CAACjI,YAAY,CAAC,CAAC;EAC5E;AACJ;AACA;;AAEA;AACA;AACA,OAAO,MAAM0P,sBAAsB,SAASvI,eAAe,CAAC;AAAG;;AAE/D;AACA;AACA;AACA;AACA,OAAO,MAAMwI,YAAY,SAASD,sBAAsB,CAAC;EACrD;AACJ;AACA;AACA;AACA;AACA;EACI,MAAMvG,QAAQA,CAAA,EAAU;IACpB,MAAMxH,KAAK,CACP,6MACJ,CAAC;EACL;AACJ;;AAEA;AACA;AACA;AACA;AACA,OAAO,MAAMiO,+BAA+B,SAASF,sBAAsB,CAAC;EAExE;AACJ;AACA;AACA;AACA;AACA;AACA;EACIxP,WAAWA,CAACwD,MAAM,EAAEvC,OAAO,EAAE4D,sBAAsB,EAAEoD,iBAAiB,EAAE;IACpE,KAAK,CAACzE,MAAM,EAAEvC,OAAO,CAAC;IACtB,IAAI,CAAC4D,sBAAsB,GAAGA,sBAAsB;IACpD,IAAI,CAACoD,iBAAiB,GAAGA,iBAAiB;IAE1C,IAAI,CAAC0D,kBAAkB,GAAG,IAAI,CAACnI,MAAM,CAACqL,cAAc;IACpD,IAAI,CAACpD,iBAAiB,GAAG,IAAI,CAACjI,MAAM,CAACsL,uBAAuB;IAC5D,IAAI,CAACpD,cAAc,GAAG,IAAI,CAAClI,MAAM,CAACuL,OAAO,GAAG,IAAI,CAACtD,iBAAiB;IAElE,IAAI,CAACF,kBAAkB,GAAG,IAAI,CAAC/H,MAAM,CAACwL,cAAc;IACpD,IAAI,CAAC5D,iBAAiB,GAAG,IAAI,CAAC5H,MAAM,CAACyL,uBAAuB;IAC5D,IAAI,CAAC5D,cAAc,GAAG,IAAI,CAAC7H,MAAM,CAACuL,OAAO,GAAG,IAAI,CAAC3D,iBAAiB;EAGtE;;EAEA;AACJ;AACA;AACA;AACA;AACA;AACA;EACI,MAAMnC,QAAQA,CACV/H,MAAM,EAGR;IAAA,IAFE+G,iBAAiB,GAAA7D,SAAA,CAAAvD,MAAA,QAAAuD,SAAA,QAAA7C,SAAA,GAAA6C,SAAA,MAAG,IAAI;IAAA,IACxB+D,gBAAgB,GAAA/D,SAAA,CAAAvD,MAAA,QAAAuD,SAAA,QAAA7C,SAAA,GAAA6C,SAAA,MAAG,IAAI;IAEvB;IACA6D,iBAAiB,GAAG,IAAI,CAACa,sBAAsB,CAACb,iBAAiB,CAAC;;IAGlE;IACAA,iBAAiB,CAAC0H,iBAAiB,KAAK,KAAK;;IAE7C;;IAEA,IAAI1H,iBAAiB,CAAC0H,iBAAiB,EAAE;MACrCxH,gBAAgB,GAAG,CAAC,IAAIxJ,+BAA+B,CAACsJ,iBAAiB,CAAC,CAAC;IAC/E;IAEA,OAAO,KAAK,CAACgB,QAAQ,CAAC/H,MAAM,EAAE+G,iBAAiB,EAAEE,gBAAgB,CAAC;EACtE;;EAEA;AACJ;AACA;AACA;AACA;AACA;EACIwB,aAAaA,CAACrE,aAAa,EAAEC,eAAe,EAAW;IACnD;IACA,OAAOF,iBAAiB,CAAC,IAAI,EAAEC,aAAa,EAAEC,eAAe,EAAE,KAAK,CAAC;EACzE;;EAEA;AACJ;AACA;AACA;AACA;EACI,MAAMsE,OAAOA,CAAC3D,IAAI,EAAE;IAChB,OAAO,MAAMD,cAAc,CAAC,IAAI,EAAEC,IAAI,EAAE;MACpCC,UAAU,EAAE;IAChB,CAAC,CAAC;EACN;;EAEA;AACJ;AACA;AACA;AACA;EACI8D,UAAUA,CAAC/D,IAAI,EAAEc,UAAU,EAAE;IACzBd,IAAI,CAACL,gBAAgB,GAAG,CAAC,GAAGK,IAAI,CAACL,gBAAgB,EAAEmB,UAAU,CAAC;EAClE;;EAEA;AACJ;AACA;AACA;AACA;EACI,MAAMpH,OAAOA,CAACE,YAAY,EAAE;IACxB,OAAO,MAAMoE,cAAc,CAAC,IAAI,EAAEpE,YAAY,CAAC;EACnD;AACJ;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAM8P,yBAAyB,SAAS3I,eAAe,CAAC;EAC3D;AACJ;AACA;AACA;AACA;AACA;EACIjH,WAAWA,CAACwD,MAAM,EAAEvC,OAAO,EAAE4D,sBAAsB,EAAE;IACjD,KAAK,CAACrB,MAAM,EAAEvC,OAAO,CAAC;IACtB,IAAI,CAAC4D,sBAAsB,GAAGA,sBAAsB;IAEpD,IAAI,CAACiH,UAAU,GAAG,IAAI,CAACtI,MAAM,CAACqM,OAAO,CAACC,OAAO;IAC7C,IAAI,CAAClE,SAAS,GAAG,IAAI,CAACpI,MAAM,CAACqM,OAAO,CAACE,MAAM;IAC3C,IAAI,CAAClE,MAAM,GAAG,IAAI,CAACrI,MAAM,CAACqM,OAAO,CAACG,MAAM,GAAG,IAAI,CAACpE,SAAS;EAC7D;;EAEA;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;EACIjC,aAAaA,CAACzI,MAAM,EAAEqE,eAAe,EAAW;IAC5C,OAAOF,iBAAiB,CAAC,IAAI,EAAEnE,MAAM,EAAEqE,eAAe,CAAC;EAC3D;;EAEA;AACJ;AACA;AACA;AACA;EACI,MAAMsE,OAAOA,CAAC3D,IAAI,EAAE;IAChB,OAAOD,cAAc,CAAC,IAAI,EAAEC,IAAI,EAAE;MAC9BC,UAAU,EAAE;IAChB,CAAC,CAAC;EACN;;EAEA;AACJ;AACA;AACA;AACA;AACA;EACI8D,UAAUA,CAAC/D,IAAI,EAAEc,UAAU,EAAE;IACzBd,IAAI,CAACL,gBAAgB,GAAG,CAAC,GAAGK,IAAI,CAACL,gBAAgB,EAAEmB,UAAU,CAAC;EAClE;;EAEA;AACJ;AACA;AACA;AACA;AACA;EACI,MAAMpH,OAAOA,CAACE,YAAY,EAAE;IACxB,OAAO,MAAMoE,cAAc,CAAC,IAAI,EAAEpE,YAAY,EAAE;MAC5CqE,eAAe,EAAE;IACrB,CAAC,CAAC;EACN;AACJ;AACA;;AAEA;AACA;AACA,OAAO,MAAM8L,mBAAmB,SAAShJ,eAAe,CAAC;AACzD,OAAO,MAAMiJ,SAAS,SAASD,mBAAmB,CAAC;;AAInD;;AAEA;AACA;AACA,OAAO,MAAME,mBAAmB,SAASlJ,eAAe,CAAC;EACrD;AACJ;AACA;AACA;AACA;EACIjH,WAAWA,CAACwD,MAAM,EAAEvC,OAAO,EAAE;IACzB,KAAK,CAACuC,MAAM,EAAEvC,OAAO,CAAC;;IAEtB;IACA,IAAI,CAACuC,MAAM,CAACD,YAAY,GAAG,IAAI,CAACC,MAAM,CAACC,YAAY;IAEnD,IAAI,CAACmI,SAAS,GAAG,IAAI,CAACpI,MAAM,CAACuM,MAAM;IACnC,IAAI,CAACjE,UAAU,GAAG,IAAI,CAACtI,MAAM,CAACsM,OAAO;IACrC,IAAI,CAACjE,MAAM,GAAG,IAAI,CAACrI,MAAM,CAACwM,MAAM,GAAG,IAAI,CAACpE,SAAS;EACrD;AACJ;AAEA,OAAO,MAAMwE,SAAS,SAASD,mBAAmB,CAAC;EAE/C;AACJ;AACA;AACA;AACA;AACA;EACI,MAAMlH,QAAQA,CAAA,EAAU;IACpB,MAAMxH,KAAK,CACP,0LACJ,CAAC;EACL;AACJ;;AAEA;AACA;AACA;AACA;AACA,OAAO,MAAM4O,eAAe,SAASF,mBAAmB,CAAC;EAErD;AACJ;AACA;AACA;AACA;AACA;AACA;EACIxG,aAAaA,CAACrE,aAAa,EAAEC,eAAe,EAAEiB,qBAAqB,EAAE;IACjE,OAAOD,iBAAiB,CAAC,IAAI,EAAEjB,aAAa,EAAEC,eAAe,EAAEiB,qBAAqB,CAAC;EACzF;;EAEA;AACJ;AACA;AACA;AACA;EACI,MAAMqD,OAAOA,CAAC3D,IAAI,EAAE;IAChB,OAAO,MAAMW,cAAc,CAAC,IAAI,EAAEX,IAAI,CAAC;EAC3C;;EAEA;AACJ;AACA;AACA;AACA;EACI+D,UAAUA,CAAC/D,IAAI,EAAEc,UAAU,EAAE;IACzB,OAAOD,iBAAiB,CAACb,IAAI,EAAEc,UAAU,CAAC;EAC9C;;EAEA;AACJ;AACA;AACA;AACA;EACI,MAAMpH,OAAOA,CAACE,YAAY,EAAE;IACxB,OAAO,MAAMI,cAAc,CAAC,IAAI,EAAEJ,YAAY,CAAC;EACnD;AAEJ;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMwQ,qBAAqB,SAASrJ,eAAe,CAAC;EACvD;AACJ;AACA;AACA;AACA;EACIjH,WAAWA,CAACwD,MAAM,EAAEvC,OAAO,EAAE;IACzB,KAAK,CAACuC,MAAM,EAAEvC,OAAO,CAAC;;IAEtB;IACA,IAAI,CAACuC,MAAM,CAACD,YAAY,GAAG,IAAI,CAACC,MAAM,CAACC,YAAY;IAEnD,IAAI,CAACmI,SAAS,GAAG,IAAI,CAACpI,MAAM,CAACoI,SAAS;IACtC,IAAI,CAACE,UAAU,GAAG,IAAI,CAACtI,MAAM,CAACsI,UAAU;IACxC,IAAI,CAACD,MAAM,GAAG,IAAI,CAACrI,MAAM,CAAC+M,WAAW,GAAG,IAAI,CAAC3E,SAAS;EAC1D;AACJ;AACA,OAAO,MAAM4E,WAAW,SAASF,qBAAqB,CAAC;EACnD;AACJ;AACA;AACA;AACA;AACA;EACI,MAAMrH,QAAQA,CAAA,EAAU;IACpB,MAAMxH,KAAK,CACP,8LACJ,CAAC;EACL;AACJ;AAEA,OAAO,MAAMgP,iBAAiB,SAASH,qBAAqB,CAAC;EAEzD;AACJ;AACA;AACA;AACA;AACA;AACA;EACI3G,aAAaA,CAACrE,aAAa,EAAEC,eAAe,EAAEiB,qBAAqB,EAAE;IACjE,OAAOD,iBAAiB,CAAC,IAAI,EAAEjB,aAAa,EAAEC,eAAe,EAAEiB,qBAAqB,CAAC;EACzF;;EAEA;AACJ;AACA;AACA;AACA;EACI,MAAMqD,OAAOA,CAAC3D,IAAI,EAAE;IAChB,OAAO,MAAMW,cAAc,CAAC,IAAI,EAAEX,IAAI,CAAC;EAC3C;;EAEA;AACJ;AACA;AACA;AACA;EACI+D,UAAUA,CAAC/D,IAAI,EAAEc,UAAU,EAAE;IACzB,OAAOD,iBAAiB,CAACb,IAAI,EAAEc,UAAU,CAAC;EAC9C;;EAEA;AACJ;AACA;AACA;AACA;EACI,MAAMpH,OAAOA,CAACE,YAAY,EAAE;IACxB,OAAO,MAAMI,cAAc,CAAC,IAAI,EAAEJ,YAAY,CAAC;EACnD;AACJ;;AAEA;AACA;AACA,OAAO,MAAM4Q,sBAAsB,SAASzJ,eAAe,CAAC;EACxD;AACJ;AACA;AACA;AACA;EACIjH,WAAWA,CAACwD,MAAM,EAAEvC,OAAO,EAAE;IACzB,KAAK,CAACuC,MAAM,EAAEvC,OAAO,CAAC;;IAEtB;IACA,IAAI,CAACuC,MAAM,CAACD,YAAY,GAAG,IAAI,CAACC,MAAM,CAACC,YAAY;IAEnD,IAAI,CAACmI,SAAS,GAAG,IAAI,CAACpI,MAAM,CAACuM,MAAM;IACnC,IAAI,CAACjE,UAAU,GAAG,IAAI,CAACtI,MAAM,CAACsM,OAAO;IACrC,IAAI,CAACjE,MAAM,GAAG,IAAI,CAACrI,MAAM,CAACwM,MAAM,GAAG,IAAI,CAACpE,SAAS;EACrD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAM+E,YAAY,SAASD,sBAAsB,CAAC;EACrD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACI,MAAMzH,QAAQA,CAAA,EAAU;IACpB,MAAMxH,KAAK,CACP,gMACJ,CAAC;EACL;AACJ;;AAEA;AACA;AACA;AACA;AACA,OAAO,MAAMmP,kBAAkB,SAASF,sBAAsB,CAAC;EAE3D;AACJ;AACA;AACA;AACA;AACA;AACA;EACI/G,aAAaA,CAACrE,aAAa,EAAEC,eAAe,EAAEiB,qBAAqB,EAAE;IACjE,OAAOD,iBAAiB,CAAC,IAAI,EAAEjB,aAAa,EAAEC,eAAe,EAAEiB,qBAAqB,CAAC;EACzF;;EAEA;AACJ;AACA;AACA;AACA;EACI,MAAMqD,OAAOA,CAAC3D,IAAI,EAAE;IAChB,OAAO,MAAMW,cAAc,CAAC,IAAI,EAAEX,IAAI,CAAC;EAC3C;;EAEA;AACJ;AACA;AACA;AACA;EACI+D,UAAUA,CAAC/D,IAAI,EAAEc,UAAU,EAAE;IACzB,OAAOD,iBAAiB,CAACb,IAAI,EAAEc,UAAU,CAAC;EAC9C;;EAEA;AACJ;AACA;AACA;AACA;EACI,MAAMpH,OAAOA,CAACE,YAAY,EAAE;IACxB,OAAO,MAAMI,cAAc,CAAC,IAAI,EAAEJ,YAAY,CAAC;EACnD;AAEJ;AACA;;AAEA;AACA,OAAO,MAAM+Q,kBAAkB,SAAS5J,eAAe,CAAC;AACxD,OAAO,MAAM6J,yBAAyB,SAASD,kBAAkB,CAAC;EAC9D;AACJ;AACA;EACI,MAAM9I,KAAKA,CAACjI,YAAY,EAAE;IACtB,OAAO,IAAI2M,wBAAwB,CAAC,MAAM,KAAK,CAAC1E,KAAK,CAACjI,YAAY,CAAC,CAAC;EACxE;AACJ;AACA;;AAEA;AACA,OAAO,MAAMiR,mBAAmB,SAAS9J,eAAe,CAAC;AACzD,OAAO,MAAM+J,sBAAsB,SAASD,mBAAmB,CAAC;EAC5D;AACJ;AACA;EACI,MAAMhJ,KAAKA,CAACjI,YAAY,EAAE;IACtB,OAAO,IAAImR,yBAAyB,CAAC,MAAM,KAAK,CAAClJ,KAAK,CAACjI,YAAY,CAAC,CAAC;EACzE;AACJ;AAEA,OAAO,MAAMoR,mBAAmB,SAASH,mBAAmB,CAAC;EACzD;AACJ;AACA;AACA;AACA;EACI,MAAMhJ,KAAKA,CAACjI,YAAY,EAAE;IACtB,OAAO,IAAIqR,sBAAsB,CAAC,MAAM,KAAK,CAACpJ,KAAK,CAACjI,YAAY,CAAC,CAAC;EACtE;AACJ;AAEA,OAAO,MAAMmR,yBAAyB,SAASlF,WAAW,CAAC;EACvD;AACJ;AACA;AACA;AACA;AACA;EACI/L,WAAWA,CAAAoR,KAAA,EAAyB;IAAA,IAAxB;MAAElM,MAAM;MAAEmM;IAAW,CAAC,GAAAD,KAAA;IAC9B,KAAK,CAAC,CAAC;IACP,IAAI,CAAClM,MAAM,GAAGA,MAAM;IACpB,IAAI,CAACmM,UAAU,GAAGA,UAAU;EAChC;AACJ;AAEA,OAAO,MAAMF,sBAAsB,SAASpF,WAAW,CAAC;EACpD;AACJ;AACA;AACA;AACA;AACA;EACI/L,WAAWA,CAAAsR,KAAA,EAAqC;IAAA,IAApC;MAAEpM,MAAM;MAAEmM,UAAU;MAAEE;IAAW,CAAC,GAAAD,KAAA;IAC1C,KAAK,CAAC,CAAC;IACP,IAAI,CAACpM,MAAM,GAAGA,MAAM;IACpB,IAAI,CAACmM,UAAU,GAAGA,UAAU;IAC5B,IAAI,CAACE,UAAU,GAAGA,UAAU;EAChC;AACJ;AACA;;AAGA;AACA,OAAO,MAAMC,kBAAkB,SAASvK,eAAe,CAAC;AACxD,OAAO,MAAMwK,QAAQ,SAASD,kBAAkB,CAAC;EAC7C;AACJ;AACA;AACA;AACA;AACA;EACI,MAAMzJ,KAAKA,CAACjI,YAAY,EAAE;IACtB,OAAO,IAAI4R,0BAA0B,CAAC,MAAM,KAAK,CAAC3J,KAAK,CAACjI,YAAY,CAAC,CAAC;EAC1E;AACJ;;AAGA;AACA;AACA;AACA,OAAO,MAAM4R,0BAA0B,SAAS3F,WAAW,CAAC;EACxD;AACJ;AACA;AACA;AACA;EACI/L,WAAWA,CAAA2R,KAAA,EAA6B;IAAA,IAA5B;MAAEC,UAAU;MAAEL;IAAW,CAAC,GAAAI,KAAA;IAClC,KAAK,CAAC,CAAC;IACP,IAAI,CAACC,UAAU,GAAGA,UAAU;IAC5B,IAAI,CAACL,UAAU,GAAGA,UAAU;EAChC;AACJ;AACA;;AAGA;AACA;AACA,OAAO,MAAMM,qBAAqB,SAAS5K,eAAe,CAAC;AAAG;AAE9D,OAAO,MAAM6K,WAAW,SAASD,qBAAqB,CAAC;EACnD;AACJ;AACA;AACA;AACA;AACA;EACI,MAAM5I,QAAQA,CAAA,EAAU;IACpB,MAAMxH,KAAK,CACP,0LACJ,CAAC;EACL;AACJ;AAEA,OAAO,MAAMsQ,aAAa,SAASF,qBAAqB,CAAC;EAErD;AACJ;AACA;AACA;AACA;AACA;AACA;EACI7R,WAAWA,CAACwD,MAAM,EAAEvC,OAAO,EAAE4D,sBAAsB,EAAEoD,iBAAiB,EAAE;IACpE,KAAK,CAACzE,MAAM,EAAEvC,OAAO,CAAC;IACtB,IAAI,CAAC4D,sBAAsB,GAAGA,sBAAsB;IACpD,IAAI,CAACoD,iBAAiB,GAAGA,iBAAiB;IAE1C,IAAI,CAAC0D,kBAAkB,GAAG,IAAI,CAACnI,MAAM,CAACqL,cAAc;IACpD,IAAI,CAACpD,iBAAiB,GAAG,IAAI,CAACjI,MAAM,CAACsL,uBAAuB;IAC5D,IAAI,CAACpD,cAAc,GAAG,IAAI,CAAClI,MAAM,CAACuL,OAAO,GAAG,IAAI,CAACtD,iBAAiB;IAElE,IAAI,CAACF,kBAAkB,GAAG,IAAI,CAAC/H,MAAM,CAACwL,cAAc;IACpD,IAAI,CAAC5D,iBAAiB,GAAG,IAAI,CAAC5H,MAAM,CAACyL,uBAAuB;IAC5D,IAAI,CAAC5D,cAAc,GAAG,IAAI,CAAC7H,MAAM,CAACuL,OAAO,GAAG,IAAI,CAAC3D,iBAAiB;EACtE;;EAEA;AACJ;AACA;AACA;AACA;AACA;AACA;EACIzB,aAAaA,CAACzI,MAAM,EAAEqE,eAAe,EAAW;IAC5C,OAAOF,iBAAiB,CAAC,IAAI,EAAEnE,MAAM,EAAEqE,eAAe,CAAC;EAC3D;;EAEA;AACJ;AACA;AACA;AACA;EACI,MAAMsE,OAAOA,CAAC3D,IAAI,EAAE;IAChB,OAAO,MAAMD,cAAc,CAAC,IAAI,EAAEC,IAAI,CAAC;EAC3C;;EAEA;AACJ;AACA;AACA;EACI+D,UAAUA,CAAC/D,IAAI,EAAEc,UAAU,EAAE;IACzBd,IAAI,CAACL,gBAAgB,GAAG,CAAC,GAAGK,IAAI,CAACL,gBAAgB,EAAEmB,UAAU,CAAC;EAClE;;EAEA;AACJ;AACA;AACA;EACI,MAAMpH,OAAOA,CAACE,YAAY,EAAE;IACxB,OAAO,MAAMoE,cAAc,CAAC,IAAI,EAAEpE,YAAY,CAAC;EACnD;AACJ;AACA;;AAEA;AACA;AACA,OAAO,MAAMkS,qBAAqB,SAAS/K,eAAe,CAAC;AAAG;AAE9D,OAAO,MAAMgL,WAAW,SAASD,qBAAqB,CAAC;EACnD;AACJ;AACA;AACA;AACA;AACA;EACI,MAAM/I,QAAQA,CAAA,EAAU;IACpB,MAAMxH,KAAK,CACP,2MACJ,CAAC;EACL;AACJ;AAEA,OAAO,MAAMyQ,8BAA8B,SAASF,qBAAqB,CAAC;EAEtE;AACJ;AACA;AACA;AACA;AACA;AACA;EACIhS,WAAWA,CAACwD,MAAM,EAAEvC,OAAO,EAAE4D,sBAAsB,EAAEoD,iBAAiB,EAAE;IACpE,KAAK,CAACzE,MAAM,EAAEvC,OAAO,CAAC;IACtB,IAAI,CAAC4D,sBAAsB,GAAGA,sBAAsB;IACpD,IAAI,CAACoD,iBAAiB,GAAGA,iBAAiB;IAE1C,IAAI,CAAC0D,kBAAkB,GAAG,IAAI,CAACnI,MAAM,CAACqL,cAAc;IACpD,IAAI,CAACpD,iBAAiB,GAAG,IAAI,CAACjI,MAAM,CAACsL,uBAAuB;IAC5D,IAAI,CAACpD,cAAc,GAAG,IAAI,CAAClI,MAAM,CAACuL,OAAO,GAAG,IAAI,CAACtD,iBAAiB;IAElE,IAAI,CAACF,kBAAkB,GAAG,IAAI,CAAC/H,MAAM,CAACwL,cAAc;IACpD,IAAI,CAAC5D,iBAAiB,GAAG,IAAI,CAAC5H,MAAM,CAACyL,uBAAuB;IAC5D,IAAI,CAAC5D,cAAc,GAAG,IAAI,CAAC7H,MAAM,CAACuL,OAAO,GAAG,IAAI,CAAC3D,iBAAiB;EACtE;;EAGA;AACJ;AACA;AACA;AACA;AACA;AACA;EACIzB,aAAaA,CAACzI,MAAM,EAAEqE,eAAe,EAAW;IAC5C,OAAOF,iBAAiB,CAAC,IAAI,EAAEnE,MAAM,EAAEqE,eAAe,CAAC;EAC3D;;EAEA;AACJ;AACA;AACA;AACA;EACI,MAAMsE,OAAOA,CAAC3D,IAAI,EAAE;IAChB,OAAO,MAAMD,cAAc,CAAC,IAAI,EAAEC,IAAI,CAAC;EAC3C;;EAEA;AACJ;AACA;AACA;EACI+D,UAAUA,CAAC/D,IAAI,EAAEc,UAAU,EAAE;IACzBd,IAAI,CAACL,gBAAgB,GAAG,CAAC,GAAGK,IAAI,CAACL,gBAAgB,EAAEmB,UAAU,CAAC;EAClE;;EAEA;AACJ;AACA;AACA;EACI,MAAMpH,OAAOA,CAACE,YAAY,EAAE;IACxB,OAAO,MAAMoE,cAAc,CAAC,IAAI,EAAEpE,YAAY,CAAC;EACnD;AACJ;AACA;;AAGA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO,MAAMqS,eAAe,CAAC;EACzB;AACJ;AACA;AACA;EACI,OAAOC,oBAAoB,GAAG,IAAI;;EAElC;AACJ;AACA;AACA;EACI,OAAOC,YAAY,GAAG,KAAK;;EAG3B;EACA,aAAa7K,eAAeA,CAACnH,6BAA6B,EAOlD;IAAA,IAPoD;MACxDI,SAAS,GAAG,IAAI;MAChBgH,iBAAiB,GAAG,IAAI;MACxBjE,MAAM,GAAG,IAAI;MACbkE,SAAS,GAAG,IAAI;MAChBC,gBAAgB,GAAG,KAAK;MACxBC,QAAQ,GAAG;IACf,CAAC,GAAAxD,SAAA,CAAAvD,MAAA,QAAAuD,SAAA,QAAA7C,SAAA,GAAA6C,SAAA,MAAG,CAAC,CAAC;IAEF,IAAI7D,OAAO,GAAG;MACVE,SAAS;MACTgH,iBAAiB;MACjBjE,MAAM;MACNkE,SAAS;MACTC,gBAAgB;MAChBC;IACJ,CAAC;IACDpE,MAAM,GAAG,MAAMzF,UAAU,CAACyJ,eAAe,CAACnH,6BAA6B,EAAEE,OAAO,CAAC;IAEjF,IAAI,CAAC,IAAI,CAAC6R,oBAAoB,EAAE;MAC5B,MAAM,IAAI3Q,KAAK,CAAC,uEAAuE,GAAG,IAAI,CAACxB,IAAI,CAAC;IACxG;IAEA,IAAIqS,UAAU;IACd,KAAK,IAAI3S,mBAAmB,IAAI,IAAI,CAACyS,oBAAoB,EAAE;MACvDE,UAAU,GAAG3S,mBAAmB,CAACI,GAAG,CAACyD,MAAM,CAAC+O,UAAU,CAAC;MACvD,IAAI,CAACD,UAAU,EAAE;QACb,SAAS,CAAC;MACd;;MAEA,OAAO,MAAMA,UAAU,CAAC9K,eAAe,CAACnH,6BAA6B,EAAEE,OAAO,CAAC;IACnF;IAEA,IAAI,IAAI,CAAC8R,YAAY,EAAE;MACnBvR,OAAO,CAACC,IAAI,CAAE,wBAAuByC,MAAM,CAAC+O,UAAW,6CAA4C,CAAC;MACpG,OAAO,MAAMtL,eAAe,CAACO,eAAe,CAACnH,6BAA6B,EAAEE,OAAO,CAAC;IACxF,CAAC,MAAM;MACH,MAAMkB,KAAK,CAAE,2BAA0B+B,MAAM,CAAC+O,UAAW,EAAC,CAAC;IAC/D;EACJ;AACJ;AAEA,MAAMC,gCAAgC,GAAG,IAAI9S,GAAG,CAAC,CAC7C,CAAC,MAAM,EAAE2M,SAAS,CAAC,EACnB,CAAC,QAAQ,EAAE0B,WAAW,CAAC,EACvB,CAAC,YAAY,EAAEhB,eAAe,CAAC,EAC/B,CAAC,SAAS,EAAEqC,YAAY,CAAC,EACzB,CAAC,MAAM,EAAEc,SAAS,CAAC,EACnB,CAAC,YAAY,EAAE7C,eAAe,CAAC,EAC/B,CAAC,aAAa,EAAEK,gBAAgB,CAAC,EAEjC,CAAC,KAAK,EAAE+D,QAAQ,CAAC,CAAE;AAAA,CACtB,CAAC;;AAEF,MAAMgB,mCAAmC,GAAG,IAAI/S,GAAG,CAAC,CAChD,CAAC,IAAI,EAAE0O,OAAO,CAAC,EACf,CAAC,KAAK,EAAEI,QAAQ,CAAC,EACjB,CAAC,MAAM,EAAEG,SAAS,CAAC,EACnB,CAAC,QAAQ,EAAEmD,WAAW,CAAC,EACvB,CAAC,SAAS,EAAErC,YAAY,CAAC,EACzB,CAAC,SAAS,EAAEwC,WAAW,CAAC,CAC3B,CAAC;AAGF,MAAMS,gCAAgC,GAAG,IAAIhT,GAAG,CAAC,CAC7C,CAAC,MAAM,EAAE0Q,SAAS,CAAC,EACnB,CAAC,SAAS,EAAEI,WAAW,CAAC,EACxB,CAAC,SAAS,EAAEG,YAAY,CAAC,CAC5B,CAAC;AAEF,MAAMgC,+CAA+C,GAAG,IAAIjT,GAAG,CAAC,CAC5D,CAAC,MAAM,EAAE8M,6BAA6B,CAAC,EACvC,CAAC,QAAQ,EAAEwB,+BAA+B,CAAC,EAC3C,CAAC,YAAY,EAAEhB,mCAAmC,CAAC,EACnD,CAAC,SAAS,EAAEsC,gCAAgC,CAAC,EAC7C,CAAC,MAAM,EAAEJ,6BAA6B,CAAC,EACvC,CAAC,YAAY,EAAE3B,mCAAmC,CAAC,EACnD,CAAC,aAAa,EAAEK,oCAAoC,CAAC,CACxD,CAAC;AAEF,MAAMgF,4CAA4C,GAAG,IAAIlT,GAAG,CAAC,CACzD,CAAC,MAAM,EAAEgN,0BAA0B,CAAC,EACpC,CAAC,YAAY,EAAEO,gCAAgC,CAAC,CACnD,CAAC;AAEF,MAAM4F,iCAAiC,GAAG,IAAInT,GAAG,CAAC,CAC9C,CAAC,IAAI,EAAE2O,0BAA0B,CAAC,EAClC,CAAC,KAAK,EAAEI,2BAA2B,CAAC,EACpC,CAAC,MAAM,EAAEG,4BAA4B,CAAC,EACtC,CAAC,SAAS,EAAEc,+BAA+B,CAAC,EAC5C,CAAC,QAAQ,EAAEqC,aAAa,CAAC,EACzB,CAAC,SAAS,EAAEG,8BAA8B,CAAC,CAC9C,CAAC;AAEF,MAAMY,gCAAgC,GAAG,IAAIpT,GAAG,CAAC,CAC7C,CAAC,MAAM,EAAE2Q,eAAe,CAAC,EACzB,CAAC,SAAS,EAAEI,iBAAiB,CAAC,EAC9B,CAAC,SAAS,EAAEG,kBAAkB,CAAC,CAClC,CAAC;AAEF,MAAMmC,iCAAiC,GAAG,IAAIrT,GAAG,CAAC,CAC9C,CAAC,MAAM,EAAE4M,eAAe,CAAC,EACzB,CAAC,QAAQ,EAAE4B,iBAAiB,CAAC,EAC7B,CAAC,YAAY,EAAEf,qBAAqB,CAAC,EACrC,CAAC,SAAS,EAAEkC,kBAAkB,CAAC,EAC/B,CAAC,YAAY,EAAE/B,qBAAqB,CAAC,EACrC,CAAC,aAAa,EAAEK,sBAAsB,CAAC,CAC1C,CAAC;AAEF,MAAMqF,0CAA0C,GAAG,IAAItT,GAAG,CAAC,CACvD,CAAC,MAAM,EAAEkN,wBAAwB,CAAC,EAClC,CAAC,QAAQ,EAAEqB,0BAA0B,CAAC,EACtC,CAAC,YAAY,EAAEf,8BAA8B,CAAC,EAC9C,CAAC,SAAS,EAAEqC,2BAA2B,CAAC,EACxC,CAAC,YAAY,EAAE/B,8BAA8B,CAAC,EAC9C,CAAC,aAAa,EAAEK,+BAA+B,CAAC,CACnD,CAAC;AAEF,MAAMoF,oCAAoC,GAAG,IAAIvT,GAAG,CAAC,CACjD,CAAC,wBAAwB,EAAEkQ,yBAAyB,CAAC,CACxD,CAAC;AAEF,MAAMsD,4CAA4C,GAAG,IAAIxT,GAAG,CAAC,CACzD,CAAC,KAAK,EAAEoR,yBAAyB,CAAC,CACrC,CAAC;AAEF,MAAMqC,wCAAwC,GAAG,IAAIzT,GAAG,CAAC,CACrD,CAAC,MAAM,EAAEsR,sBAAsB,CAAC,CACnC,CAAC;AAEF,MAAMoC,0CAA0C,GAAG,IAAI1T,GAAG,CAAC,CACvD,CAAC,MAAM,EAAEwR,mBAAmB,CAAC,CAChC,CAAC;AAEF,MAAMmC,uCAAuC,GAAG,IAAI3T,GAAG,CAAC,CACpD,CAAC,KAAK,EAAE+R,QAAQ,CAAC,CACpB,CAAC;AAEF,MAAM6B,wBAAwB,GAAG,CAC7B,CAACd,gCAAgC,EAAEnT,oBAAoB,CAAC,EACxD,CAACoT,mCAAmC,EAAEnT,uBAAuB,CAAC,EAC9D,CAACoT,gCAAgC,EAAElT,oBAAoB,CAAC,EACxD,CAACmT,+CAA+C,EAAEtT,oBAAoB,CAAC,EACvE,CAACuT,4CAA4C,EAAEvT,oBAAoB,CAAC,EACpE,CAACwT,iCAAiC,EAAEtT,gBAAgB,CAAC,EACrD,CAACuT,gCAAgC,EAAEtT,oBAAoB,CAAC,EACxD,CAACuT,iCAAiC,EAAE1T,oBAAoB,CAAC,EACzD,CAAC2T,0CAA0C,EAAE3T,oBAAoB,CAAC,EAClE,CAAC4T,oCAAoC,EAAE3T,uBAAuB,CAAC,EAC/D,CAAC4T,4CAA4C,EAAE7T,oBAAoB,CAAC,EACpE,CAAC+T,0CAA0C,EAAE/T,oBAAoB,CAAC,EAClE,CAAC8T,wCAAwC,EAAE9T,oBAAoB,CAAC,EAChE,CAACgU,uCAAuC,EAAEhU,oBAAoB,CAAC,CAClE;AAED,KAAK,IAAI,CAACkU,QAAQ,EAAEC,IAAI,CAAC,IAAIF,wBAAwB,EAAE;EACnD;EACA,KAAK,IAAI,CAACrT,IAAI,EAAEwT,KAAK,CAAC,IAAIF,QAAQ,CAACG,OAAO,CAAC,CAAC,EAAE;IAC1CjU,kBAAkB,CAACkU,GAAG,CAACF,KAAK,CAACxT,IAAI,EAAEuT,IAAI,CAAC;IACxC7T,mBAAmB,CAACgU,GAAG,CAACF,KAAK,CAACxT,IAAI,EAAEA,IAAI,CAAC;EAC7C;AACJ;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAM2T,SAAS,SAASzB,eAAe,CAAC;EAC3C,OAAOC,oBAAoB,GAAG,CAACI,gCAAgC,EAAEC,mCAAmC,EAAEC,gCAAgC,CAAC;EACvI,OAAOL,YAAY,GAAG,IAAI;AAC9B;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMwB,kCAAkC,SAAS1B,eAAe,CAAC;EACpE,OAAOC,oBAAoB,GAAG,CAACO,+CAA+C,CAAC;AACnF;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMmB,+BAA+B,SAAS3B,eAAe,CAAC;EACjE,OAAOC,oBAAoB,GAAG,CAACQ,4CAA4C,CAAC;AAChF;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMmB,qBAAqB,SAAS5B,eAAe,CAAC;EACvD,OAAOC,oBAAoB,GAAG,CAACS,iCAAiC,CAAC;AACrE;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMmB,oBAAoB,SAAS7B,eAAe,CAAC;EACtD,OAAOC,oBAAoB,GAAG,CAACU,gCAAgC,CAAC;AACpE;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMmB,oBAAoB,SAAS9B,eAAe,CAAC;EACtD,OAAOC,oBAAoB,GAAG,CAACW,iCAAiC,CAAC;AACrE;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMmB,6BAA6B,SAAS/B,eAAe,CAAC;EAC/D,OAAOC,oBAAoB,GAAG,CAACY,0CAA0C,CAAC;AAC9E;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMmB,sBAAsB,SAAShC,eAAe,CAAC;EACxD,OAAOC,oBAAoB,GAAG,CAACa,oCAAoC,CAAC;AACxE;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMmB,+BAA+B,SAASjC,eAAe,CAAC;EACjE,OAAOC,oBAAoB,GAAG,CAACc,4CAA4C,CAAC;AAChF;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMmB,6BAA6B,SAASlC,eAAe,CAAC;EAC/D,OAAOC,oBAAoB,GAAG,CAACgB,0CAA0C,CAAC;AAC9E;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMkB,2BAA2B,SAASnC,eAAe,CAAC;EAC7D,OAAOC,oBAAoB,GAAG,CAACe,wCAAwC,CAAC;AAC5E;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMoB,0BAA0B,SAASpC,eAAe,CAAC;EAC5D,OAAOC,oBAAoB,GAAG,CAACiB,uCAAuC,CAAC;AAC3E;AACA;;AAEA;AACA,OAAO,MAAMjO,eAAe,SAAS2G,WAAW,CAAC;EAC7C;AACJ;AACA;AACA;AACA;AACA;EACI/L,WAAWA,CAAAwU,KAAA,EAA+C;IAAA,IAA9C;MAAEtP,MAAM;MAAEZ,eAAe;MAAED;IAAgB,CAAC,GAAAmQ,KAAA;IACpD,KAAK,CAAC,CAAC;IACP,IAAI,CAACtP,MAAM,GAAGA,MAAM;IACpB,IAAI,CAACZ,eAAe,GAAGA,eAAe;IACtC,IAAI,CAACD,eAAe,GAAGA,eAAe;EAC1C;AACJ;;AAEA;AACA;AACA;AACA,OAAO,MAAMoI,wBAAwB,SAASV,WAAW,CAAC;EACtD;AACJ;AACA;AACA;EACI/L,WAAWA,CAAAyU,KAAA,EAAa;IAAA,IAAZ;MAAEvP;IAAO,CAAC,GAAAuP,KAAA;IAClB,KAAK,CAAC,CAAC;IACP,IAAI,CAACvP,MAAM,GAAGA,MAAM;EACxB;AACJ;;AAEA;AACA;AACA;AACA,OAAO,MAAMyH,qBAAqB,SAASZ,WAAW,CAAC;EACnD;AACJ;AACA;AACA;EACI/L,WAAWA,CAAA0U,KAAA,EAAa;IAAA,IAAZ;MAAExP;IAAO,CAAC,GAAAwP,KAAA;IAClB,KAAK,CAAC,CAAC;IACP,IAAI,CAACxP,MAAM,GAAGA,MAAM;EACxB;AACJ;;AAEA;AACA;AACA;AACA,OAAO,MAAMqH,cAAc,SAASR,WAAW,CAAC;EAC5C;AACJ;AACA;AACA;EACI/L,WAAWA,CAAA2U,KAAA,EAAa;IAAA,IAAZ;MAAEzP;IAAO,CAAC,GAAAyP,KAAA;IAClB,KAAK,CAAC,CAAC;IACP,IAAI,CAACzP,MAAM,GAAGA,MAAM;EACxB;AACJ;;AAEA;AACA;AACA;AACA,OAAO,MAAM2H,4BAA4B,SAASd,WAAW,CAAC;EAC1D;AACJ;AACA;AACA;AACA;EACI/L,WAAWA,CAAA4U,KAAA,EAA+B;IAAA,IAA9B;MAAEC,YAAY;MAAEC;IAAW,CAAC,GAAAF,KAAA;IACpC,KAAK,CAAC,CAAC;IACP,IAAI,CAACC,YAAY,GAAGA,YAAY;IAChC,IAAI,CAACC,UAAU,GAAGA,UAAU;EAChC;AACJ;;AAGA;AACA;AACA;AACA,OAAO,MAAMC,sBAAsB,SAAShJ,WAAW,CAAC;EACpD;AACJ;AACA;AACA;AACA;AACA;EACI/L,WAAWA,CAAAgV,MAAA,EAA8B;IAAA,IAA7B;MAAE9P,MAAM;MAAEZ;IAAgB,CAAC,GAAA0Q,MAAA;IACnC,KAAK,CAAC,CAAC;IACP,IAAI,CAAC9P,MAAM,GAAGA,MAAM;IACpB,IAAI,CAACZ,eAAe,GAAGA,eAAe;EAC1C;AACJ"},"metadata":{},"sourceType":"module","externalDependencies":[]}