{"ast":null,"code":"/**\n * @file Pipelines provide a high-level, easy to use, API for running machine learning models.\n * \n * **Example:** Instantiate pipeline using the `pipeline` function.\n * ```javascript\n * import { pipeline } from '@xenova/transformers';\n * \n * let pipeline = await pipeline('sentiment-analysis');\n * let result = await pipeline('I love transformers!');\n * // [{'label': 'POSITIVE', 'score': 0.999817686}]\n * ```\n * \n * @module pipelines\n */\n\nimport { AutoTokenizer, PreTrainedTokenizer } from './tokenizers.js';\nimport { AutoModel, AutoModelForSequenceClassification, AutoModelForTokenClassification, AutoModelForQuestionAnswering, AutoModelForMaskedLM, AutoModelForSeq2SeqLM, AutoModelForCausalLM, AutoModelForVision2Seq, AutoModelForImageClassification, AutoModelForImageSegmentation, AutoModelForObjectDetection, PreTrainedModel } from './models.js';\nimport { AutoProcessor, Processor } from './processors.js';\nimport { Callable, isString, dispatchCallback, pop } from './utils/core.js';\nimport { softmax, max, getTopItems } from './utils/maths.js';\nimport { read_audio } from './utils/audio.js';\nimport { mean_pooling } from './utils/tensor.js';\nimport { RawImage } from './utils/image.js';\n\n/**\n * Prepare images for further tasks.\n * @param {any[]} images images to prepare.\n * @returns {Promise<any[]>} returns processed images.\n * @private\n */\nasync function prepareImages(images) {\n  if (!Array.isArray(images)) {\n    images = [images];\n  }\n\n  // Possibly convert any non-images to images\n  images = await Promise.all(images.map(x => RawImage.read(x)));\n  return images;\n}\n\n/**\n * The Pipeline class is the class from which all pipelines inherit.\n * Refer to this class for methods shared across different pipelines.\n * @extends Callable\n */\nexport class Pipeline extends Callable {\n  /**\n   * Create a new Pipeline.\n   * @param {string} task The task of the pipeline. Useful for specifying subtasks.\n   * @param {PreTrainedTokenizer} tokenizer The tokenizer to use.\n   * @param {PreTrainedModel} model The model to use.\n   */\n  constructor(task, tokenizer, model) {\n    super();\n    this.task = task;\n    this.tokenizer = tokenizer;\n    this.model = model;\n  }\n\n  /**\n   * Disposes the model.\n   * @returns {Promise<void>} A promise that resolves when the model has been disposed.\n   */\n  async dispose() {\n    await this.model.dispose();\n  }\n\n  /**\n   * Executes the task associated with the pipeline.\n   * @param {any} texts The input texts to be processed.\n   * @returns {Promise<any>} A promise that resolves to an array containing the inputs and outputs of the task.\n   */\n  async _call(texts) {\n    // Run tokenization\n    let inputs = this.tokenizer(texts, {\n      padding: true,\n      truncation: true\n    });\n\n    // Run model\n    let outputs = await this.model(inputs);\n    return [inputs, outputs];\n  }\n}\n\n/**\n * Text classification pipeline using any `ModelForSequenceClassification`.\n * @extends Pipeline\n */\nexport class TextClassificationPipeline extends Pipeline {\n  /**\n   * Executes the text classification task.\n   * @param {any} texts The input texts to be classified.\n   * @param {Object} options An optional object containing the following properties:\n   * @param {number} [options.topk=1] The number of top predictions to be returned.\n   * @returns {Promise<Object[]|Object>} A promise that resolves to an array or object containing the predicted labels and scores.\n   */\n  async _call(texts) {\n    let {\n      topk = 1\n    } = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    let [inputs, outputs] = await super._call(texts);\n    let id2label = this.model.config.id2label;\n    let toReturn = [];\n    for (let batch of outputs.logits) {\n      let scores = getTopItems(softmax(batch.data), topk);\n      let vals = scores.map(function (x) {\n        return {\n          label: id2label[x[0]],\n          score: x[1]\n        };\n      });\n      if (topk === 1) {\n        toReturn.push(...vals);\n      } else {\n        toReturn.push(vals);\n      }\n    }\n    return Array.isArray(texts) || topk === 1 ? toReturn : toReturn[0];\n  }\n}\n\n/**\n * Named Entity Recognition pipeline using any `ModelForTokenClassification`.\n * @extends Pipeline\n */\nexport class TokenClassificationPipeline extends Pipeline {\n  /**\n   * Executes the token classification task.\n   * @param {any} texts The input texts to be classified.\n   * @param {Object} options An optional object containing the following properties:\n   * @returns {Promise<Object[]|Object>} A promise that resolves to an array or object containing the predicted labels and scores.\n   */\n  async _call(texts) {\n    let {\n      ignore_labels = ['O'] // TODO init param?\n    } = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    let isBatched = Array.isArray(texts);\n    if (!isBatched) {\n      texts = [texts];\n    }\n    let tokenizer = this.tokenizer;\n    let [inputs, outputs] = await super._call(texts);\n    let logits = outputs.logits;\n    let id2label = this.model.config.id2label;\n    let toReturn = [];\n    for (let i = 0; i < logits.dims[0]; ++i) {\n      let ids = inputs.input_ids[i];\n      let batch = logits[i];\n\n      // List of tokens that aren't ignored\n      let tokens = [];\n      for (let j = 0; j < batch.dims[0]; ++j) {\n        let tokenData = batch[j];\n        let topScoreIndex = max(tokenData.data)[1];\n        let entity = id2label[topScoreIndex];\n        if (ignore_labels.includes(entity)) {\n          // We predicted a token that should be ignored. So, we skip it.\n          continue;\n        }\n\n        // TODO add option to keep special tokens?\n        let word = tokenizer.decode([ids[j].item()], {\n          skip_special_tokens: true\n        });\n        if (word === '') {\n          // Was a special token. So, we skip it.\n          continue;\n        }\n        let scores = softmax(tokenData.data);\n        tokens.push({\n          entity: entity,\n          score: scores[topScoreIndex],\n          index: j,\n          word: word,\n          // TODO: null for now, but will add\n          start: null,\n          end: null\n        });\n      }\n      toReturn.push(tokens);\n    }\n    return isBatched ? toReturn : toReturn[0];\n  }\n}\n/**\n * Question Answering pipeline using any `ModelForQuestionAnswering`.\n * \n * **Example:** Run question answering with `distilbert-base-uncased-distilled-squad`.\n * ```javascript\n * let question = 'Who was Jim Henson?';\n * let context = 'Jim Henson was a nice puppet.';\n * \n * let answerer = await pipeline('question-answering', 'Xenova/distilbert-base-uncased-distilled-squad');\n * let outputs = await answerer(question, context);\n * console.log(outputs);\n * // {\n * //     \"answer\": \"a nice puppet\",\n * //     \"score\": 0.5768911502526741\n * // }\n * ```\n * @extends Pipeline\n */\nexport class QuestionAnsweringPipeline extends Pipeline {\n  /**\n   * Executes the question answering task.\n   * @param {string|string[]} question The question(s) to be answered.\n   * @param {string|string[]} context The context(s) where the answer(s) can be found.\n   * @param {Object} options An optional object containing the following properties:\n   * @param {number} [options.topk=1] The number of top answer predictions to be returned.\n   * @returns {Promise<any>} A promise that resolves to an array or object containing the predicted answers and scores.\n   */\n  // @ts-ignore\n  async _call(question, context) {\n    let {\n      topk = 1\n    } = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n    let inputs = this.tokenizer(question, {\n      text_pair: context\n    });\n    let output = await this.model(inputs);\n    let toReturn = [];\n    for (let j = 0; j < output.start_logits.dims[0]; ++j) {\n      let ids = inputs.input_ids[j];\n      let sepIndex = ids.indexOf(this.tokenizer.sep_token_id);\n      let s1 = Array.from(softmax(output.start_logits[j].data)).map((x, i) => [x, i]).filter(x => x[1] > sepIndex);\n      let e1 = Array.from(softmax(output.end_logits[j].data)).map((x, i) => [x, i]).filter(x => x[1] > sepIndex);\n      let options = product(s1, e1).filter(x => x[0][1] <= x[1][1]).map(x => [x[0][1], x[1][1], x[0][0] * x[1][0]]).sort((a, b) => b[2] - a[2]);\n      for (let k = 0; k < Math.min(options.length, topk); ++k) {\n        let [start, end, score] = options[k];\n        let answer_tokens = [...ids].slice(start, end + 1);\n        let answer = this.tokenizer.decode(answer_tokens, {\n          skip_special_tokens: true\n        });\n\n        // TODO add start and end?\n        // NOTE: HF returns character index\n        toReturn.push({\n          answer,\n          score\n        });\n      }\n    }\n\n    // Mimic HF's return type based on topk\n    return topk === 1 ? toReturn[0] : toReturn;\n  }\n}\n\n/**\n * Masked language modeling prediction pipeline using any `ModelWithLMHead`.\n * @extends Pipeline\n */\nexport class FillMaskPipeline extends Pipeline {\n  /**\n   * Fill the masked token in the text(s) given as inputs.\n   * @param {any} texts The masked input texts.\n   * @param {Object} options An optional object containing the following properties:\n   * @param {number} [options.topk=5] The number of top predictions to be returned.\n   * @returns {Promise<Object[]|Object>} A promise that resolves to an array or object containing the predicted tokens and scores.\n   */\n  async _call(texts) {\n    let {\n      topk = 5\n    } = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    // Run tokenization\n    let [inputs, outputs] = await super._call(texts);\n\n    // Determine indices of mask tokens\n    // let mask_token_indices = inputs.input_ids.data.map(x => )\n\n    // let logits = reshape(outputs.logits.data, outputs.logits.dims);\n\n    let tokenizer = this.tokenizer;\n    let toReturn = [];\n    for (let i = 0; i < inputs.input_ids.dims[0]; ++i) {\n      let ids = inputs.input_ids[i];\n      let mask_token_index = ids.indexOf(this.tokenizer.mask_token_id);\n      if (mask_token_index === -1) {\n        throw Error(`Mask token (${tokenizer.mask_token}) not found in text.`);\n      }\n      let logits = outputs.logits[i];\n      let itemLogits = logits[mask_token_index];\n      let scores = getTopItems(softmax(itemLogits.data), topk);\n      toReturn.push(scores.map(x => {\n        let sequence = [...ids];\n        sequence[mask_token_index] = x[0];\n        return {\n          score: x[1],\n          token: x[0],\n          token_str: tokenizer.model.vocab[x[0]],\n          sequence: tokenizer.decode(sequence, {\n            skip_special_tokens: true\n          })\n        };\n      }));\n    }\n    return Array.isArray(texts) ? toReturn : toReturn[0];\n  }\n}\n\n/**\n * Text2TextGenerationPipeline class for generating text using a model that performs text-to-text generation tasks.\n * @extends Pipeline\n */\nexport class Text2TextGenerationPipeline extends Pipeline {\n  _key = null;\n\n  /**\n   * Fill the masked token in the text(s) given as inputs.\n   * @param {string|string[]} texts The text or array of texts to be processed.\n   * @param {Object} [options={}] Options for the fill-mask pipeline.\n   * @param {number} [options.topk=5] The number of top-k predictions to return.\n   * @returns {Promise<any>} An array of objects containing the score, predicted token, predicted token string,\n   * and the sequence with the predicted token filled in, or an array of such arrays (one for each input text).\n   * If only one input text is given, the output will be an array of objects.\n   * @throws {Error} When the mask token is not found in the input text.\n   */\n  async _call(texts) {\n    let generate_kwargs = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    if (!Array.isArray(texts)) {\n      texts = [texts];\n    }\n\n    // Add global prefix, if present\n    if (this.model.config.prefix) {\n      texts = texts.map(x => this.model.config.prefix + x);\n    }\n\n    // Handle task specific params:\n    let task_specific_params = this.model.config.task_specific_params;\n    if (task_specific_params && task_specific_params[this.task]) {\n      // Add prefixes, if present\n      if (task_specific_params[this.task].prefix) {\n        texts = texts.map(x => task_specific_params[this.task].prefix + x);\n      }\n\n      // TODO update generation config\n    }\n\n    let tokenizer_options = {\n      padding: true,\n      truncation: true\n    };\n    let input_ids;\n    if (this instanceof TranslationPipeline && '_build_translation_inputs' in this.tokenizer) {\n      // TODO: move to Translation pipeline?\n      // Currently put here to avoid code duplication\n      // @ts-ignore\n      input_ids = this.tokenizer._build_translation_inputs(texts, tokenizer_options, generate_kwargs).input_ids;\n    } else {\n      input_ids = this.tokenizer(texts, tokenizer_options).input_ids;\n    }\n    let outputTokenIds = await this.model.generate(input_ids, generate_kwargs);\n\n    /**\n     * @type {any[]}\n     */\n    let toReturn = this.tokenizer.batch_decode(outputTokenIds, {\n      skip_special_tokens: true\n    });\n    if (this._key !== null) {\n      toReturn = toReturn.map(text => {\n        return this._key === null ? text : {\n          [this._key]: text\n        };\n      });\n    }\n    return toReturn;\n  }\n}\n\n/**\n * A pipeline for summarization tasks, inheriting from Text2TextGenerationPipeline.\n * @extends Text2TextGenerationPipeline\n */\nexport class SummarizationPipeline extends Text2TextGenerationPipeline {\n  _key = 'summary_text';\n}\n\n/**\n * TranslationPipeline class to translate text from one language to another using the provided model and tokenizer.\n * @extends Text2TextGenerationPipeline\n */\nexport class TranslationPipeline extends Text2TextGenerationPipeline {\n  _key = 'translation_text';\n}\n\n/**\n * Language generation pipeline using any `ModelWithLMHead`.\n * This pipeline predicts the words that will follow a specified text prompt.\n * @extends Pipeline\n */\nexport class TextGenerationPipeline extends Pipeline {\n  /**\n   * Generates text based on an input prompt.\n   * @param {any} texts The input prompt or prompts to generate text from.\n   * @param {Object} [generate_kwargs={}] Additional arguments for text generation.\n   * @returns {Promise<any>} The generated text or texts.\n   */\n  async _call(texts) {\n    let generate_kwargs = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    let stringInput = typeof texts === 'string' || texts instanceof String;\n    if (stringInput) {\n      texts = [texts];\n    }\n    this.tokenizer.padding_side = 'left';\n    let inputs = this.tokenizer(texts, {\n      padding: true,\n      truncation: true\n    });\n    let input_ids = inputs.input_ids;\n    let attention_mask = inputs.attention_mask;\n    let outputTokenIds = await this.model.generate(input_ids, generate_kwargs, null, {\n      inputs_attention_mask: attention_mask\n    });\n    const trimmedTexts = texts.map(x => x.trim());\n    const decoded = this.tokenizer.batch_decode(outputTokenIds, {\n      skip_special_tokens: true\n    });\n    const toReturn = Array.from({\n      length: texts.length\n    }, _ => []);\n    for (let i = 0; i < decoded.length; ++i) {\n      const textIndex = Math.floor(i / outputTokenIds.length * trimmedTexts.length);\n      let startText = trimmedTexts[textIndex];\n      toReturn[textIndex].push({\n        generated_text: startText + decoded[i]\n      });\n    }\n    return stringInput && toReturn.length === 1 ? toReturn[0] : toReturn;\n  }\n}\n\n/**\n * NLI-based zero-shot classification pipeline using a `ModelForSequenceClassification`\n * trained on NLI (natural language inference) tasks. Equivalent of `text-classification`\n * pipelines, but these models don't require a hardcoded number of potential classes, they\n * can be chosen at runtime. It usually means it's slower but it is **much** more flexible.\n * @extends Pipeline\n */\nexport class ZeroShotClassificationPipeline extends Pipeline {\n  /**\n   * Create a new ZeroShotClassificationPipeline.\n   * @param {string} task The task of the pipeline. Useful for specifying subtasks.\n   * @param {PreTrainedTokenizer} tokenizer The tokenizer to use.\n   * @param {PreTrainedModel} model The model to use.\n   */\n  constructor(task, tokenizer, model) {\n    super(task, tokenizer, model);\n\n    // Use model config to get label2id mapping\n    this.label2id = Object.fromEntries(Object.entries(this.model.config.label2id).map(_ref => {\n      let [k, v] = _ref;\n      return [k.toLowerCase(), v];\n    }));\n    this.entailment_id = this.label2id['entailment'];\n    if (this.entailment_id === undefined) {\n      console.warn(\"Could not find 'entailment' in label2id mapping. Using 2 as entailment_id.\");\n      this.entailment_id = 2;\n    }\n    this.contradiction_id = this.label2id['contradiction'];\n    if (this.contradiction_id === undefined) {\n      console.warn(\"Could not find 'contradiction' in label2id mapping. Using 0 as contradiction_id.\");\n      this.contradiction_id = 0;\n    }\n  }\n  /**\n   * @param {any[]} texts\n   * @param {string[]} candidate_labels\n   * @param {Object} options Additional options:\n   * @param {string} [options.hypothesis_template=\"This example is {}.\"] The template used to turn each\n   * candidate label into an NLI-style hypothesis. The candidate label will replace the {} placeholder.\n   * @param {boolean} [options.multi_label=false] Whether or not multiple candidate labels can be true.\n   * If `false`, the scores are normalized such that the sum of the label likelihoods for each sequence\n   * is 1. If `true`, the labels are considered independent and probabilities are normalized for each\n   * candidate by doing a softmax of the entailment score vs. the contradiction score.\n   * @return {Promise<Object|Object[]>} The prediction(s), as a map (or list of maps) from label to score.\n   */\n  // @ts-ignore\n  async _call(texts, candidate_labels) {\n    let {\n      hypothesis_template = \"This example is {}.\",\n      multi_label = false\n    } = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n    let isBatched = Array.isArray(texts);\n    if (!isBatched) {\n      texts = [texts];\n    }\n    if (!Array.isArray(candidate_labels)) {\n      candidate_labels = [candidate_labels];\n    }\n\n    // Insert labels into hypothesis template\n    let hypotheses = candidate_labels.map(x => hypothesis_template.replace('{}', x));\n\n    // How to perform the softmax over the logits:\n    //  - true:  softmax over the entailment vs. contradiction dim for each label independently\n    //  - false: softmax the \"entailment\" logits over all candidate labels\n    let softmaxEach = multi_label || candidate_labels.length === 1;\n    let toReturn = [];\n    for (let premise of texts) {\n      let entails_logits = [];\n      for (let hypothesis of hypotheses) {\n        let inputs = this.tokenizer(premise, {\n          text_pair: hypothesis\n        });\n        let outputs = await this.model(inputs);\n        if (softmaxEach) {\n          entails_logits.push([outputs.logits.data[this.contradiction_id], outputs.logits.data[this.entailment_id]]);\n        } else {\n          entails_logits.push(outputs.logits.data[this.entailment_id]);\n        }\n      }\n      let scores;\n      if (softmaxEach) {\n        scores = entails_logits.map(x => softmax(x)[1]);\n      } else {\n        scores = softmax(entails_logits);\n      }\n\n      // Sort by scores (desc) and return scores with indices\n      let scores_sorted = scores.map((x, i) => [x, i]).sort((a, b) => {\n        return b[0] - a[0];\n      });\n      toReturn.push({\n        sequence: premise,\n        labels: scores_sorted.map(x => candidate_labels[x[1]]),\n        scores: scores_sorted.map(x => x[0])\n      });\n    }\n    return isBatched ? toReturn : toReturn[0];\n  }\n}\n\n/**\n * Feature extraction pipeline using no model head. This pipeline extracts the hidden\n * states from the base transformer, which can be used as features in downstream tasks.\n * \n * **Example:** Run feature extraction with `bert-base-uncased` (without pooling/normalization).\n * ```javascript\n * let extractor = await pipeline('feature-extraction', 'Xenova/bert-base-uncased', { revision: 'default' });\n * let result = await extractor('This is a simple test.');\n * console.log(result);\n * // Tensor {\n * //     type: 'float32',\n * //     data: Float32Array [0.05939924716949463, 0.021655935794115067, ...],\n * //     dims: [1, 8, 768]\n * // }\n * ```\n * \n * **Example:** Run feature extraction with `bert-base-uncased` (with pooling/normalization).\n * ```javascript\n * let extractor = await pipeline('feature-extraction', 'Xenova/bert-base-uncased', { revision: 'default' });\n * let result = await extractor('This is a simple test.', { pooling: 'mean', normalize: true });\n * console.log(result);\n * // Tensor {\n * //     type: 'float32',\n * //     data: Float32Array [0.03373778983950615, -0.010106077417731285, ...],\n * //     dims: [1, 768]\n * // }\n * ```\n * \n * **Example:** Calculating embeddings with `sentence-transformers` models.\n * ```javascript\n * let extractor = await pipeline('feature-extraction', 'Xenova/all-MiniLM-L6-v2');\n * let result = await extractor('This is a simple test.', { pooling: 'mean', normalize: true });\n * console.log(result);\n * // Tensor {\n * //     type: 'float32',\n * //     data: Float32Array [0.09094982594251633, -0.014774246141314507, ...],\n * //     dims: [1, 384]\n * // }\n * ```\n * @extends Pipeline\n */\nexport class FeatureExtractionPipeline extends Pipeline {\n  /**\n   * Extract the features of the input(s).\n   * \n   * @param {string|string[]} texts The input texts\n   * @param {Object} options Additional options:\n   * @param {string} [options.pooling=\"none\"] The pooling method to use. Can be one of: \"none\", \"mean\".\n   * @param {boolean} [options.normalize=false] Whether or not to normalize the embeddings in the last dimension.\n   * @returns The features computed by the model.\n   */\n  async _call(texts) {\n    let {\n      pooling = 'none',\n      normalize = false\n    } = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    let [inputs, outputs] = await super._call(texts);\n\n    // TODO: Provide warning to the user that they might be using model which was not exported\n    // specifically for feature extraction\n    // console.log(this.model.config)\n    // console.log(outputs)\n\n    let result = outputs.last_hidden_state ?? outputs.logits;\n    if (pooling === 'none') {\n      // Skip pooling\n    } else if (pooling === 'mean') {\n      result = mean_pooling(result, inputs.attention_mask);\n    } else {\n      throw Error(`Pooling method '${pooling}' not supported.`);\n    }\n    if (normalize) {\n      result = result.normalize(2, -1);\n    }\n    return result;\n  }\n}\n\n// TODO\n// export class SentenceSimilarityPipeline extends Pipeline {\n// }\n\n/**\n * Pipeline that aims at extracting spoken text contained within some audio.\n *\n * **Example:** Transcribe English.\n * ```javascript\n * let url = 'https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/jfk.wav';\n * let transcriber = await pipeline('automatic-speech-recognition', 'Xenova/whisper-tiny.en');\n * let output = await transcriber(url);\n * // { text: \" And so my fellow Americans ask not what your country can do for you, ask what you can do for your country.\" }\n * ```\n * \n * **Example:** Transcribe English w/ timestamps.\n * ```javascript\n * let url = 'https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/jfk.wav';\n * let transcriber = await pipeline('automatic-speech-recognition', 'Xenova/whisper-tiny.en');\n * let output = await transcriber(url, { return_timestamps: true });\n * // {\n * //   text: \" And so my fellow Americans ask not what your country can do for you, ask what you can do for your country.\"\n * //   chunks: [\n * //     { timestamp: [0, 8],  text: \" And so my fellow Americans ask not what your country can do for you\" }\n * //     { timestamp: [8, 11], text: \" ask what you can do for your country.\" }\n * //   ]\n * // }\n * ```\n * \n * **Example:** Transcribe French.\n * ```javascript\n * let url = 'https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/french-audio.mp3';\n * let transcriber = await pipeline('automatic-speech-recognition', 'Xenova/whisper-small');\n * let output = await transcriber(url, { language: 'french', task: 'transcribe' });\n * // { text: \" J'adore, j'aime, je n'aime pas, je d√©teste.\" }\n * ```\n * \n * **Example:** Translate French to English.\n * ```javascript\n * let url = 'https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/french-audio.mp3';\n * let transcriber = await pipeline('automatic-speech-recognition', 'Xenova/whisper-small');\n * let output = await transcriber(url, { language: 'french', task: 'translate' });\n * // { text: \" I love, I like, I don't like, I hate.\" }\n * ```\n * @extends Pipeline\n */\nexport class AutomaticSpeechRecognitionPipeline extends Pipeline {\n  /**\n   * Create a new AutomaticSpeechRecognitionPipeline.\n   * @param {string} task The task of the pipeline. Useful for specifying subtasks.\n   * @param {PreTrainedTokenizer} tokenizer The tokenizer to use.\n   * @param {PreTrainedModel} model The model to use.\n   * @param {Processor} processor The processor to use.\n   */\n  constructor(task, tokenizer, model, processor) {\n    super(task, tokenizer, model);\n    this.processor = processor;\n  }\n\n  /**\n   * Preprocesses the input audio for the AutomaticSpeechRecognitionPipeline.\n   * @param {any} audio The audio to be preprocessed.\n   * @param {number} sampling_rate The sampling rate of the audio.\n   * @returns {Promise<Float32Array>} A promise that resolves to the preprocessed audio data.\n   * @private\n   */\n  async _preprocess(audio, sampling_rate) {\n    if (isString(audio)) {\n      audio = await read_audio(audio, sampling_rate);\n    }\n    return audio;\n  }\n\n  /**\n   * @typedef {import('./utils/tensor.js').Tensor} Tensor\n   * @typedef {{stride: number[], input_features: Tensor, is_last: boolean, tokens?: number[]}} Chunk\n   * \n   * @callback ChunkCallback\n   * @param {Chunk} chunk The chunk to process.\n   */\n\n  /**\n   * Asynchronously processes audio and generates text transcription using the model.\n   * @param {Float32Array|Float32Array[]} audio The audio to be transcribed. Can be a single Float32Array or an array of Float32Arrays.\n   * @param {Object} [kwargs={}] Optional arguments.\n   * @param {boolean} [kwargs.return_timestamps] Whether to return timestamps or not. Default is `false`.\n   * @param {number} [kwargs.chunk_length_s] The length of audio chunks to process in seconds. Default is 0 (no chunking).\n   * @param {number} [kwargs.stride_length_s] The length of overlap between consecutive audio chunks in seconds. If not provided, defaults to `chunk_length_s / 6`.\n   * @param {ChunkCallback} [kwargs.chunk_callback] Callback function to be called with each chunk processed.\n   * @param {boolean} [kwargs.force_full_sequences] Whether to force outputting full sequences or not. Default is `false`.\n   * @param {string} [kwargs.language] The source language. Default is `null`, meaning it should be auto-detected. Use this to potentially improve performance if the source language is known.\n   * @param {string} [kwargs.task] The task to perform. Default is `null`, meaning it should be auto-detected.\n   * @param {number[][]} [kwargs.forced_decoder_ids] A list of pairs of integers which indicates a mapping from generation indices to token indices\n   * that will be forced before sampling. For example, [[1, 123]] means the second generated token will always be a token of index 123.\n   * @returns {Promise<Object>} A Promise that resolves to an object containing the transcription text and optionally timestamps if `return_timestamps` is `true`.\n   */\n  async _call(audio) {\n    let kwargs = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    let return_timestamps = kwargs.return_timestamps ?? false;\n    let chunk_length_s = kwargs.chunk_length_s ?? 0;\n    let stride_length_s = kwargs.stride_length_s ?? null;\n    let chunk_callback = kwargs.chunk_callback ?? null;\n    let force_full_sequences = kwargs.force_full_sequences ?? false;\n    let language = pop(kwargs, 'language', null);\n    let task = pop(kwargs, 'task', null);\n    if (language || task || return_timestamps) {\n      if (kwargs.forced_decoder_ids) {\n        throw new Error(\"Cannot specify `language`/`task`/`return_timestamps` and `forced_decoder_ids` at the same time.\");\n      }\n      // @ts-ignore\n      let decoder_prompt_ids = this.tokenizer.get_decoder_prompt_ids({\n        language,\n        task,\n        no_timestamps: !return_timestamps\n      });\n      if (decoder_prompt_ids.length > 0) {\n        kwargs.forced_decoder_ids = decoder_prompt_ids;\n      }\n    }\n    let single = !Array.isArray(audio);\n    if (single) {\n      // @ts-ignore\n      audio = [audio];\n    }\n    const sampling_rate = this.processor.feature_extractor.config.sampling_rate;\n    const time_precision = this.processor.feature_extractor.config.chunk_length / this.model.config.max_source_positions;\n    let toReturn = [];\n    for (let aud of audio) {\n      aud = await this._preprocess(aud, sampling_rate);\n\n      /** @type {Chunk[]} */\n      let chunks = [];\n      if (chunk_length_s > 0) {\n        if (stride_length_s === null) {\n          stride_length_s = chunk_length_s / 6;\n        } else if (chunk_length_s <= stride_length_s) {\n          throw Error(\"`chunk_length_s` must be larger than `stride_length_s`.\");\n        }\n\n        // TODO support different stride_length_s (for left and right)\n\n        const window = sampling_rate * chunk_length_s;\n        const stride = sampling_rate * stride_length_s;\n        const jump = window - 2 * stride;\n        let offset = 0;\n\n        // Create subarrays of audio with overlaps\n\n        while (offset < aud.length) {\n          let subarr = aud.subarray(offset, offset + window);\n          let feature = await this.processor(subarr);\n          let isFirst = offset === 0;\n          let isLast = offset + jump >= aud.length;\n          chunks.push({\n            stride: [subarr.length, isFirst ? 0 : stride, isLast ? 0 : stride],\n            input_features: feature.input_features,\n            is_last: isLast\n          });\n          offset += jump;\n        }\n      } else {\n        chunks = [{\n          stride: [aud.length, 0, 0],\n          input_features: (await this.processor(aud)).input_features,\n          is_last: true\n        }];\n      }\n\n      // Generate for each set of input features\n      for (let chunk of chunks) {\n        // NOTE: doing sequentially for now\n        let data = await this.model.generate(chunk.input_features, kwargs);\n\n        // Get top beam\n        chunk.tokens = data[0];\n\n        // convert stride to seconds\n        chunk.stride = chunk.stride.map(x => x / sampling_rate);\n        if (chunk_callback !== null) {\n          chunk_callback(chunk);\n        }\n      }\n\n      // Merge text chunks\n      // @ts-ignore\n      let [full_text, optional] = this.tokenizer._decode_asr(chunks, {\n        time_precision: time_precision,\n        return_timestamps: return_timestamps,\n        force_full_sequences: force_full_sequences\n      });\n      toReturn.push({\n        text: full_text,\n        ...optional\n      });\n    }\n    return single ? toReturn[0] : toReturn;\n  }\n}\n\n/**\n * Image To Text pipeline using a `AutoModelForVision2Seq`. This pipeline predicts a caption for a given image.\n * @extends Pipeline\n */\nexport class ImageToTextPipeline extends Pipeline {\n  /**\n   * Create a new ImageToTextPipeline.\n   * @param {string} task The task of the pipeline. Useful for specifying subtasks.\n   * @param {PreTrainedTokenizer} tokenizer The tokenizer to use.\n   * @param {PreTrainedModel} model The model to use.\n   * @param {Processor} processor The processor to use.\n   */\n  constructor(task, tokenizer, model, processor) {\n    super(task, tokenizer, model);\n    this.processor = processor;\n  }\n\n  /**\n   * Assign labels to the image(s) passed as inputs.\n   * @param {any[]} images The images to be captioned.\n   * @param {Object} [generate_kwargs={}] Optional generation arguments.\n   * @returns {Promise<Object|Object[]>} A Promise that resolves to an object (or array of objects) containing the generated text(s).\n   */\n  async _call(images) {\n    let generate_kwargs = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    let isBatched = Array.isArray(images);\n    images = await prepareImages(images);\n    let {\n      pixel_values\n    } = await this.processor(images);\n    let toReturn = [];\n    for (let batch of pixel_values) {\n      batch.dims = [1, ...batch.dims];\n      let output = await this.model.generate(batch, generate_kwargs);\n      let decoded = this.tokenizer.batch_decode(output, {\n        skip_special_tokens: true\n      }).map(x => {\n        return {\n          generated_text: x.trim()\n        };\n      });\n      toReturn.push(decoded);\n    }\n    return isBatched ? toReturn : toReturn[0];\n  }\n}\n\n/**\n * Image classification pipeline using any `AutoModelForImageClassification`.\n * This pipeline predicts the class of an image.\n * @extends Pipeline\n */\nexport class ImageClassificationPipeline extends Pipeline {\n  /**\n   * Create a new ImageClassificationPipeline.\n   * @param {string} task The task of the pipeline. Useful for specifying subtasks.\n   * @param {PreTrainedModel} model The model to use.\n   * @param {Processor} processor The processor to use.\n   */\n  constructor(task, model, processor) {\n    super(task, null, model); // TODO tokenizer\n    this.processor = processor;\n  }\n\n  /**\n   * Classify the given images.\n   * @param {any} images The images to classify.\n   * @param {Object} options The options to use for classification.\n   * @param {number} [options.topk=1] The number of top results to return.\n   * @returns {Promise<any>} The top classification results for the images.\n   */\n  async _call(images) {\n    let {\n      topk = 1\n    } = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    let isBatched = Array.isArray(images);\n    images = await prepareImages(images);\n    let {\n      pixel_values\n    } = await this.processor(images);\n    let output = await this.model({\n      pixel_values\n    });\n    let id2label = this.model.config.id2label;\n    let toReturn = [];\n    for (let batch of output.logits) {\n      let scores = getTopItems(softmax(batch.data), topk);\n      let vals = scores.map(function (x) {\n        return {\n          label: id2label[x[0]],\n          score: x[1]\n        };\n      });\n      if (topk === 1) {\n        toReturn.push(...vals);\n      } else {\n        toReturn.push(vals);\n      }\n    }\n    return isBatched || topk === 1 ? toReturn : toReturn[0];\n  }\n}\n\n/**\n * Image segmentation pipeline using any `AutoModelForXXXSegmentation`.\n * This pipeline predicts masks of objects and their classes.\n * @extends Pipeline\n */\nexport class ImageSegmentationPipeline extends Pipeline {\n  /**\n   * Create a new ImageSegmentationPipeline.\n   * @param {string} task The task of the pipeline. Useful for specifying subtasks.\n   * @param {PreTrainedModel} model The model to use.\n   * @param {Processor} processor The processor to use.\n   */\n  constructor(task, model, processor) {\n    super(task, null, model); // TODO tokenizer\n    this.processor = processor;\n    this.subtasks_mapping = {\n      // Mapping of subtasks to their corresponding post-processing function names.\n      panoptic: 'post_process_panoptic_segmentation',\n      instance: 'post_process_instance_segmentation',\n      semantic: 'post_process_semantic_segmentation'\n    };\n  }\n\n  /**\n   * Segment the input images.\n   * @param {Array} images The input images.\n   * @param {Object} options The options to use for segmentation.\n   * @param {number} [options.threshold=0.5] Probability threshold to filter out predicted masks.\n   * @param {number} [options.mask_threshold=0.5] Threshold to use when turning the predicted masks into binary values.\n   * @param {number} [options.overlap_mask_area_threshold=0.8] Mask overlap threshold to eliminate small, disconnected segments.\n   * @param {null|string} [options.subtask=null] Segmentation task to be performed. One of [`panoptic`, `instance`, and `semantic`], depending on model capabilities. If not set, the pipeline will attempt to resolve (in that order).\n   * @param {Array} [options.label_ids_to_fuse=null] List of label ids to fuse. If not set, do not fuse any labels.\n   * @param {Array} [options.target_sizes=null] List of target sizes for the input images. If not set, use the original image sizes.\n   * @returns {Promise<Array>} The annotated segments.\n   */\n  async _call(images) {\n    let {\n      threshold = 0.5,\n      mask_threshold = 0.5,\n      overlap_mask_area_threshold = 0.8,\n      label_ids_to_fuse = null,\n      target_sizes = null,\n      subtask = null // TODO use\n    } = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    let isBatched = Array.isArray(images);\n    if (isBatched && images.length !== 1) {\n      throw Error(\"Image segmentation pipeline currently only supports a batch size of 1.\");\n    }\n    images = await prepareImages(images);\n    let imageSizes = images.map(x => [x.height, x.width]);\n    let {\n      pixel_values,\n      pixel_mask\n    } = await this.processor(images);\n    let output = await this.model({\n      pixel_values,\n      pixel_mask\n    });\n    let fn = null;\n    if (subtask !== null) {\n      fn = this.subtasks_mapping[subtask];\n    } else {\n      for (let [task, func] of Object.entries(this.subtasks_mapping)) {\n        if (func in this.processor.feature_extractor) {\n          fn = this.processor.feature_extractor[func].bind(this.processor.feature_extractor);\n          subtask = task;\n          break;\n        }\n      }\n    }\n\n    // add annotations\n    let annotation = [];\n    if (subtask === 'panoptic' || subtask === 'instance') {\n      let processed = fn(output, threshold, mask_threshold, overlap_mask_area_threshold, label_ids_to_fuse, target_sizes ?? imageSizes // TODO FIX?\n      )[0];\n      let segmentation = processed.segmentation;\n      let id2label = this.model.config.id2label;\n      for (let segment of processed.segments_info) {\n        let maskData = new Uint8ClampedArray(segmentation.data.length);\n        for (let i = 0; i < segmentation.data.length; ++i) {\n          if (segmentation.data[i] === segment.id) {\n            maskData[i] = 255;\n          }\n        }\n        let mask = new RawImage(maskData, segmentation.dims[1], segmentation.dims[0], 1);\n        annotation.push({\n          score: segment.score,\n          label: id2label[segment.label_id],\n          mask: mask\n        });\n      }\n    } else if (subtask === 'semantic') {\n      throw Error(`semantic segmentation not yet supported.`);\n    } else {\n      throw Error(`Subtask ${subtask} not supported.`);\n    }\n    return annotation;\n  }\n}\n\n/**\n * Zero shot image classification pipeline. This pipeline predicts the class of\n * an image when you provide an image and a set of `candidate_labels`.\n * @extends Pipeline\n */\nexport class ZeroShotImageClassificationPipeline extends Pipeline {\n  /**\n   * Create a new ZeroShotImageClassificationPipeline.\n   * @param {string} task The task of the pipeline. Useful for specifying subtasks.\n   * @param {PreTrainedTokenizer} tokenizer The tokenizer to use.\n   * @param {PreTrainedModel} model The model to use.\n   * @param {Processor} processor The processor to use.\n   */\n  constructor(task, tokenizer, model, processor) {\n    super(task, tokenizer, model);\n    this.processor = processor;\n  }\n\n  /**\n   * Classify the input images with candidate labels using a zero-shot approach.\n   * @param {Array} images The input images.\n   * @param {Array} candidate_labels The candidate labels.\n   * @param {Object} options The options for the classification.\n   * @param {string} [options.hypothesis_template] The hypothesis template to use for zero-shot classification. Default: \"This is a photo of {}\".\n   * @returns {Promise<any>} An array of classifications for each input image or a single classification object if only one input image is provided.\n   */\n  // @ts-ignore\n  async _call(images, candidate_labels) {\n    let {\n      hypothesis_template = \"This is a photo of {}\"\n    } = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n    let isBatched = Array.isArray(images);\n    images = await prepareImages(images);\n\n    // Insert label into hypothesis template \n    let texts = candidate_labels.map(x => hypothesis_template.replace('{}', x));\n\n    // Run tokenization\n    let text_inputs = this.tokenizer(texts, {\n      padding: true,\n      truncation: true\n    });\n\n    // Run processor\n    let {\n      pixel_values\n    } = await this.processor(images);\n\n    // Run model with both text and pixel inputs\n    let output = await this.model({\n      ...text_inputs,\n      pixel_values\n    });\n\n    // Compare each image with each candidate label\n    let toReturn = [];\n    for (let batch of output.logits_per_image) {\n      // Compute softmax per image\n      let probs = softmax(batch.data);\n      toReturn.push([...probs].map((x, i) => {\n        return {\n          score: x,\n          label: candidate_labels[i]\n        };\n      }));\n    }\n    return isBatched ? toReturn : toReturn[0];\n  }\n}\n\n/**\n * Object detection pipeline using any `AutoModelForObjectDetection`.\n * This pipeline predicts bounding boxes of objects and their classes.\n * @extends Pipeline\n */\nexport class ObjectDetectionPipeline extends Pipeline {\n  /**\n   * Create a new ObjectDetectionPipeline.\n   * @param {string} task The task of the pipeline. Useful for specifying subtasks.\n   * @param {PreTrainedModel} model The model to use.\n   * @param {Processor} processor The processor to use.\n   */\n  constructor(task, model, processor) {\n    super(task, null, model); // TODO tokenizer\n    this.processor = processor;\n  }\n\n  /**\n   * Detect objects (bounding boxes & classes) in the image(s) passed as inputs.\n   * @param {any[]} images The input images.\n   * @param {Object} options The options for the object detection.\n   * @param {number} [options.threshold=0.9] The threshold used to filter boxes by score.\n   * @param {boolean} [options.percentage=false] Whether to return the boxes coordinates in percentage (true) or in pixels (false).\n   */\n  async _call(images) {\n    let {\n      threshold = 0.9,\n      percentage = false\n    } = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    let isBatched = Array.isArray(images);\n    if (isBatched && images.length !== 1) {\n      throw Error(\"Object detection pipeline currently only supports a batch size of 1.\");\n    }\n    images = await prepareImages(images);\n    let imageSizes = percentage ? null : images.map(x => [x.height, x.width]);\n    let {\n      pixel_values,\n      pixel_mask\n    } = await this.processor(images);\n    let output = await this.model({\n      pixel_values,\n      pixel_mask\n    });\n\n    // @ts-ignore\n    let processed = this.processor.feature_extractor.post_process_object_detection(output, threshold, imageSizes);\n\n    // Add labels\n    let id2label = this.model.config.id2label;\n    processed.forEach(x => x.labels = x.classes.map(y => id2label[y]));\n    return isBatched ? processed : processed[0];\n  }\n}\nconst SUPPORTED_TASKS = {\n  \"text-classification\": {\n    \"tokenizer\": AutoTokenizer,\n    \"pipeline\": TextClassificationPipeline,\n    \"model\": AutoModelForSequenceClassification,\n    \"default\": {\n      // TODO: replace with original\n      // \"model\": \"distilbert-base-uncased-finetuned-sst-2-english\",\n      \"model\": \"Xenova/distilbert-base-uncased-finetuned-sst-2-english\"\n    },\n    \"type\": \"text\"\n  },\n  \"token-classification\": {\n    \"tokenizer\": AutoTokenizer,\n    \"pipeline\": TokenClassificationPipeline,\n    \"model\": AutoModelForTokenClassification,\n    \"default\": {\n      // TODO: replace with original\n      // \"model\": \"Davlan/bert-base-multilingual-cased-ner-hrl\",\n      \"model\": \"Xenova/bert-base-multilingual-cased-ner-hrl\"\n    },\n    \"type\": \"text\"\n  },\n  \"question-answering\": {\n    \"tokenizer\": AutoTokenizer,\n    \"pipeline\": QuestionAnsweringPipeline,\n    \"model\": AutoModelForQuestionAnswering,\n    \"default\": {\n      // TODO: replace with original\n      // \"model\": \"distilbert-base-cased-distilled-squad\",\n      \"model\": \"Xenova/distilbert-base-cased-distilled-squad\"\n    },\n    \"type\": \"text\"\n  },\n  \"fill-mask\": {\n    \"tokenizer\": AutoTokenizer,\n    \"pipeline\": FillMaskPipeline,\n    \"model\": AutoModelForMaskedLM,\n    \"default\": {\n      // TODO: replace with original\n      // \"model\": \"bert-base-uncased\",\n      \"model\": \"Xenova/bert-base-uncased\"\n    },\n    \"type\": \"text\"\n  },\n  \"summarization\": {\n    \"tokenizer\": AutoTokenizer,\n    \"pipeline\": SummarizationPipeline,\n    \"model\": AutoModelForSeq2SeqLM,\n    \"default\": {\n      // TODO: replace with original\n      // \"model\": \"sshleifer/distilbart-cnn-6-6\",\n      \"model\": \"Xenova/distilbart-cnn-6-6\"\n    },\n    \"type\": \"text\"\n  },\n  \"translation\": {\n    \"tokenizer\": AutoTokenizer,\n    \"pipeline\": TranslationPipeline,\n    \"model\": AutoModelForSeq2SeqLM,\n    \"default\": {\n      // TODO: replace with original\n      // \"model\": \"t5-small\",\n      \"model\": \"Xenova/t5-small\"\n    },\n    \"type\": \"text\"\n  },\n  \"text2text-generation\": {\n    \"tokenizer\": AutoTokenizer,\n    \"pipeline\": Text2TextGenerationPipeline,\n    \"model\": AutoModelForSeq2SeqLM,\n    \"default\": {\n      // TODO: replace with original\n      // \"model\": \"google/flan-t5-small\",\n      \"model\": \"Xenova/flan-t5-small\"\n    },\n    \"type\": \"text\"\n  },\n  \"text-generation\": {\n    \"tokenizer\": AutoTokenizer,\n    \"pipeline\": TextGenerationPipeline,\n    \"model\": AutoModelForCausalLM,\n    \"default\": {\n      // TODO: replace with original\n      // \"model\": \"gpt2\",\n      \"model\": \"Xenova/gpt2\"\n    },\n    \"type\": \"text\"\n  },\n  \"zero-shot-classification\": {\n    \"tokenizer\": AutoTokenizer,\n    \"pipeline\": ZeroShotClassificationPipeline,\n    \"model\": AutoModelForSequenceClassification,\n    \"default\": {\n      // TODO: replace with original\n      // \"model\": \"typeform/distilbert-base-uncased-mnli\",\n      \"model\": \"Xenova/distilbert-base-uncased-mnli\"\n    },\n    \"type\": \"text\"\n  },\n  \"automatic-speech-recognition\": {\n    \"tokenizer\": AutoTokenizer,\n    \"pipeline\": AutomaticSpeechRecognitionPipeline,\n    \"model\": AutoModelForSeq2SeqLM,\n    \"processor\": AutoProcessor,\n    \"default\": {\n      // TODO: replace with original\n      // \"model\": \"openai/whisper-tiny.en\",\n      \"model\": \"Xenova/whisper-tiny.en\"\n    },\n    \"type\": \"multimodal\"\n  },\n  \"image-to-text\": {\n    \"tokenizer\": AutoTokenizer,\n    \"pipeline\": ImageToTextPipeline,\n    \"model\": AutoModelForVision2Seq,\n    \"processor\": AutoProcessor,\n    \"default\": {\n      // TODO: replace with original\n      // \"model\": \"nlpconnect/vit-gpt2-image-captioning\",\n      \"model\": \"Xenova/vit-gpt2-image-captioning\"\n    },\n    \"type\": \"multimodal\"\n  },\n  \"image-classification\": {\n    // no tokenizer\n    \"pipeline\": ImageClassificationPipeline,\n    \"model\": AutoModelForImageClassification,\n    \"processor\": AutoProcessor,\n    \"default\": {\n      // TODO: replace with original\n      // \"model\": \"google/vit-base-patch16-224\",\n      \"model\": \"Xenova/vit-base-patch16-224\"\n    },\n    \"type\": \"multimodal\"\n  },\n  \"image-segmentation\": {\n    // no tokenizer\n    \"pipeline\": ImageSegmentationPipeline,\n    \"model\": AutoModelForImageSegmentation,\n    \"processor\": AutoProcessor,\n    \"default\": {\n      // TODO: replace with original\n      // \"model\": \"facebook/detr-resnet-50-panoptic\",\n      \"model\": \"Xenova/detr-resnet-50-panoptic\"\n    },\n    \"type\": \"multimodal\"\n  },\n  \"zero-shot-image-classification\": {\n    // no tokenizer\n    \"tokenizer\": AutoTokenizer,\n    \"pipeline\": ZeroShotImageClassificationPipeline,\n    \"model\": AutoModel,\n    \"processor\": AutoProcessor,\n    \"default\": {\n      // TODO: replace with original\n      // \"model\": \"openai/clip-vit-base-patch32\",\n      \"model\": \"Xenova/clip-vit-base-patch32\"\n    },\n    \"type\": \"multimodal\"\n  },\n  \"object-detection\": {\n    // no tokenizer\n    \"pipeline\": ObjectDetectionPipeline,\n    \"model\": AutoModelForObjectDetection,\n    \"processor\": AutoProcessor,\n    \"default\": {\n      // TODO: replace with original\n      // \"model\": \"facebook/detr-resnet-50\",\n      \"model\": \"Xenova/detr-resnet-50\"\n    },\n    \"type\": \"multimodal\"\n  },\n  // This task serves as a useful interface for dealing with sentence-transformers (https://huggingface.co/sentence-transformers).\n  \"feature-extraction\": {\n    \"tokenizer\": AutoTokenizer,\n    \"pipeline\": FeatureExtractionPipeline,\n    \"model\": AutoModel,\n    \"default\": {\n      // TODO: replace with original\n      // \"model\": \"sentence-transformers/all-MiniLM-L6-v2\",\n      \"model\": \"Xenova/all-MiniLM-L6-v2\"\n    },\n    \"type\": \"text\"\n  }\n};\nconst TASK_ALIASES = {\n  \"sentiment-analysis\": \"text-classification\",\n  \"ner\": \"token-classification\",\n  \"vqa\": \"visual-question-answering\",\n  \"asr\": \"automatic-speech-recognition\",\n  // Add for backwards compatibility\n  \"embeddings\": \"feature-extraction\"\n};\n\n/**\n * @typedef {import('./utils/hub.js').PretrainedOptions} PretrainedOptions\n */\n\n/**\n * Utility factory method to build a [`Pipeline`] object.\n *\n * @param {string} task The task of the pipeline.\n * @param {string} [model=null] The name of the pre-trained model to use. If not specified, the default model for the task will be used.\n * @param {PretrainedOptions} [options] Optional parameters for the pipeline.\n * @returns {Promise<Pipeline>} A Pipeline object for the specified task.\n * @throws {Error} If an unsupported pipeline is requested.\n */\nexport async function pipeline(task) {\n  let model = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;\n  let {\n    quantized = true,\n    progress_callback = null,\n    config = null,\n    cache_dir = null,\n    local_files_only = false,\n    revision = 'main'\n  } = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n  // Helper method to construct pipeline\n\n  // Apply aliases\n  task = TASK_ALIASES[task] ?? task;\n\n  // Get pipeline info\n  let pipelineInfo = SUPPORTED_TASKS[task.split('_', 1)[0]];\n  if (!pipelineInfo) {\n    throw Error(`Unsupported pipeline: ${task}. Must be one of [${Object.keys(SUPPORTED_TASKS)}]`);\n  }\n\n  // Use model if specified, otherwise, use default\n  if (!model) {\n    model = pipelineInfo.default.model;\n    console.log(`No model specified. Using default model: \"${model}\".`);\n  }\n  let tokenizerClass = pipelineInfo.tokenizer;\n  let modelClass = pipelineInfo.model;\n  let pipelineClass = pipelineInfo.pipeline;\n  let processorClass = pipelineInfo.processor;\n  let promises = [];\n  let pretrainedOptions = {\n    quantized,\n    progress_callback,\n    config,\n    cache_dir,\n    local_files_only,\n    revision\n  };\n  if (tokenizerClass) {\n    promises.push(tokenizerClass.from_pretrained(model, pretrainedOptions));\n  }\n  if (modelClass) {\n    promises.push(modelClass.from_pretrained(model, pretrainedOptions));\n  }\n  if (processorClass) {\n    promises.push(processorClass.from_pretrained(model, pretrainedOptions));\n  }\n\n  // Load tokenizer and model\n  let items = await Promise.all(promises);\n  dispatchCallback(progress_callback, {\n    'status': 'ready',\n    'task': task,\n    'model': model\n  });\n  return new pipelineClass(task, ...items);\n}\n\n/**\n * Compute the Cartesian product of given arrays\n * @param {...Array} a Arrays to compute the product\n * @returns {Array} Returns the computed Cartesian product as an array\n * @private\n */\nfunction product() {\n  for (var _len = arguments.length, a = new Array(_len), _key = 0; _key < _len; _key++) {\n    a[_key] = arguments[_key];\n  }\n  // Cartesian product of items\n  // Adapted from https://stackoverflow.com/a/43053803\n  return a.reduce((a, b) => a.flatMap(d => b.map(e => [d, e])));\n}","map":{"version":3,"names":["AutoTokenizer","PreTrainedTokenizer","AutoModel","AutoModelForSequenceClassification","AutoModelForTokenClassification","AutoModelForQuestionAnswering","AutoModelForMaskedLM","AutoModelForSeq2SeqLM","AutoModelForCausalLM","AutoModelForVision2Seq","AutoModelForImageClassification","AutoModelForImageSegmentation","AutoModelForObjectDetection","PreTrainedModel","AutoProcessor","Processor","Callable","isString","dispatchCallback","pop","softmax","max","getTopItems","read_audio","mean_pooling","RawImage","prepareImages","images","Array","isArray","Promise","all","map","x","read","Pipeline","constructor","task","tokenizer","model","dispose","_call","texts","inputs","padding","truncation","outputs","TextClassificationPipeline","topk","arguments","length","undefined","id2label","config","toReturn","batch","logits","scores","data","vals","label","score","push","TokenClassificationPipeline","ignore_labels","isBatched","i","dims","ids","input_ids","tokens","j","tokenData","topScoreIndex","entity","includes","word","decode","item","skip_special_tokens","index","start","end","QuestionAnsweringPipeline","question","context","text_pair","output","start_logits","sepIndex","indexOf","sep_token_id","s1","from","filter","e1","end_logits","options","product","sort","a","b","k","Math","min","answer_tokens","slice","answer","FillMaskPipeline","mask_token_index","mask_token_id","Error","mask_token","itemLogits","sequence","token","token_str","vocab","Text2TextGenerationPipeline","_key","generate_kwargs","prefix","task_specific_params","tokenizer_options","TranslationPipeline","_build_translation_inputs","outputTokenIds","generate","batch_decode","text","SummarizationPipeline","TextGenerationPipeline","stringInput","String","padding_side","attention_mask","inputs_attention_mask","trimmedTexts","trim","decoded","_","textIndex","floor","startText","generated_text","ZeroShotClassificationPipeline","label2id","Object","fromEntries","entries","_ref","v","toLowerCase","entailment_id","console","warn","contradiction_id","candidate_labels","hypothesis_template","multi_label","hypotheses","replace","softmaxEach","premise","entails_logits","hypothesis","scores_sorted","labels","FeatureExtractionPipeline","pooling","normalize","result","last_hidden_state","AutomaticSpeechRecognitionPipeline","processor","_preprocess","audio","sampling_rate","kwargs","return_timestamps","chunk_length_s","stride_length_s","chunk_callback","force_full_sequences","language","forced_decoder_ids","decoder_prompt_ids","get_decoder_prompt_ids","no_timestamps","single","feature_extractor","time_precision","chunk_length","max_source_positions","aud","chunks","window","stride","jump","offset","subarr","subarray","feature","isFirst","isLast","input_features","is_last","chunk","full_text","optional","_decode_asr","ImageToTextPipeline","pixel_values","ImageClassificationPipeline","ImageSegmentationPipeline","subtasks_mapping","panoptic","instance","semantic","threshold","mask_threshold","overlap_mask_area_threshold","label_ids_to_fuse","target_sizes","subtask","imageSizes","height","width","pixel_mask","fn","func","bind","annotation","processed","segmentation","segment","segments_info","maskData","Uint8ClampedArray","id","mask","label_id","ZeroShotImageClassificationPipeline","text_inputs","logits_per_image","probs","ObjectDetectionPipeline","percentage","post_process_object_detection","forEach","classes","y","SUPPORTED_TASKS","TASK_ALIASES","pipeline","quantized","progress_callback","cache_dir","local_files_only","revision","pipelineInfo","split","keys","default","log","tokenizerClass","modelClass","pipelineClass","processorClass","promises","pretrainedOptions","from_pretrained","items","_len","reduce","flatMap","d","e"],"sources":["/Users/phreetech13/Desktop/RealTimeAudioToText/node_modules/@xenova/transformers/src/pipelines.js"],"sourcesContent":["/**\n * @file Pipelines provide a high-level, easy to use, API for running machine learning models.\n * \n * **Example:** Instantiate pipeline using the `pipeline` function.\n * ```javascript\n * import { pipeline } from '@xenova/transformers';\n * \n * let pipeline = await pipeline('sentiment-analysis');\n * let result = await pipeline('I love transformers!');\n * // [{'label': 'POSITIVE', 'score': 0.999817686}]\n * ```\n * \n * @module pipelines\n */\n\nimport {\n    AutoTokenizer,\n    PreTrainedTokenizer,\n} from './tokenizers.js';\nimport {\n    AutoModel,\n    AutoModelForSequenceClassification,\n    AutoModelForTokenClassification,\n    AutoModelForQuestionAnswering,\n    AutoModelForMaskedLM,\n    AutoModelForSeq2SeqLM,\n    AutoModelForCausalLM,\n    AutoModelForVision2Seq,\n    AutoModelForImageClassification,\n    AutoModelForImageSegmentation,\n    AutoModelForObjectDetection,\n    PreTrainedModel,\n} from './models.js';\nimport {\n    AutoProcessor,\n    Processor\n} from './processors.js';\n\n\nimport {\n    Callable,\n    isString,\n    dispatchCallback,\n    pop,\n} from './utils/core.js';\nimport {\n    softmax,\n    max,\n    getTopItems,\n} from './utils/maths.js';\nimport {\n    read_audio\n} from './utils/audio.js';\nimport {\n    mean_pooling,\n} from './utils/tensor.js';\nimport { RawImage } from './utils/image.js';\n\n/**\n * Prepare images for further tasks.\n * @param {any[]} images images to prepare.\n * @returns {Promise<any[]>} returns processed images.\n * @private\n */\nasync function prepareImages(images) {\n    if (!Array.isArray(images)) {\n        images = [images];\n    }\n\n    // Possibly convert any non-images to images\n    images = await Promise.all(images.map(x => RawImage.read(x)));\n    return images;\n}\n\n/**\n * The Pipeline class is the class from which all pipelines inherit.\n * Refer to this class for methods shared across different pipelines.\n * @extends Callable\n */\nexport class Pipeline extends Callable {\n    /**\n     * Create a new Pipeline.\n     * @param {string} task The task of the pipeline. Useful for specifying subtasks.\n     * @param {PreTrainedTokenizer} tokenizer The tokenizer to use.\n     * @param {PreTrainedModel} model The model to use.\n     */\n    constructor(task, tokenizer, model) {\n        super();\n        this.task = task;\n        this.tokenizer = tokenizer;\n        this.model = model;\n    }\n\n    /**\n     * Disposes the model.\n     * @returns {Promise<void>} A promise that resolves when the model has been disposed.\n     */\n    async dispose() {\n        await this.model.dispose();\n    }\n\n    /**\n     * Executes the task associated with the pipeline.\n     * @param {any} texts The input texts to be processed.\n     * @returns {Promise<any>} A promise that resolves to an array containing the inputs and outputs of the task.\n     */\n    async _call(texts) {\n        // Run tokenization\n        let inputs = this.tokenizer(texts, {\n            padding: true,\n            truncation: true\n        });\n\n        // Run model\n        let outputs = await this.model(inputs)\n\n        return [inputs, outputs];\n    }\n}\n\n/**\n * Text classification pipeline using any `ModelForSequenceClassification`.\n * @extends Pipeline\n */\nexport class TextClassificationPipeline extends Pipeline {\n    /**\n     * Executes the text classification task.\n     * @param {any} texts The input texts to be classified.\n     * @param {Object} options An optional object containing the following properties:\n     * @param {number} [options.topk=1] The number of top predictions to be returned.\n     * @returns {Promise<Object[]|Object>} A promise that resolves to an array or object containing the predicted labels and scores.\n     */\n    async _call(texts, {\n        topk = 1\n    } = {}) {\n\n        let [inputs, outputs] = await super._call(texts);\n\n        let id2label = this.model.config.id2label;\n        let toReturn = [];\n        for (let batch of outputs.logits) {\n            let scores = getTopItems(softmax(batch.data), topk);\n\n            let vals = scores.map(function (x) {\n                return {\n                    label: id2label[x[0]],\n                    score: x[1],\n                }\n            });\n            if (topk === 1) {\n                toReturn.push(...vals);\n            } else {\n                toReturn.push(vals);\n            }\n        }\n\n        return Array.isArray(texts) || topk === 1 ? toReturn : toReturn[0];\n    }\n}\n\n\n/**\n * Named Entity Recognition pipeline using any `ModelForTokenClassification`.\n * @extends Pipeline\n */\nexport class TokenClassificationPipeline extends Pipeline {\n    /**\n     * Executes the token classification task.\n     * @param {any} texts The input texts to be classified.\n     * @param {Object} options An optional object containing the following properties:\n     * @returns {Promise<Object[]|Object>} A promise that resolves to an array or object containing the predicted labels and scores.\n     */\n    async _call(texts, {\n        ignore_labels = ['O'], // TODO init param?\n    } = {}) {\n\n        let isBatched = Array.isArray(texts);\n\n        if (!isBatched) {\n            texts = [texts];\n        }\n\n        let tokenizer = this.tokenizer;\n        let [inputs, outputs] = await super._call(texts);\n\n        let logits = outputs.logits;\n        let id2label = this.model.config.id2label;\n\n        let toReturn = [];\n        for (let i = 0; i < logits.dims[0]; ++i) {\n            let ids = inputs.input_ids[i];\n            let batch = logits[i];\n\n            // List of tokens that aren't ignored\n            let tokens = [];\n            for (let j = 0; j < batch.dims[0]; ++j) {\n                let tokenData = batch[j];\n                let topScoreIndex = max(tokenData.data)[1];\n\n                let entity = id2label[topScoreIndex];\n                if (ignore_labels.includes(entity)) {\n                    // We predicted a token that should be ignored. So, we skip it.\n                    continue;\n                }\n\n                // TODO add option to keep special tokens?\n                let word = tokenizer.decode([ids[j].item()], { skip_special_tokens: true });\n                if (word === '') {\n                    // Was a special token. So, we skip it.\n                    continue;\n                }\n\n                let scores = softmax(tokenData.data);\n\n                tokens.push({\n                    entity: entity,\n                    score: scores[topScoreIndex],\n                    index: j,\n                    word: word,\n\n                    // TODO: null for now, but will add\n                    start: null,\n                    end: null,\n                });\n            }\n            toReturn.push(tokens);\n        }\n        return isBatched ? toReturn : toReturn[0];\n    }\n}\n/**\n * Question Answering pipeline using any `ModelForQuestionAnswering`.\n * \n * **Example:** Run question answering with `distilbert-base-uncased-distilled-squad`.\n * ```javascript\n * let question = 'Who was Jim Henson?';\n * let context = 'Jim Henson was a nice puppet.';\n * \n * let answerer = await pipeline('question-answering', 'Xenova/distilbert-base-uncased-distilled-squad');\n * let outputs = await answerer(question, context);\n * console.log(outputs);\n * // {\n * //     \"answer\": \"a nice puppet\",\n * //     \"score\": 0.5768911502526741\n * // }\n * ```\n * @extends Pipeline\n */\nexport class QuestionAnsweringPipeline extends Pipeline {\n    /**\n     * Executes the question answering task.\n     * @param {string|string[]} question The question(s) to be answered.\n     * @param {string|string[]} context The context(s) where the answer(s) can be found.\n     * @param {Object} options An optional object containing the following properties:\n     * @param {number} [options.topk=1] The number of top answer predictions to be returned.\n     * @returns {Promise<any>} A promise that resolves to an array or object containing the predicted answers and scores.\n     */\n    // @ts-ignore\n    async _call(question, context, {\n        topk = 1\n    } = {}) {\n\n        let inputs = this.tokenizer(question, {\n            text_pair: context\n        })\n\n        let output = await this.model(inputs);\n\n        let toReturn = [];\n        for (let j = 0; j < output.start_logits.dims[0]; ++j) {\n            let ids = inputs.input_ids[j];\n            let sepIndex = ids.indexOf(this.tokenizer.sep_token_id);\n\n            let s1 = Array.from(softmax(output.start_logits[j].data))\n                .map((x, i) => [x, i])\n                .filter(x => x[1] > sepIndex);\n            let e1 = Array.from(softmax(output.end_logits[j].data))\n                .map((x, i) => [x, i])\n                .filter(x => x[1] > sepIndex);\n\n            let options = product(s1, e1)\n                .filter(x => x[0][1] <= x[1][1])\n                .map(x => [x[0][1], x[1][1], x[0][0] * x[1][0]])\n                .sort((a, b) => b[2] - a[2]);\n\n            for (let k = 0; k < Math.min(options.length, topk); ++k) {\n                let [start, end, score] = options[k];\n\n                let answer_tokens = [...ids].slice(start, end + 1)\n\n                let answer = this.tokenizer.decode(answer_tokens, {\n                    skip_special_tokens: true,\n                });\n\n                // TODO add start and end?\n                // NOTE: HF returns character index\n                toReturn.push({\n                    answer, score\n                });\n            }\n        }\n\n        // Mimic HF's return type based on topk\n        return (topk === 1) ? toReturn[0] : toReturn;\n\n    }\n}\n\n/**\n * Masked language modeling prediction pipeline using any `ModelWithLMHead`.\n * @extends Pipeline\n */\nexport class FillMaskPipeline extends Pipeline {\n    /**\n     * Fill the masked token in the text(s) given as inputs.\n     * @param {any} texts The masked input texts.\n     * @param {Object} options An optional object containing the following properties:\n     * @param {number} [options.topk=5] The number of top predictions to be returned.\n     * @returns {Promise<Object[]|Object>} A promise that resolves to an array or object containing the predicted tokens and scores.\n     */\n    async _call(texts, {\n        topk = 5\n    } = {}) {\n        // Run tokenization\n        let [inputs, outputs] = await super._call(texts);\n\n        // Determine indices of mask tokens\n        // let mask_token_indices = inputs.input_ids.data.map(x => )\n\n        // let logits = reshape(outputs.logits.data, outputs.logits.dims);\n\n        let tokenizer = this.tokenizer;\n\n        let toReturn = [];\n\n        for (let i = 0; i < inputs.input_ids.dims[0]; ++i) {\n            let ids = inputs.input_ids[i];\n            let mask_token_index = ids.indexOf(this.tokenizer.mask_token_id)\n\n            if (mask_token_index === -1) {\n                throw Error(`Mask token (${tokenizer.mask_token}) not found in text.`)\n            }\n            let logits = outputs.logits[i];\n            let itemLogits = logits[mask_token_index];\n\n            let scores = getTopItems(softmax(itemLogits.data), topk);\n\n            toReturn.push(scores.map(x => {\n                let sequence = [...ids];\n                sequence[mask_token_index] = x[0];\n\n                return {\n                    score: x[1],\n                    token: x[0],\n                    token_str: tokenizer.model.vocab[x[0]],\n                    sequence: tokenizer.decode(sequence, { skip_special_tokens: true }),\n                }\n            }));\n        }\n        return Array.isArray(texts) ? toReturn : toReturn[0];\n    }\n}\n\n/**\n * Text2TextGenerationPipeline class for generating text using a model that performs text-to-text generation tasks.\n * @extends Pipeline\n */\nexport class Text2TextGenerationPipeline extends Pipeline {\n    _key = null;\n\n    /**\n     * Fill the masked token in the text(s) given as inputs.\n     * @param {string|string[]} texts The text or array of texts to be processed.\n     * @param {Object} [options={}] Options for the fill-mask pipeline.\n     * @param {number} [options.topk=5] The number of top-k predictions to return.\n     * @returns {Promise<any>} An array of objects containing the score, predicted token, predicted token string,\n     * and the sequence with the predicted token filled in, or an array of such arrays (one for each input text).\n     * If only one input text is given, the output will be an array of objects.\n     * @throws {Error} When the mask token is not found in the input text.\n     */\n    async _call(texts, generate_kwargs = {}) {\n        if (!Array.isArray(texts)) {\n            texts = [texts];\n        }\n\n        // Add global prefix, if present\n        if (this.model.config.prefix) {\n            texts = texts.map(x => this.model.config.prefix + x)\n        }\n\n        // Handle task specific params:\n        let task_specific_params = this.model.config.task_specific_params\n        if (task_specific_params && task_specific_params[this.task]) {\n            // Add prefixes, if present\n            if (task_specific_params[this.task].prefix) {\n                texts = texts.map(x => task_specific_params[this.task].prefix + x)\n            }\n\n            // TODO update generation config\n        }\n\n        let tokenizer_options = {\n            padding: true,\n            truncation: true,\n        }\n        let input_ids;\n        if (this instanceof TranslationPipeline && '_build_translation_inputs' in this.tokenizer) {\n            // TODO: move to Translation pipeline?\n            // Currently put here to avoid code duplication\n            // @ts-ignore\n            input_ids = this.tokenizer._build_translation_inputs(texts, tokenizer_options, generate_kwargs).input_ids;\n\n        } else {\n            input_ids = this.tokenizer(texts, tokenizer_options).input_ids;\n        }\n\n        let outputTokenIds = await this.model.generate(input_ids, generate_kwargs);\n\n        /**\n         * @type {any[]}\n         */\n        let toReturn = this.tokenizer.batch_decode(outputTokenIds, {\n            skip_special_tokens: true,\n        });\n        if (this._key !== null) {\n            toReturn = toReturn.map(text => {\n                return (this._key === null) ? text : { [this._key]: text }\n            })\n        }\n        return toReturn\n    }\n}\n\n\n/**\n * A pipeline for summarization tasks, inheriting from Text2TextGenerationPipeline.\n * @extends Text2TextGenerationPipeline\n */\nexport class SummarizationPipeline extends Text2TextGenerationPipeline {\n    _key = 'summary_text';\n}\n\n/**\n * TranslationPipeline class to translate text from one language to another using the provided model and tokenizer.\n * @extends Text2TextGenerationPipeline\n */\nexport class TranslationPipeline extends Text2TextGenerationPipeline {\n    _key = 'translation_text';\n}\n\n/**\n * Language generation pipeline using any `ModelWithLMHead`.\n * This pipeline predicts the words that will follow a specified text prompt.\n * @extends Pipeline\n */\nexport class TextGenerationPipeline extends Pipeline {\n    /**\n     * Generates text based on an input prompt.\n     * @param {any} texts The input prompt or prompts to generate text from.\n     * @param {Object} [generate_kwargs={}] Additional arguments for text generation.\n     * @returns {Promise<any>} The generated text or texts.\n     */\n    async _call(texts, generate_kwargs = {}) {\n        let stringInput = typeof texts === 'string' || texts instanceof String;\n        if (stringInput) {\n            texts = [texts];\n        }\n\n        this.tokenizer.padding_side = 'left';\n        let inputs = this.tokenizer(texts, {\n            padding: true,\n            truncation: true,\n        });\n\n        let input_ids = inputs.input_ids;\n        let attention_mask = inputs.attention_mask;\n\n        let outputTokenIds = await this.model.generate(input_ids, generate_kwargs, null, {\n            inputs_attention_mask: attention_mask\n        });\n\n        const trimmedTexts = texts.map(x => x.trim());\n        const decoded = this.tokenizer.batch_decode(outputTokenIds, {\n            skip_special_tokens: true,\n        });\n        const toReturn = Array.from({ length: texts.length }, _ => []);\n        for (let i = 0; i < decoded.length; ++i) {\n            const textIndex = Math.floor(i / outputTokenIds.length * trimmedTexts.length);\n            let startText = trimmedTexts[textIndex];\n\n            toReturn[textIndex].push({\n                generated_text: startText + decoded[i]\n            });\n        }\n        return (stringInput && toReturn.length === 1) ? toReturn[0] : toReturn;\n    }\n}\n\n/**\n * NLI-based zero-shot classification pipeline using a `ModelForSequenceClassification`\n * trained on NLI (natural language inference) tasks. Equivalent of `text-classification`\n * pipelines, but these models don't require a hardcoded number of potential classes, they\n * can be chosen at runtime. It usually means it's slower but it is **much** more flexible.\n * @extends Pipeline\n */\nexport class ZeroShotClassificationPipeline extends Pipeline {\n\n    /**\n     * Create a new ZeroShotClassificationPipeline.\n     * @param {string} task The task of the pipeline. Useful for specifying subtasks.\n     * @param {PreTrainedTokenizer} tokenizer The tokenizer to use.\n     * @param {PreTrainedModel} model The model to use.\n     */\n    constructor(task, tokenizer, model) {\n        super(task, tokenizer, model);\n\n        // Use model config to get label2id mapping\n        this.label2id = Object.fromEntries(\n            Object.entries(this.model.config.label2id).map(\n                ([k, v]) => [k.toLowerCase(), v]\n            )\n        );\n\n        this.entailment_id = this.label2id['entailment'];\n        if (this.entailment_id === undefined) {\n            console.warn(\"Could not find 'entailment' in label2id mapping. Using 2 as entailment_id.\");\n            this.entailment_id = 2;\n        }\n\n        this.contradiction_id = this.label2id['contradiction'];\n        if (this.contradiction_id === undefined) {\n            console.warn(\"Could not find 'contradiction' in label2id mapping. Using 0 as contradiction_id.\");\n            this.contradiction_id = 0;\n        }\n    }\n    /**\n     * @param {any[]} texts\n     * @param {string[]} candidate_labels\n     * @param {Object} options Additional options:\n     * @param {string} [options.hypothesis_template=\"This example is {}.\"] The template used to turn each\n     * candidate label into an NLI-style hypothesis. The candidate label will replace the {} placeholder.\n     * @param {boolean} [options.multi_label=false] Whether or not multiple candidate labels can be true.\n     * If `false`, the scores are normalized such that the sum of the label likelihoods for each sequence\n     * is 1. If `true`, the labels are considered independent and probabilities are normalized for each\n     * candidate by doing a softmax of the entailment score vs. the contradiction score.\n     * @return {Promise<Object|Object[]>} The prediction(s), as a map (or list of maps) from label to score.\n     */\n    // @ts-ignore\n    async _call(texts, candidate_labels, {\n        hypothesis_template = \"This example is {}.\",\n        multi_label = false,\n    } = {}) {\n\n        let isBatched = Array.isArray(texts);\n\n        if (!isBatched) {\n            texts = [texts];\n        }\n        if (!Array.isArray(candidate_labels)) {\n            candidate_labels = [candidate_labels];\n        }\n\n        // Insert labels into hypothesis template\n        let hypotheses = candidate_labels.map(\n            x => hypothesis_template.replace('{}', x)\n        );\n\n        // How to perform the softmax over the logits:\n        //  - true:  softmax over the entailment vs. contradiction dim for each label independently\n        //  - false: softmax the \"entailment\" logits over all candidate labels\n        let softmaxEach = multi_label || candidate_labels.length === 1;\n\n        let toReturn = [];\n        for (let premise of texts) {\n            let entails_logits = [];\n\n            for (let hypothesis of hypotheses) {\n                let inputs = this.tokenizer(premise, {\n                    text_pair: hypothesis,\n                })\n                let outputs = await this.model(inputs)\n\n                if (softmaxEach) {\n                    entails_logits.push([\n                        outputs.logits.data[this.contradiction_id],\n                        outputs.logits.data[this.entailment_id]\n                    ])\n                } else {\n                    entails_logits.push(outputs.logits.data[this.entailment_id])\n                }\n            }\n\n            let scores;\n            if (softmaxEach) {\n                scores = entails_logits.map(x => softmax(x)[1]);\n            } else {\n                scores = softmax(entails_logits);\n            }\n\n            // Sort by scores (desc) and return scores with indices\n            let scores_sorted = scores\n                .map((x, i) => [x, i])\n                .sort((a, b) => {\n                    return b[0] - a[0];\n                });\n\n            toReturn.push({\n                sequence: premise,\n                labels: scores_sorted.map(x => candidate_labels[x[1]]),\n                scores: scores_sorted.map(x => x[0]),\n            });\n        }\n        return isBatched ? toReturn : toReturn[0];\n    }\n}\n\n\n/**\n * Feature extraction pipeline using no model head. This pipeline extracts the hidden\n * states from the base transformer, which can be used as features in downstream tasks.\n * \n * **Example:** Run feature extraction with `bert-base-uncased` (without pooling/normalization).\n * ```javascript\n * let extractor = await pipeline('feature-extraction', 'Xenova/bert-base-uncased', { revision: 'default' });\n * let result = await extractor('This is a simple test.');\n * console.log(result);\n * // Tensor {\n * //     type: 'float32',\n * //     data: Float32Array [0.05939924716949463, 0.021655935794115067, ...],\n * //     dims: [1, 8, 768]\n * // }\n * ```\n * \n * **Example:** Run feature extraction with `bert-base-uncased` (with pooling/normalization).\n * ```javascript\n * let extractor = await pipeline('feature-extraction', 'Xenova/bert-base-uncased', { revision: 'default' });\n * let result = await extractor('This is a simple test.', { pooling: 'mean', normalize: true });\n * console.log(result);\n * // Tensor {\n * //     type: 'float32',\n * //     data: Float32Array [0.03373778983950615, -0.010106077417731285, ...],\n * //     dims: [1, 768]\n * // }\n * ```\n * \n * **Example:** Calculating embeddings with `sentence-transformers` models.\n * ```javascript\n * let extractor = await pipeline('feature-extraction', 'Xenova/all-MiniLM-L6-v2');\n * let result = await extractor('This is a simple test.', { pooling: 'mean', normalize: true });\n * console.log(result);\n * // Tensor {\n * //     type: 'float32',\n * //     data: Float32Array [0.09094982594251633, -0.014774246141314507, ...],\n * //     dims: [1, 384]\n * // }\n * ```\n * @extends Pipeline\n */\nexport class FeatureExtractionPipeline extends Pipeline {\n\n    /**\n     * Extract the features of the input(s).\n     * \n     * @param {string|string[]} texts The input texts\n     * @param {Object} options Additional options:\n     * @param {string} [options.pooling=\"none\"] The pooling method to use. Can be one of: \"none\", \"mean\".\n     * @param {boolean} [options.normalize=false] Whether or not to normalize the embeddings in the last dimension.\n     * @returns The features computed by the model.\n     */\n    async _call(texts, {\n        pooling = 'none',\n        normalize = false,\n    } = {}) {\n        let [inputs, outputs] = await super._call(texts);\n\n        // TODO: Provide warning to the user that they might be using model which was not exported\n        // specifically for feature extraction\n        // console.log(this.model.config)\n        // console.log(outputs)\n\n        let result = outputs.last_hidden_state ?? outputs.logits;\n        if (pooling === 'none') {\n            // Skip pooling\n        } else if (pooling === 'mean') {\n            result = mean_pooling(result, inputs.attention_mask);\n        } else {\n            throw Error(`Pooling method '${pooling}' not supported.`);\n        }\n\n        if (normalize) {\n            result = result.normalize(2, -1);\n        }\n\n        return result;\n    }\n}\n\n// TODO\n// export class SentenceSimilarityPipeline extends Pipeline {\n// }\n\n\n/**\n * Pipeline that aims at extracting spoken text contained within some audio.\n *\n * **Example:** Transcribe English.\n * ```javascript\n * let url = 'https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/jfk.wav';\n * let transcriber = await pipeline('automatic-speech-recognition', 'Xenova/whisper-tiny.en');\n * let output = await transcriber(url);\n * // { text: \" And so my fellow Americans ask not what your country can do for you, ask what you can do for your country.\" }\n * ```\n * \n * **Example:** Transcribe English w/ timestamps.\n * ```javascript\n * let url = 'https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/jfk.wav';\n * let transcriber = await pipeline('automatic-speech-recognition', 'Xenova/whisper-tiny.en');\n * let output = await transcriber(url, { return_timestamps: true });\n * // {\n * //   text: \" And so my fellow Americans ask not what your country can do for you, ask what you can do for your country.\"\n * //   chunks: [\n * //     { timestamp: [0, 8],  text: \" And so my fellow Americans ask not what your country can do for you\" }\n * //     { timestamp: [8, 11], text: \" ask what you can do for your country.\" }\n * //   ]\n * // }\n * ```\n * \n * **Example:** Transcribe French.\n * ```javascript\n * let url = 'https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/french-audio.mp3';\n * let transcriber = await pipeline('automatic-speech-recognition', 'Xenova/whisper-small');\n * let output = await transcriber(url, { language: 'french', task: 'transcribe' });\n * // { text: \" J'adore, j'aime, je n'aime pas, je d√©teste.\" }\n * ```\n * \n * **Example:** Translate French to English.\n * ```javascript\n * let url = 'https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/french-audio.mp3';\n * let transcriber = await pipeline('automatic-speech-recognition', 'Xenova/whisper-small');\n * let output = await transcriber(url, { language: 'french', task: 'translate' });\n * // { text: \" I love, I like, I don't like, I hate.\" }\n * ```\n * @extends Pipeline\n */\nexport class AutomaticSpeechRecognitionPipeline extends Pipeline {\n\n    /**\n     * Create a new AutomaticSpeechRecognitionPipeline.\n     * @param {string} task The task of the pipeline. Useful for specifying subtasks.\n     * @param {PreTrainedTokenizer} tokenizer The tokenizer to use.\n     * @param {PreTrainedModel} model The model to use.\n     * @param {Processor} processor The processor to use.\n     */\n    constructor(task, tokenizer, model, processor) {\n        super(task, tokenizer, model);\n        this.processor = processor;\n    }\n\n    /**\n     * Preprocesses the input audio for the AutomaticSpeechRecognitionPipeline.\n     * @param {any} audio The audio to be preprocessed.\n     * @param {number} sampling_rate The sampling rate of the audio.\n     * @returns {Promise<Float32Array>} A promise that resolves to the preprocessed audio data.\n     * @private\n     */\n    async _preprocess(audio, sampling_rate) {\n        if (isString(audio)) {\n            audio = await read_audio(audio, sampling_rate);\n        }\n\n        return audio;\n    }\n\n    /**\n     * @typedef {import('./utils/tensor.js').Tensor} Tensor\n     * @typedef {{stride: number[], input_features: Tensor, is_last: boolean, tokens?: number[]}} Chunk\n     * \n     * @callback ChunkCallback\n     * @param {Chunk} chunk The chunk to process.\n     */\n\n    /**\n     * Asynchronously processes audio and generates text transcription using the model.\n     * @param {Float32Array|Float32Array[]} audio The audio to be transcribed. Can be a single Float32Array or an array of Float32Arrays.\n     * @param {Object} [kwargs={}] Optional arguments.\n     * @param {boolean} [kwargs.return_timestamps] Whether to return timestamps or not. Default is `false`.\n     * @param {number} [kwargs.chunk_length_s] The length of audio chunks to process in seconds. Default is 0 (no chunking).\n     * @param {number} [kwargs.stride_length_s] The length of overlap between consecutive audio chunks in seconds. If not provided, defaults to `chunk_length_s / 6`.\n     * @param {ChunkCallback} [kwargs.chunk_callback] Callback function to be called with each chunk processed.\n     * @param {boolean} [kwargs.force_full_sequences] Whether to force outputting full sequences or not. Default is `false`.\n     * @param {string} [kwargs.language] The source language. Default is `null`, meaning it should be auto-detected. Use this to potentially improve performance if the source language is known.\n     * @param {string} [kwargs.task] The task to perform. Default is `null`, meaning it should be auto-detected.\n     * @param {number[][]} [kwargs.forced_decoder_ids] A list of pairs of integers which indicates a mapping from generation indices to token indices\n     * that will be forced before sampling. For example, [[1, 123]] means the second generated token will always be a token of index 123.\n     * @returns {Promise<Object>} A Promise that resolves to an object containing the transcription text and optionally timestamps if `return_timestamps` is `true`.\n     */\n    async _call(audio, kwargs = {}) {\n        let return_timestamps = kwargs.return_timestamps ?? false;\n        let chunk_length_s = kwargs.chunk_length_s ?? 0;\n        let stride_length_s = kwargs.stride_length_s ?? null;\n        let chunk_callback = kwargs.chunk_callback ?? null;\n        let force_full_sequences = kwargs.force_full_sequences ?? false;\n\n        let language = pop(kwargs, 'language', null);\n        let task = pop(kwargs, 'task', null);\n\n        if (language || task || return_timestamps) {\n            if (kwargs.forced_decoder_ids) {\n                throw new Error(\"Cannot specify `language`/`task`/`return_timestamps` and `forced_decoder_ids` at the same time.\")\n            }\n            // @ts-ignore\n            let decoder_prompt_ids = this.tokenizer.get_decoder_prompt_ids({ language, task, no_timestamps: !return_timestamps })\n\n            if(decoder_prompt_ids.length > 0){\n                kwargs.forced_decoder_ids = decoder_prompt_ids;\n            }\n        }\n\n        let single = !Array.isArray(audio);\n        if (single) {\n            // @ts-ignore\n            audio = [audio];\n        }\n\n        const sampling_rate = this.processor.feature_extractor.config.sampling_rate;\n        const time_precision = this.processor.feature_extractor.config.chunk_length / this.model.config.max_source_positions;\n\n        let toReturn = [];\n        for (let aud of audio) {\n            aud = await this._preprocess(aud, sampling_rate)\n\n            /** @type {Chunk[]} */\n            let chunks = [];\n            if (chunk_length_s > 0) {\n                if (stride_length_s === null) {\n                    stride_length_s = chunk_length_s / 6;\n                } else if (chunk_length_s <= stride_length_s) {\n                    throw Error(\"`chunk_length_s` must be larger than `stride_length_s`.\")\n                }\n\n                // TODO support different stride_length_s (for left and right)\n\n                const window = sampling_rate * chunk_length_s;\n                const stride = sampling_rate * stride_length_s;\n                const jump = window - 2 * stride;\n                let offset = 0;\n\n                // Create subarrays of audio with overlaps\n\n                while (offset < aud.length) {\n                    let subarr = aud.subarray(offset, offset + window);\n                    let feature = await this.processor(subarr);\n\n                    let isFirst = offset === 0;\n                    let isLast = offset + jump >= aud.length;\n                    chunks.push({\n                        stride: [\n                            subarr.length,\n                            isFirst ? 0 : stride,\n                            isLast ? 0 : stride\n                        ],\n                        input_features: feature.input_features,\n                        is_last: isLast\n                    })\n                    offset += jump;\n                }\n\n            } else {\n                chunks = [{\n                    stride: [aud.length, 0, 0],\n                    input_features: (await this.processor(aud)).input_features,\n                    is_last: true\n                }]\n            }\n\n            // Generate for each set of input features\n            for (let chunk of chunks) {\n                // NOTE: doing sequentially for now\n                let data = await this.model.generate(chunk.input_features, kwargs);\n\n                // Get top beam\n                chunk.tokens = data[0];\n\n                // convert stride to seconds\n                chunk.stride = chunk.stride.map(x => x / sampling_rate);\n\n                if (chunk_callback !== null) {\n                    chunk_callback(chunk)\n                }\n            }\n\n            // Merge text chunks\n            // @ts-ignore\n            let [full_text, optional] = this.tokenizer._decode_asr(chunks, {\n                time_precision: time_precision,\n                return_timestamps: return_timestamps,\n                force_full_sequences: force_full_sequences\n            });\n\n            toReturn.push({ text: full_text, ...optional })\n        }\n        return single ? toReturn[0] : toReturn;\n    }\n}\n\n/**\n * Image To Text pipeline using a `AutoModelForVision2Seq`. This pipeline predicts a caption for a given image.\n * @extends Pipeline\n */\nexport class ImageToTextPipeline extends Pipeline {\n    /**\n     * Create a new ImageToTextPipeline.\n     * @param {string} task The task of the pipeline. Useful for specifying subtasks.\n     * @param {PreTrainedTokenizer} tokenizer The tokenizer to use.\n     * @param {PreTrainedModel} model The model to use.\n     * @param {Processor} processor The processor to use.\n     */\n    constructor(task, tokenizer, model, processor) {\n        super(task, tokenizer, model);\n        this.processor = processor;\n    }\n\n    /**\n     * Assign labels to the image(s) passed as inputs.\n     * @param {any[]} images The images to be captioned.\n     * @param {Object} [generate_kwargs={}] Optional generation arguments.\n     * @returns {Promise<Object|Object[]>} A Promise that resolves to an object (or array of objects) containing the generated text(s).\n     */\n    async _call(images, generate_kwargs = {}) {\n        let isBatched = Array.isArray(images);\n\n        images = await prepareImages(images);\n\n        let { pixel_values } = await this.processor(images);\n\n        let toReturn = [];\n        for (let batch of pixel_values) {\n            batch.dims = [1, ...batch.dims]\n            let output = await this.model.generate(batch, generate_kwargs);\n            let decoded = this.tokenizer.batch_decode(output, {\n                skip_special_tokens: true,\n            }).map(x => {\n                return { generated_text: x.trim() }\n            })\n            toReturn.push(decoded);\n        }\n\n        return isBatched ? toReturn : toReturn[0];\n    }\n}\n\n/**\n * Image classification pipeline using any `AutoModelForImageClassification`.\n * This pipeline predicts the class of an image.\n * @extends Pipeline\n */\nexport class ImageClassificationPipeline extends Pipeline {\n    /**\n     * Create a new ImageClassificationPipeline.\n     * @param {string} task The task of the pipeline. Useful for specifying subtasks.\n     * @param {PreTrainedModel} model The model to use.\n     * @param {Processor} processor The processor to use.\n     */\n    constructor(task, model, processor) {\n        super(task, null, model); // TODO tokenizer\n        this.processor = processor;\n    }\n\n    /**\n     * Classify the given images.\n     * @param {any} images The images to classify.\n     * @param {Object} options The options to use for classification.\n     * @param {number} [options.topk=1] The number of top results to return.\n     * @returns {Promise<any>} The top classification results for the images.\n     */\n    async _call(images, {\n        topk = 1\n    } = {}) {\n        let isBatched = Array.isArray(images);\n        images = await prepareImages(images);\n\n        let { pixel_values } = await this.processor(images);\n        let output = await this.model({ pixel_values });\n\n        let id2label = this.model.config.id2label;\n        let toReturn = [];\n        for (let batch of output.logits) {\n            let scores = getTopItems(softmax(batch.data), topk);\n\n            let vals = scores.map(function (x) {\n                return {\n                    label: id2label[x[0]],\n                    score: x[1],\n                }\n            });\n            if (topk === 1) {\n                toReturn.push(...vals);\n            } else {\n                toReturn.push(vals);\n            }\n        }\n\n        return isBatched || topk === 1 ? toReturn : toReturn[0];\n    }\n\n}\n\n/**\n * Image segmentation pipeline using any `AutoModelForXXXSegmentation`.\n * This pipeline predicts masks of objects and their classes.\n * @extends Pipeline\n */\nexport class ImageSegmentationPipeline extends Pipeline {\n    /**\n     * Create a new ImageSegmentationPipeline.\n     * @param {string} task The task of the pipeline. Useful for specifying subtasks.\n     * @param {PreTrainedModel} model The model to use.\n     * @param {Processor} processor The processor to use.\n     */\n    constructor(task, model, processor) {\n        super(task, null, model); // TODO tokenizer\n        this.processor = processor;\n\n        this.subtasks_mapping = {\n            // Mapping of subtasks to their corresponding post-processing function names.\n            panoptic: 'post_process_panoptic_segmentation',\n            instance: 'post_process_instance_segmentation',\n            semantic: 'post_process_semantic_segmentation'\n        }\n    }\n\n    /**\n     * Segment the input images.\n     * @param {Array} images The input images.\n     * @param {Object} options The options to use for segmentation.\n     * @param {number} [options.threshold=0.5] Probability threshold to filter out predicted masks.\n     * @param {number} [options.mask_threshold=0.5] Threshold to use when turning the predicted masks into binary values.\n     * @param {number} [options.overlap_mask_area_threshold=0.8] Mask overlap threshold to eliminate small, disconnected segments.\n     * @param {null|string} [options.subtask=null] Segmentation task to be performed. One of [`panoptic`, `instance`, and `semantic`], depending on model capabilities. If not set, the pipeline will attempt to resolve (in that order).\n     * @param {Array} [options.label_ids_to_fuse=null] List of label ids to fuse. If not set, do not fuse any labels.\n     * @param {Array} [options.target_sizes=null] List of target sizes for the input images. If not set, use the original image sizes.\n     * @returns {Promise<Array>} The annotated segments.\n     */\n    async _call(images, {\n        threshold = 0.5,\n        mask_threshold = 0.5,\n        overlap_mask_area_threshold = 0.8,\n        label_ids_to_fuse = null,\n        target_sizes = null,\n        subtask = null, // TODO use\n    } = {}) {\n        let isBatched = Array.isArray(images);\n\n        if (isBatched && images.length !== 1) {\n            throw Error(\"Image segmentation pipeline currently only supports a batch size of 1.\");\n        }\n\n        images = await prepareImages(images);\n        let imageSizes = images.map(x => [x.height, x.width]);\n\n        let { pixel_values, pixel_mask } = await this.processor(images);\n        let output = await this.model({ pixel_values, pixel_mask });\n\n        let fn = null;\n        if (subtask !== null) {\n            fn = this.subtasks_mapping[subtask];\n        } else {\n            for (let [task, func] of Object.entries(this.subtasks_mapping)) {\n                if (func in this.processor.feature_extractor) {\n                    fn = this.processor.feature_extractor[func].bind(this.processor.feature_extractor);\n                    subtask = task;\n                    break;\n                }\n            }\n        }\n\n        // add annotations\n        let annotation = [];\n\n        if (subtask === 'panoptic' || subtask === 'instance') {\n\n            let processed = fn(\n                output,\n                threshold,\n                mask_threshold,\n                overlap_mask_area_threshold,\n                label_ids_to_fuse,\n                target_sizes ?? imageSizes, // TODO FIX?\n            )[0];\n\n            let segmentation = processed.segmentation;\n            let id2label = this.model.config.id2label;\n\n            for (let segment of processed.segments_info) {\n                let maskData = new Uint8ClampedArray(segmentation.data.length);\n                for (let i = 0; i < segmentation.data.length; ++i) {\n                    if (segmentation.data[i] === segment.id) {\n                        maskData[i] = 255;\n                    }\n                }\n\n                let mask = new RawImage(maskData, segmentation.dims[1], segmentation.dims[0], 1)\n\n                annotation.push({\n                    score: segment.score,\n                    label: id2label[segment.label_id],\n                    mask: mask\n                })\n            }\n\n        } else if (subtask === 'semantic') {\n            throw Error(`semantic segmentation not yet supported.`);\n\n        } else {\n            throw Error(`Subtask ${subtask} not supported.`);\n        }\n\n        return annotation;\n    }\n}\n\n\n/**\n * Zero shot image classification pipeline. This pipeline predicts the class of\n * an image when you provide an image and a set of `candidate_labels`.\n * @extends Pipeline\n */\nexport class ZeroShotImageClassificationPipeline extends Pipeline {\n\n    /**\n     * Create a new ZeroShotImageClassificationPipeline.\n     * @param {string} task The task of the pipeline. Useful for specifying subtasks.\n     * @param {PreTrainedTokenizer} tokenizer The tokenizer to use.\n     * @param {PreTrainedModel} model The model to use.\n     * @param {Processor} processor The processor to use.\n     */\n    constructor(task, tokenizer, model, processor) {\n        super(task, tokenizer, model);\n        this.processor = processor;\n    }\n\n    /**\n     * Classify the input images with candidate labels using a zero-shot approach.\n     * @param {Array} images The input images.\n     * @param {Array} candidate_labels The candidate labels.\n     * @param {Object} options The options for the classification.\n     * @param {string} [options.hypothesis_template] The hypothesis template to use for zero-shot classification. Default: \"This is a photo of {}\".\n     * @returns {Promise<any>} An array of classifications for each input image or a single classification object if only one input image is provided.\n     */\n    // @ts-ignore\n    async _call(images, candidate_labels, {\n        hypothesis_template = \"This is a photo of {}\"\n    } = {}) {\n        let isBatched = Array.isArray(images);\n        images = await prepareImages(images);\n\n        // Insert label into hypothesis template \n        let texts = candidate_labels.map(\n            x => hypothesis_template.replace('{}', x)\n        );\n\n        // Run tokenization\n        let text_inputs = this.tokenizer(texts, {\n            padding: true,\n            truncation: true\n        });\n\n        // Run processor\n        let { pixel_values } = await this.processor(images);\n\n        // Run model with both text and pixel inputs\n        let output = await this.model({ ...text_inputs, pixel_values });\n\n        // Compare each image with each candidate label\n        let toReturn = [];\n        for (let batch of output.logits_per_image) {\n            // Compute softmax per image\n            let probs = softmax(batch.data);\n\n            toReturn.push([...probs].map((x, i) => {\n                return {\n                    score: x,\n                    label: candidate_labels[i]\n                }\n            }));\n        }\n\n        return isBatched ? toReturn : toReturn[0];\n    }\n}\n\n/**\n * Object detection pipeline using any `AutoModelForObjectDetection`.\n * This pipeline predicts bounding boxes of objects and their classes.\n * @extends Pipeline\n */\nexport class ObjectDetectionPipeline extends Pipeline {\n    /**\n     * Create a new ObjectDetectionPipeline.\n     * @param {string} task The task of the pipeline. Useful for specifying subtasks.\n     * @param {PreTrainedModel} model The model to use.\n     * @param {Processor} processor The processor to use.\n     */\n    constructor(task, model, processor) {\n        super(task, null, model); // TODO tokenizer\n        this.processor = processor;\n    }\n\n    /**\n     * Detect objects (bounding boxes & classes) in the image(s) passed as inputs.\n     * @param {any[]} images The input images.\n     * @param {Object} options The options for the object detection.\n     * @param {number} [options.threshold=0.9] The threshold used to filter boxes by score.\n     * @param {boolean} [options.percentage=false] Whether to return the boxes coordinates in percentage (true) or in pixels (false).\n     */\n    async _call(images, {\n        threshold = 0.9,\n        percentage = false,\n    } = {}) {\n        let isBatched = Array.isArray(images);\n\n        if (isBatched && images.length !== 1) {\n            throw Error(\"Object detection pipeline currently only supports a batch size of 1.\");\n        }\n        images = await prepareImages(images);\n\n        let imageSizes = percentage ? null : images.map(x => [x.height, x.width]);\n\n        let { pixel_values, pixel_mask } = await this.processor(images);\n        let output = await this.model({ pixel_values, pixel_mask });\n\n        // @ts-ignore\n        let processed = this.processor.feature_extractor.post_process_object_detection(output, threshold, imageSizes);\n\n        // Add labels\n        let id2label = this.model.config.id2label;\n        processed.forEach(x => x.labels = x.classes.map(y => id2label[y]));\n\n        return isBatched ? processed : processed[0];\n    }\n}\n\nconst SUPPORTED_TASKS = {\n    \"text-classification\": {\n        \"tokenizer\": AutoTokenizer,\n        \"pipeline\": TextClassificationPipeline,\n        \"model\": AutoModelForSequenceClassification,\n        \"default\": {\n            // TODO: replace with original\n            // \"model\": \"distilbert-base-uncased-finetuned-sst-2-english\",\n            \"model\": \"Xenova/distilbert-base-uncased-finetuned-sst-2-english\",\n        },\n        \"type\": \"text\",\n    },\n    \"token-classification\": {\n        \"tokenizer\": AutoTokenizer,\n        \"pipeline\": TokenClassificationPipeline,\n        \"model\": AutoModelForTokenClassification,\n        \"default\": {\n            // TODO: replace with original\n            // \"model\": \"Davlan/bert-base-multilingual-cased-ner-hrl\",\n            \"model\": \"Xenova/bert-base-multilingual-cased-ner-hrl\",\n        },\n        \"type\": \"text\",\n    },\n    \"question-answering\": {\n        \"tokenizer\": AutoTokenizer,\n        \"pipeline\": QuestionAnsweringPipeline,\n        \"model\": AutoModelForQuestionAnswering,\n        \"default\": {\n            // TODO: replace with original\n            // \"model\": \"distilbert-base-cased-distilled-squad\",\n            \"model\": \"Xenova/distilbert-base-cased-distilled-squad\",\n        },\n        \"type\": \"text\",\n    },\n\n    \"fill-mask\": {\n        \"tokenizer\": AutoTokenizer,\n        \"pipeline\": FillMaskPipeline,\n        \"model\": AutoModelForMaskedLM,\n        \"default\": {\n            // TODO: replace with original\n            // \"model\": \"bert-base-uncased\",\n            \"model\": \"Xenova/bert-base-uncased\",\n        },\n        \"type\": \"text\",\n    },\n    \"summarization\": {\n        \"tokenizer\": AutoTokenizer,\n        \"pipeline\": SummarizationPipeline,\n        \"model\": AutoModelForSeq2SeqLM,\n        \"default\": {\n            // TODO: replace with original\n            // \"model\": \"sshleifer/distilbart-cnn-6-6\",\n            \"model\": \"Xenova/distilbart-cnn-6-6\",\n        },\n        \"type\": \"text\",\n    },\n    \"translation\": {\n        \"tokenizer\": AutoTokenizer,\n        \"pipeline\": TranslationPipeline,\n        \"model\": AutoModelForSeq2SeqLM,\n        \"default\": {\n            // TODO: replace with original\n            // \"model\": \"t5-small\",\n            \"model\": \"Xenova/t5-small\",\n        },\n        \"type\": \"text\",\n    },\n    \"text2text-generation\": {\n        \"tokenizer\": AutoTokenizer,\n        \"pipeline\": Text2TextGenerationPipeline,\n        \"model\": AutoModelForSeq2SeqLM,\n        \"default\": {\n            // TODO: replace with original\n            // \"model\": \"google/flan-t5-small\",\n            \"model\": \"Xenova/flan-t5-small\",\n        },\n        \"type\": \"text\",\n    },\n    \"text-generation\": {\n        \"tokenizer\": AutoTokenizer,\n        \"pipeline\": TextGenerationPipeline,\n        \"model\": AutoModelForCausalLM,\n        \"default\": {\n            // TODO: replace with original\n            // \"model\": \"gpt2\",\n            \"model\": \"Xenova/gpt2\",\n        },\n        \"type\": \"text\",\n    },\n    \"zero-shot-classification\": {\n        \"tokenizer\": AutoTokenizer,\n        \"pipeline\": ZeroShotClassificationPipeline,\n        \"model\": AutoModelForSequenceClassification,\n        \"default\": {\n            // TODO: replace with original\n            // \"model\": \"typeform/distilbert-base-uncased-mnli\",\n            \"model\": \"Xenova/distilbert-base-uncased-mnli\",\n        },\n        \"type\": \"text\",\n    },\n\n    \"automatic-speech-recognition\": {\n        \"tokenizer\": AutoTokenizer,\n        \"pipeline\": AutomaticSpeechRecognitionPipeline,\n        \"model\": AutoModelForSeq2SeqLM,\n        \"processor\": AutoProcessor,\n        \"default\": {\n            // TODO: replace with original\n            // \"model\": \"openai/whisper-tiny.en\",\n            \"model\": \"Xenova/whisper-tiny.en\",\n        },\n        \"type\": \"multimodal\",\n    },\n\n    \"image-to-text\": {\n        \"tokenizer\": AutoTokenizer,\n        \"pipeline\": ImageToTextPipeline,\n        \"model\": AutoModelForVision2Seq,\n        \"processor\": AutoProcessor,\n        \"default\": {\n            // TODO: replace with original\n            // \"model\": \"nlpconnect/vit-gpt2-image-captioning\",\n            \"model\": \"Xenova/vit-gpt2-image-captioning\",\n        },\n        \"type\": \"multimodal\",\n    },\n\n    \"image-classification\": {\n        // no tokenizer\n        \"pipeline\": ImageClassificationPipeline,\n        \"model\": AutoModelForImageClassification,\n        \"processor\": AutoProcessor,\n        \"default\": {\n            // TODO: replace with original\n            // \"model\": \"google/vit-base-patch16-224\",\n            \"model\": \"Xenova/vit-base-patch16-224\",\n        },\n        \"type\": \"multimodal\",\n    },\n\n    \"image-segmentation\": {\n        // no tokenizer\n        \"pipeline\": ImageSegmentationPipeline,\n        \"model\": AutoModelForImageSegmentation,\n        \"processor\": AutoProcessor,\n        \"default\": {\n            // TODO: replace with original\n            // \"model\": \"facebook/detr-resnet-50-panoptic\",\n            \"model\": \"Xenova/detr-resnet-50-panoptic\",\n        },\n        \"type\": \"multimodal\",\n    },\n\n    \"zero-shot-image-classification\": {\n        // no tokenizer\n        \"tokenizer\": AutoTokenizer,\n        \"pipeline\": ZeroShotImageClassificationPipeline,\n        \"model\": AutoModel,\n        \"processor\": AutoProcessor,\n        \"default\": {\n            // TODO: replace with original\n            // \"model\": \"openai/clip-vit-base-patch32\",\n            \"model\": \"Xenova/clip-vit-base-patch32\",\n        },\n        \"type\": \"multimodal\",\n    },\n\n    \"object-detection\": {\n        // no tokenizer\n        \"pipeline\": ObjectDetectionPipeline,\n        \"model\": AutoModelForObjectDetection,\n        \"processor\": AutoProcessor,\n        \"default\": {\n            // TODO: replace with original\n            // \"model\": \"facebook/detr-resnet-50\",\n            \"model\": \"Xenova/detr-resnet-50\",\n        },\n        \"type\": \"multimodal\",\n    },\n\n    // This task serves as a useful interface for dealing with sentence-transformers (https://huggingface.co/sentence-transformers).\n    \"feature-extraction\": {\n        \"tokenizer\": AutoTokenizer,\n        \"pipeline\": FeatureExtractionPipeline,\n        \"model\": AutoModel,\n        \"default\": {\n            // TODO: replace with original\n            // \"model\": \"sentence-transformers/all-MiniLM-L6-v2\",\n            \"model\": \"Xenova/all-MiniLM-L6-v2\",\n        },\n        \"type\": \"text\",\n    },\n}\n\n\nconst TASK_ALIASES = {\n    \"sentiment-analysis\": \"text-classification\",\n    \"ner\": \"token-classification\",\n    \"vqa\": \"visual-question-answering\",\n    \"asr\": \"automatic-speech-recognition\",\n\n    // Add for backwards compatibility\n    \"embeddings\": \"feature-extraction\",\n}\n\n/**\n * @typedef {import('./utils/hub.js').PretrainedOptions} PretrainedOptions\n */\n\n/**\n * Utility factory method to build a [`Pipeline`] object.\n *\n * @param {string} task The task of the pipeline.\n * @param {string} [model=null] The name of the pre-trained model to use. If not specified, the default model for the task will be used.\n * @param {PretrainedOptions} [options] Optional parameters for the pipeline.\n * @returns {Promise<Pipeline>} A Pipeline object for the specified task.\n * @throws {Error} If an unsupported pipeline is requested.\n */\nexport async function pipeline(\n    task,\n    model = null,\n    {\n        quantized = true,\n        progress_callback = null,\n        config = null,\n        cache_dir = null,\n        local_files_only = false,\n        revision = 'main',\n    } = {}\n) {\n    // Helper method to construct pipeline\n\n    // Apply aliases\n    task = TASK_ALIASES[task] ?? task;\n\n    // Get pipeline info\n    let pipelineInfo = SUPPORTED_TASKS[task.split('_', 1)[0]];\n    if (!pipelineInfo) {\n        throw Error(`Unsupported pipeline: ${task}. Must be one of [${Object.keys(SUPPORTED_TASKS)}]`)\n    }\n\n    // Use model if specified, otherwise, use default\n    if (!model) {\n        model = pipelineInfo.default.model\n        console.log(`No model specified. Using default model: \"${model}\".`);\n    }\n\n    let tokenizerClass = pipelineInfo.tokenizer;\n    let modelClass = pipelineInfo.model;\n    let pipelineClass = pipelineInfo.pipeline;\n    let processorClass = pipelineInfo.processor;\n\n    let promises = [];\n\n    let pretrainedOptions = {\n        quantized,\n        progress_callback,\n        config,\n        cache_dir,\n        local_files_only,\n        revision,\n    }\n    if (tokenizerClass) {\n        promises.push(\n            tokenizerClass.from_pretrained(model, pretrainedOptions),\n        )\n    }\n    if (modelClass) {\n        promises.push(\n            modelClass.from_pretrained(model, pretrainedOptions)\n        )\n    }\n\n    if (processorClass) {\n        promises.push(\n            processorClass.from_pretrained(model, pretrainedOptions)\n        )\n    }\n\n    // Load tokenizer and model\n    let items = await Promise.all(promises)\n\n    dispatchCallback(progress_callback, {\n        'status': 'ready',\n        'task': task,\n        'model': model,\n    });\n\n    return new pipelineClass(task, ...items);\n\n}\n\n/**\n * Compute the Cartesian product of given arrays\n * @param {...Array} a Arrays to compute the product\n * @returns {Array} Returns the computed Cartesian product as an array\n * @private\n */\nfunction product(...a) {\n    // Cartesian product of items\n    // Adapted from https://stackoverflow.com/a/43053803\n    return a.reduce((a, b) => a.flatMap(d => b.map(e => [d, e])));\n}\n"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,SACIA,aAAa,EACbC,mBAAmB,QAChB,iBAAiB;AACxB,SACIC,SAAS,EACTC,kCAAkC,EAClCC,+BAA+B,EAC/BC,6BAA6B,EAC7BC,oBAAoB,EACpBC,qBAAqB,EACrBC,oBAAoB,EACpBC,sBAAsB,EACtBC,+BAA+B,EAC/BC,6BAA6B,EAC7BC,2BAA2B,EAC3BC,eAAe,QACZ,aAAa;AACpB,SACIC,aAAa,EACbC,SAAS,QACN,iBAAiB;AAGxB,SACIC,QAAQ,EACRC,QAAQ,EACRC,gBAAgB,EAChBC,GAAG,QACA,iBAAiB;AACxB,SACIC,OAAO,EACPC,GAAG,EACHC,WAAW,QACR,kBAAkB;AACzB,SACIC,UAAU,QACP,kBAAkB;AACzB,SACIC,YAAY,QACT,mBAAmB;AAC1B,SAASC,QAAQ,QAAQ,kBAAkB;;AAE3C;AACA;AACA;AACA;AACA;AACA;AACA,eAAeC,aAAaA,CAACC,MAAM,EAAE;EACjC,IAAI,CAACC,KAAK,CAACC,OAAO,CAACF,MAAM,CAAC,EAAE;IACxBA,MAAM,GAAG,CAACA,MAAM,CAAC;EACrB;;EAEA;EACAA,MAAM,GAAG,MAAMG,OAAO,CAACC,GAAG,CAACJ,MAAM,CAACK,GAAG,CAACC,CAAC,IAAIR,QAAQ,CAACS,IAAI,CAACD,CAAC,CAAC,CAAC,CAAC;EAC7D,OAAON,MAAM;AACjB;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMQ,QAAQ,SAASnB,QAAQ,CAAC;EACnC;AACJ;AACA;AACA;AACA;AACA;EACIoB,WAAWA,CAACC,IAAI,EAAEC,SAAS,EAAEC,KAAK,EAAE;IAChC,KAAK,CAAC,CAAC;IACP,IAAI,CAACF,IAAI,GAAGA,IAAI;IAChB,IAAI,CAACC,SAAS,GAAGA,SAAS;IAC1B,IAAI,CAACC,KAAK,GAAGA,KAAK;EACtB;;EAEA;AACJ;AACA;AACA;EACI,MAAMC,OAAOA,CAAA,EAAG;IACZ,MAAM,IAAI,CAACD,KAAK,CAACC,OAAO,CAAC,CAAC;EAC9B;;EAEA;AACJ;AACA;AACA;AACA;EACI,MAAMC,KAAKA,CAACC,KAAK,EAAE;IACf;IACA,IAAIC,MAAM,GAAG,IAAI,CAACL,SAAS,CAACI,KAAK,EAAE;MAC/BE,OAAO,EAAE,IAAI;MACbC,UAAU,EAAE;IAChB,CAAC,CAAC;;IAEF;IACA,IAAIC,OAAO,GAAG,MAAM,IAAI,CAACP,KAAK,CAACI,MAAM,CAAC;IAEtC,OAAO,CAACA,MAAM,EAAEG,OAAO,CAAC;EAC5B;AACJ;;AAEA;AACA;AACA;AACA;AACA,OAAO,MAAMC,0BAA0B,SAASZ,QAAQ,CAAC;EACrD;AACJ;AACA;AACA;AACA;AACA;AACA;EACI,MAAMM,KAAKA,CAACC,KAAK,EAET;IAAA,IAFW;MACfM,IAAI,GAAG;IACX,CAAC,GAAAC,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,CAAC,CAAC;IAEF,IAAI,CAACN,MAAM,EAAEG,OAAO,CAAC,GAAG,MAAM,KAAK,CAACL,KAAK,CAACC,KAAK,CAAC;IAEhD,IAAIU,QAAQ,GAAG,IAAI,CAACb,KAAK,CAACc,MAAM,CAACD,QAAQ;IACzC,IAAIE,QAAQ,GAAG,EAAE;IACjB,KAAK,IAAIC,KAAK,IAAIT,OAAO,CAACU,MAAM,EAAE;MAC9B,IAAIC,MAAM,GAAGnC,WAAW,CAACF,OAAO,CAACmC,KAAK,CAACG,IAAI,CAAC,EAAEV,IAAI,CAAC;MAEnD,IAAIW,IAAI,GAAGF,MAAM,CAACzB,GAAG,CAAC,UAAUC,CAAC,EAAE;QAC/B,OAAO;UACH2B,KAAK,EAAER,QAAQ,CAACnB,CAAC,CAAC,CAAC,CAAC,CAAC;UACrB4B,KAAK,EAAE5B,CAAC,CAAC,CAAC;QACd,CAAC;MACL,CAAC,CAAC;MACF,IAAIe,IAAI,KAAK,CAAC,EAAE;QACZM,QAAQ,CAACQ,IAAI,CAAC,GAAGH,IAAI,CAAC;MAC1B,CAAC,MAAM;QACHL,QAAQ,CAACQ,IAAI,CAACH,IAAI,CAAC;MACvB;IACJ;IAEA,OAAO/B,KAAK,CAACC,OAAO,CAACa,KAAK,CAAC,IAAIM,IAAI,KAAK,CAAC,GAAGM,QAAQ,GAAGA,QAAQ,CAAC,CAAC,CAAC;EACtE;AACJ;;AAGA;AACA;AACA;AACA;AACA,OAAO,MAAMS,2BAA2B,SAAS5B,QAAQ,CAAC;EACtD;AACJ;AACA;AACA;AACA;AACA;EACI,MAAMM,KAAKA,CAACC,KAAK,EAET;IAAA,IAFW;MACfsB,aAAa,GAAG,CAAC,GAAG,CAAC,CAAE;IAC3B,CAAC,GAAAf,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,CAAC,CAAC;IAEF,IAAIgB,SAAS,GAAGrC,KAAK,CAACC,OAAO,CAACa,KAAK,CAAC;IAEpC,IAAI,CAACuB,SAAS,EAAE;MACZvB,KAAK,GAAG,CAACA,KAAK,CAAC;IACnB;IAEA,IAAIJ,SAAS,GAAG,IAAI,CAACA,SAAS;IAC9B,IAAI,CAACK,MAAM,EAAEG,OAAO,CAAC,GAAG,MAAM,KAAK,CAACL,KAAK,CAACC,KAAK,CAAC;IAEhD,IAAIc,MAAM,GAAGV,OAAO,CAACU,MAAM;IAC3B,IAAIJ,QAAQ,GAAG,IAAI,CAACb,KAAK,CAACc,MAAM,CAACD,QAAQ;IAEzC,IAAIE,QAAQ,GAAG,EAAE;IACjB,KAAK,IAAIY,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGV,MAAM,CAACW,IAAI,CAAC,CAAC,CAAC,EAAE,EAAED,CAAC,EAAE;MACrC,IAAIE,GAAG,GAAGzB,MAAM,CAAC0B,SAAS,CAACH,CAAC,CAAC;MAC7B,IAAIX,KAAK,GAAGC,MAAM,CAACU,CAAC,CAAC;;MAErB;MACA,IAAII,MAAM,GAAG,EAAE;MACf,KAAK,IAAIC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGhB,KAAK,CAACY,IAAI,CAAC,CAAC,CAAC,EAAE,EAAEI,CAAC,EAAE;QACpC,IAAIC,SAAS,GAAGjB,KAAK,CAACgB,CAAC,CAAC;QACxB,IAAIE,aAAa,GAAGpD,GAAG,CAACmD,SAAS,CAACd,IAAI,CAAC,CAAC,CAAC,CAAC;QAE1C,IAAIgB,MAAM,GAAGtB,QAAQ,CAACqB,aAAa,CAAC;QACpC,IAAIT,aAAa,CAACW,QAAQ,CAACD,MAAM,CAAC,EAAE;UAChC;UACA;QACJ;;QAEA;QACA,IAAIE,IAAI,GAAGtC,SAAS,CAACuC,MAAM,CAAC,CAACT,GAAG,CAACG,CAAC,CAAC,CAACO,IAAI,CAAC,CAAC,CAAC,EAAE;UAAEC,mBAAmB,EAAE;QAAK,CAAC,CAAC;QAC3E,IAAIH,IAAI,KAAK,EAAE,EAAE;UACb;UACA;QACJ;QAEA,IAAInB,MAAM,GAAGrC,OAAO,CAACoD,SAAS,CAACd,IAAI,CAAC;QAEpCY,MAAM,CAACR,IAAI,CAAC;UACRY,MAAM,EAAEA,MAAM;UACdb,KAAK,EAAEJ,MAAM,CAACgB,aAAa,CAAC;UAC5BO,KAAK,EAAET,CAAC;UACRK,IAAI,EAAEA,IAAI;UAEV;UACAK,KAAK,EAAE,IAAI;UACXC,GAAG,EAAE;QACT,CAAC,CAAC;MACN;MACA5B,QAAQ,CAACQ,IAAI,CAACQ,MAAM,CAAC;IACzB;IACA,OAAOL,SAAS,GAAGX,QAAQ,GAAGA,QAAQ,CAAC,CAAC,CAAC;EAC7C;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAM6B,yBAAyB,SAAShD,QAAQ,CAAC;EACpD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;EACI;EACA,MAAMM,KAAKA,CAAC2C,QAAQ,EAAEC,OAAO,EAErB;IAAA,IAFuB;MAC3BrC,IAAI,GAAG;IACX,CAAC,GAAAC,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,CAAC,CAAC;IAEF,IAAIN,MAAM,GAAG,IAAI,CAACL,SAAS,CAAC8C,QAAQ,EAAE;MAClCE,SAAS,EAAED;IACf,CAAC,CAAC;IAEF,IAAIE,MAAM,GAAG,MAAM,IAAI,CAAChD,KAAK,CAACI,MAAM,CAAC;IAErC,IAAIW,QAAQ,GAAG,EAAE;IACjB,KAAK,IAAIiB,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGgB,MAAM,CAACC,YAAY,CAACrB,IAAI,CAAC,CAAC,CAAC,EAAE,EAAEI,CAAC,EAAE;MAClD,IAAIH,GAAG,GAAGzB,MAAM,CAAC0B,SAAS,CAACE,CAAC,CAAC;MAC7B,IAAIkB,QAAQ,GAAGrB,GAAG,CAACsB,OAAO,CAAC,IAAI,CAACpD,SAAS,CAACqD,YAAY,CAAC;MAEvD,IAAIC,EAAE,GAAGhE,KAAK,CAACiE,IAAI,CAACzE,OAAO,CAACmE,MAAM,CAACC,YAAY,CAACjB,CAAC,CAAC,CAACb,IAAI,CAAC,CAAC,CACpD1B,GAAG,CAAC,CAACC,CAAC,EAAEiC,CAAC,KAAK,CAACjC,CAAC,EAAEiC,CAAC,CAAC,CAAC,CACrB4B,MAAM,CAAC7D,CAAC,IAAIA,CAAC,CAAC,CAAC,CAAC,GAAGwD,QAAQ,CAAC;MACjC,IAAIM,EAAE,GAAGnE,KAAK,CAACiE,IAAI,CAACzE,OAAO,CAACmE,MAAM,CAACS,UAAU,CAACzB,CAAC,CAAC,CAACb,IAAI,CAAC,CAAC,CAClD1B,GAAG,CAAC,CAACC,CAAC,EAAEiC,CAAC,KAAK,CAACjC,CAAC,EAAEiC,CAAC,CAAC,CAAC,CACrB4B,MAAM,CAAC7D,CAAC,IAAIA,CAAC,CAAC,CAAC,CAAC,GAAGwD,QAAQ,CAAC;MAEjC,IAAIQ,OAAO,GAAGC,OAAO,CAACN,EAAE,EAAEG,EAAE,CAAC,CACxBD,MAAM,CAAC7D,CAAC,IAAIA,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,IAAIA,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAC/BD,GAAG,CAACC,CAAC,IAAI,CAACA,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,EAAEA,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,EAAEA,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,GAAGA,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAC/CkE,IAAI,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKA,CAAC,CAAC,CAAC,CAAC,GAAGD,CAAC,CAAC,CAAC,CAAC,CAAC;MAEhC,KAAK,IAAIE,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGC,IAAI,CAACC,GAAG,CAACP,OAAO,CAAC/C,MAAM,EAAEF,IAAI,CAAC,EAAE,EAAEsD,CAAC,EAAE;QACrD,IAAI,CAACrB,KAAK,EAAEC,GAAG,EAAErB,KAAK,CAAC,GAAGoC,OAAO,CAACK,CAAC,CAAC;QAEpC,IAAIG,aAAa,GAAG,CAAC,GAAGrC,GAAG,CAAC,CAACsC,KAAK,CAACzB,KAAK,EAAEC,GAAG,GAAG,CAAC,CAAC;QAElD,IAAIyB,MAAM,GAAG,IAAI,CAACrE,SAAS,CAACuC,MAAM,CAAC4B,aAAa,EAAE;UAC9C1B,mBAAmB,EAAE;QACzB,CAAC,CAAC;;QAEF;QACA;QACAzB,QAAQ,CAACQ,IAAI,CAAC;UACV6C,MAAM;UAAE9C;QACZ,CAAC,CAAC;MACN;IACJ;;IAEA;IACA,OAAQb,IAAI,KAAK,CAAC,GAAIM,QAAQ,CAAC,CAAC,CAAC,GAAGA,QAAQ;EAEhD;AACJ;;AAEA;AACA;AACA;AACA;AACA,OAAO,MAAMsD,gBAAgB,SAASzE,QAAQ,CAAC;EAC3C;AACJ;AACA;AACA;AACA;AACA;AACA;EACI,MAAMM,KAAKA,CAACC,KAAK,EAET;IAAA,IAFW;MACfM,IAAI,GAAG;IACX,CAAC,GAAAC,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,CAAC,CAAC;IACF;IACA,IAAI,CAACN,MAAM,EAAEG,OAAO,CAAC,GAAG,MAAM,KAAK,CAACL,KAAK,CAACC,KAAK,CAAC;;IAEhD;IACA;;IAEA;;IAEA,IAAIJ,SAAS,GAAG,IAAI,CAACA,SAAS;IAE9B,IAAIgB,QAAQ,GAAG,EAAE;IAEjB,KAAK,IAAIY,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGvB,MAAM,CAAC0B,SAAS,CAACF,IAAI,CAAC,CAAC,CAAC,EAAE,EAAED,CAAC,EAAE;MAC/C,IAAIE,GAAG,GAAGzB,MAAM,CAAC0B,SAAS,CAACH,CAAC,CAAC;MAC7B,IAAI2C,gBAAgB,GAAGzC,GAAG,CAACsB,OAAO,CAAC,IAAI,CAACpD,SAAS,CAACwE,aAAa,CAAC;MAEhE,IAAID,gBAAgB,KAAK,CAAC,CAAC,EAAE;QACzB,MAAME,KAAK,CAAE,eAAczE,SAAS,CAAC0E,UAAW,sBAAqB,CAAC;MAC1E;MACA,IAAIxD,MAAM,GAAGV,OAAO,CAACU,MAAM,CAACU,CAAC,CAAC;MAC9B,IAAI+C,UAAU,GAAGzD,MAAM,CAACqD,gBAAgB,CAAC;MAEzC,IAAIpD,MAAM,GAAGnC,WAAW,CAACF,OAAO,CAAC6F,UAAU,CAACvD,IAAI,CAAC,EAAEV,IAAI,CAAC;MAExDM,QAAQ,CAACQ,IAAI,CAACL,MAAM,CAACzB,GAAG,CAACC,CAAC,IAAI;QAC1B,IAAIiF,QAAQ,GAAG,CAAC,GAAG9C,GAAG,CAAC;QACvB8C,QAAQ,CAACL,gBAAgB,CAAC,GAAG5E,CAAC,CAAC,CAAC,CAAC;QAEjC,OAAO;UACH4B,KAAK,EAAE5B,CAAC,CAAC,CAAC,CAAC;UACXkF,KAAK,EAAElF,CAAC,CAAC,CAAC,CAAC;UACXmF,SAAS,EAAE9E,SAAS,CAACC,KAAK,CAAC8E,KAAK,CAACpF,CAAC,CAAC,CAAC,CAAC,CAAC;UACtCiF,QAAQ,EAAE5E,SAAS,CAACuC,MAAM,CAACqC,QAAQ,EAAE;YAAEnC,mBAAmB,EAAE;UAAK,CAAC;QACtE,CAAC;MACL,CAAC,CAAC,CAAC;IACP;IACA,OAAOnD,KAAK,CAACC,OAAO,CAACa,KAAK,CAAC,GAAGY,QAAQ,GAAGA,QAAQ,CAAC,CAAC,CAAC;EACxD;AACJ;;AAEA;AACA;AACA;AACA;AACA,OAAO,MAAMgE,2BAA2B,SAASnF,QAAQ,CAAC;EACtDoF,IAAI,GAAG,IAAI;;EAEX;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACI,MAAM9E,KAAKA,CAACC,KAAK,EAAwB;IAAA,IAAtB8E,eAAe,GAAAvE,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,CAAC,CAAC;IACnC,IAAI,CAACrB,KAAK,CAACC,OAAO,CAACa,KAAK,CAAC,EAAE;MACvBA,KAAK,GAAG,CAACA,KAAK,CAAC;IACnB;;IAEA;IACA,IAAI,IAAI,CAACH,KAAK,CAACc,MAAM,CAACoE,MAAM,EAAE;MAC1B/E,KAAK,GAAGA,KAAK,CAACV,GAAG,CAACC,CAAC,IAAI,IAAI,CAACM,KAAK,CAACc,MAAM,CAACoE,MAAM,GAAGxF,CAAC,CAAC;IACxD;;IAEA;IACA,IAAIyF,oBAAoB,GAAG,IAAI,CAACnF,KAAK,CAACc,MAAM,CAACqE,oBAAoB;IACjE,IAAIA,oBAAoB,IAAIA,oBAAoB,CAAC,IAAI,CAACrF,IAAI,CAAC,EAAE;MACzD;MACA,IAAIqF,oBAAoB,CAAC,IAAI,CAACrF,IAAI,CAAC,CAACoF,MAAM,EAAE;QACxC/E,KAAK,GAAGA,KAAK,CAACV,GAAG,CAACC,CAAC,IAAIyF,oBAAoB,CAAC,IAAI,CAACrF,IAAI,CAAC,CAACoF,MAAM,GAAGxF,CAAC,CAAC;MACtE;;MAEA;IACJ;;IAEA,IAAI0F,iBAAiB,GAAG;MACpB/E,OAAO,EAAE,IAAI;MACbC,UAAU,EAAE;IAChB,CAAC;IACD,IAAIwB,SAAS;IACb,IAAI,IAAI,YAAYuD,mBAAmB,IAAI,2BAA2B,IAAI,IAAI,CAACtF,SAAS,EAAE;MACtF;MACA;MACA;MACA+B,SAAS,GAAG,IAAI,CAAC/B,SAAS,CAACuF,yBAAyB,CAACnF,KAAK,EAAEiF,iBAAiB,EAAEH,eAAe,CAAC,CAACnD,SAAS;IAE7G,CAAC,MAAM;MACHA,SAAS,GAAG,IAAI,CAAC/B,SAAS,CAACI,KAAK,EAAEiF,iBAAiB,CAAC,CAACtD,SAAS;IAClE;IAEA,IAAIyD,cAAc,GAAG,MAAM,IAAI,CAACvF,KAAK,CAACwF,QAAQ,CAAC1D,SAAS,EAAEmD,eAAe,CAAC;;IAE1E;AACR;AACA;IACQ,IAAIlE,QAAQ,GAAG,IAAI,CAAChB,SAAS,CAAC0F,YAAY,CAACF,cAAc,EAAE;MACvD/C,mBAAmB,EAAE;IACzB,CAAC,CAAC;IACF,IAAI,IAAI,CAACwC,IAAI,KAAK,IAAI,EAAE;MACpBjE,QAAQ,GAAGA,QAAQ,CAACtB,GAAG,CAACiG,IAAI,IAAI;QAC5B,OAAQ,IAAI,CAACV,IAAI,KAAK,IAAI,GAAIU,IAAI,GAAG;UAAE,CAAC,IAAI,CAACV,IAAI,GAAGU;QAAK,CAAC;MAC9D,CAAC,CAAC;IACN;IACA,OAAO3E,QAAQ;EACnB;AACJ;;AAGA;AACA;AACA;AACA;AACA,OAAO,MAAM4E,qBAAqB,SAASZ,2BAA2B,CAAC;EACnEC,IAAI,GAAG,cAAc;AACzB;;AAEA;AACA;AACA;AACA;AACA,OAAO,MAAMK,mBAAmB,SAASN,2BAA2B,CAAC;EACjEC,IAAI,GAAG,kBAAkB;AAC7B;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMY,sBAAsB,SAAShG,QAAQ,CAAC;EACjD;AACJ;AACA;AACA;AACA;AACA;EACI,MAAMM,KAAKA,CAACC,KAAK,EAAwB;IAAA,IAAtB8E,eAAe,GAAAvE,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,CAAC,CAAC;IACnC,IAAImF,WAAW,GAAG,OAAO1F,KAAK,KAAK,QAAQ,IAAIA,KAAK,YAAY2F,MAAM;IACtE,IAAID,WAAW,EAAE;MACb1F,KAAK,GAAG,CAACA,KAAK,CAAC;IACnB;IAEA,IAAI,CAACJ,SAAS,CAACgG,YAAY,GAAG,MAAM;IACpC,IAAI3F,MAAM,GAAG,IAAI,CAACL,SAAS,CAACI,KAAK,EAAE;MAC/BE,OAAO,EAAE,IAAI;MACbC,UAAU,EAAE;IAChB,CAAC,CAAC;IAEF,IAAIwB,SAAS,GAAG1B,MAAM,CAAC0B,SAAS;IAChC,IAAIkE,cAAc,GAAG5F,MAAM,CAAC4F,cAAc;IAE1C,IAAIT,cAAc,GAAG,MAAM,IAAI,CAACvF,KAAK,CAACwF,QAAQ,CAAC1D,SAAS,EAAEmD,eAAe,EAAE,IAAI,EAAE;MAC7EgB,qBAAqB,EAAED;IAC3B,CAAC,CAAC;IAEF,MAAME,YAAY,GAAG/F,KAAK,CAACV,GAAG,CAACC,CAAC,IAAIA,CAAC,CAACyG,IAAI,CAAC,CAAC,CAAC;IAC7C,MAAMC,OAAO,GAAG,IAAI,CAACrG,SAAS,CAAC0F,YAAY,CAACF,cAAc,EAAE;MACxD/C,mBAAmB,EAAE;IACzB,CAAC,CAAC;IACF,MAAMzB,QAAQ,GAAG1B,KAAK,CAACiE,IAAI,CAAC;MAAE3C,MAAM,EAAER,KAAK,CAACQ;IAAO,CAAC,EAAE0F,CAAC,IAAI,EAAE,CAAC;IAC9D,KAAK,IAAI1E,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGyE,OAAO,CAACzF,MAAM,EAAE,EAAEgB,CAAC,EAAE;MACrC,MAAM2E,SAAS,GAAGtC,IAAI,CAACuC,KAAK,CAAC5E,CAAC,GAAG4D,cAAc,CAAC5E,MAAM,GAAGuF,YAAY,CAACvF,MAAM,CAAC;MAC7E,IAAI6F,SAAS,GAAGN,YAAY,CAACI,SAAS,CAAC;MAEvCvF,QAAQ,CAACuF,SAAS,CAAC,CAAC/E,IAAI,CAAC;QACrBkF,cAAc,EAAED,SAAS,GAAGJ,OAAO,CAACzE,CAAC;MACzC,CAAC,CAAC;IACN;IACA,OAAQkE,WAAW,IAAI9E,QAAQ,CAACJ,MAAM,KAAK,CAAC,GAAII,QAAQ,CAAC,CAAC,CAAC,GAAGA,QAAQ;EAC1E;AACJ;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAM2F,8BAA8B,SAAS9G,QAAQ,CAAC;EAEzD;AACJ;AACA;AACA;AACA;AACA;EACIC,WAAWA,CAACC,IAAI,EAAEC,SAAS,EAAEC,KAAK,EAAE;IAChC,KAAK,CAACF,IAAI,EAAEC,SAAS,EAAEC,KAAK,CAAC;;IAE7B;IACA,IAAI,CAAC2G,QAAQ,GAAGC,MAAM,CAACC,WAAW,CAC9BD,MAAM,CAACE,OAAO,CAAC,IAAI,CAAC9G,KAAK,CAACc,MAAM,CAAC6F,QAAQ,CAAC,CAAClH,GAAG,CAC1CsH,IAAA;MAAA,IAAC,CAAChD,CAAC,EAAEiD,CAAC,CAAC,GAAAD,IAAA;MAAA,OAAK,CAAChD,CAAC,CAACkD,WAAW,CAAC,CAAC,EAAED,CAAC,CAAC;IAAA,CACpC,CACJ,CAAC;IAED,IAAI,CAACE,aAAa,GAAG,IAAI,CAACP,QAAQ,CAAC,YAAY,CAAC;IAChD,IAAI,IAAI,CAACO,aAAa,KAAKtG,SAAS,EAAE;MAClCuG,OAAO,CAACC,IAAI,CAAC,4EAA4E,CAAC;MAC1F,IAAI,CAACF,aAAa,GAAG,CAAC;IAC1B;IAEA,IAAI,CAACG,gBAAgB,GAAG,IAAI,CAACV,QAAQ,CAAC,eAAe,CAAC;IACtD,IAAI,IAAI,CAACU,gBAAgB,KAAKzG,SAAS,EAAE;MACrCuG,OAAO,CAACC,IAAI,CAAC,kFAAkF,CAAC;MAChG,IAAI,CAACC,gBAAgB,GAAG,CAAC;IAC7B;EACJ;EACA;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACI;EACA,MAAMnH,KAAKA,CAACC,KAAK,EAAEmH,gBAAgB,EAG3B;IAAA,IAH6B;MACjCC,mBAAmB,GAAG,qBAAqB;MAC3CC,WAAW,GAAG;IAClB,CAAC,GAAA9G,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,CAAC,CAAC;IAEF,IAAIgB,SAAS,GAAGrC,KAAK,CAACC,OAAO,CAACa,KAAK,CAAC;IAEpC,IAAI,CAACuB,SAAS,EAAE;MACZvB,KAAK,GAAG,CAACA,KAAK,CAAC;IACnB;IACA,IAAI,CAACd,KAAK,CAACC,OAAO,CAACgI,gBAAgB,CAAC,EAAE;MAClCA,gBAAgB,GAAG,CAACA,gBAAgB,CAAC;IACzC;;IAEA;IACA,IAAIG,UAAU,GAAGH,gBAAgB,CAAC7H,GAAG,CACjCC,CAAC,IAAI6H,mBAAmB,CAACG,OAAO,CAAC,IAAI,EAAEhI,CAAC,CAC5C,CAAC;;IAED;IACA;IACA;IACA,IAAIiI,WAAW,GAAGH,WAAW,IAAIF,gBAAgB,CAAC3G,MAAM,KAAK,CAAC;IAE9D,IAAII,QAAQ,GAAG,EAAE;IACjB,KAAK,IAAI6G,OAAO,IAAIzH,KAAK,EAAE;MACvB,IAAI0H,cAAc,GAAG,EAAE;MAEvB,KAAK,IAAIC,UAAU,IAAIL,UAAU,EAAE;QAC/B,IAAIrH,MAAM,GAAG,IAAI,CAACL,SAAS,CAAC6H,OAAO,EAAE;UACjC7E,SAAS,EAAE+E;QACf,CAAC,CAAC;QACF,IAAIvH,OAAO,GAAG,MAAM,IAAI,CAACP,KAAK,CAACI,MAAM,CAAC;QAEtC,IAAIuH,WAAW,EAAE;UACbE,cAAc,CAACtG,IAAI,CAAC,CAChBhB,OAAO,CAACU,MAAM,CAACE,IAAI,CAAC,IAAI,CAACkG,gBAAgB,CAAC,EAC1C9G,OAAO,CAACU,MAAM,CAACE,IAAI,CAAC,IAAI,CAAC+F,aAAa,CAAC,CAC1C,CAAC;QACN,CAAC,MAAM;UACHW,cAAc,CAACtG,IAAI,CAAChB,OAAO,CAACU,MAAM,CAACE,IAAI,CAAC,IAAI,CAAC+F,aAAa,CAAC,CAAC;QAChE;MACJ;MAEA,IAAIhG,MAAM;MACV,IAAIyG,WAAW,EAAE;QACbzG,MAAM,GAAG2G,cAAc,CAACpI,GAAG,CAACC,CAAC,IAAIb,OAAO,CAACa,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;MACnD,CAAC,MAAM;QACHwB,MAAM,GAAGrC,OAAO,CAACgJ,cAAc,CAAC;MACpC;;MAEA;MACA,IAAIE,aAAa,GAAG7G,MAAM,CACrBzB,GAAG,CAAC,CAACC,CAAC,EAAEiC,CAAC,KAAK,CAACjC,CAAC,EAAEiC,CAAC,CAAC,CAAC,CACrBiC,IAAI,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAK;QACZ,OAAOA,CAAC,CAAC,CAAC,CAAC,GAAGD,CAAC,CAAC,CAAC,CAAC;MACtB,CAAC,CAAC;MAEN9C,QAAQ,CAACQ,IAAI,CAAC;QACVoD,QAAQ,EAAEiD,OAAO;QACjBI,MAAM,EAAED,aAAa,CAACtI,GAAG,CAACC,CAAC,IAAI4H,gBAAgB,CAAC5H,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QACtDwB,MAAM,EAAE6G,aAAa,CAACtI,GAAG,CAACC,CAAC,IAAIA,CAAC,CAAC,CAAC,CAAC;MACvC,CAAC,CAAC;IACN;IACA,OAAOgC,SAAS,GAAGX,QAAQ,GAAGA,QAAQ,CAAC,CAAC,CAAC;EAC7C;AACJ;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMkH,yBAAyB,SAASrI,QAAQ,CAAC;EAEpD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACI,MAAMM,KAAKA,CAACC,KAAK,EAGT;IAAA,IAHW;MACf+H,OAAO,GAAG,MAAM;MAChBC,SAAS,GAAG;IAChB,CAAC,GAAAzH,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,CAAC,CAAC;IACF,IAAI,CAACN,MAAM,EAAEG,OAAO,CAAC,GAAG,MAAM,KAAK,CAACL,KAAK,CAACC,KAAK,CAAC;;IAEhD;IACA;IACA;IACA;;IAEA,IAAIiI,MAAM,GAAG7H,OAAO,CAAC8H,iBAAiB,IAAI9H,OAAO,CAACU,MAAM;IACxD,IAAIiH,OAAO,KAAK,MAAM,EAAE;MACpB;IAAA,CACH,MAAM,IAAIA,OAAO,KAAK,MAAM,EAAE;MAC3BE,MAAM,GAAGnJ,YAAY,CAACmJ,MAAM,EAAEhI,MAAM,CAAC4F,cAAc,CAAC;IACxD,CAAC,MAAM;MACH,MAAMxB,KAAK,CAAE,mBAAkB0D,OAAQ,kBAAiB,CAAC;IAC7D;IAEA,IAAIC,SAAS,EAAE;MACXC,MAAM,GAAGA,MAAM,CAACD,SAAS,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;IACpC;IAEA,OAAOC,MAAM;EACjB;AACJ;;AAEA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAME,kCAAkC,SAAS1I,QAAQ,CAAC;EAE7D;AACJ;AACA;AACA;AACA;AACA;AACA;EACIC,WAAWA,CAACC,IAAI,EAAEC,SAAS,EAAEC,KAAK,EAAEuI,SAAS,EAAE;IAC3C,KAAK,CAACzI,IAAI,EAAEC,SAAS,EAAEC,KAAK,CAAC;IAC7B,IAAI,CAACuI,SAAS,GAAGA,SAAS;EAC9B;;EAEA;AACJ;AACA;AACA;AACA;AACA;AACA;EACI,MAAMC,WAAWA,CAACC,KAAK,EAAEC,aAAa,EAAE;IACpC,IAAIhK,QAAQ,CAAC+J,KAAK,CAAC,EAAE;MACjBA,KAAK,GAAG,MAAMzJ,UAAU,CAACyJ,KAAK,EAAEC,aAAa,CAAC;IAClD;IAEA,OAAOD,KAAK;EAChB;;EAEA;AACJ;AACA;AACA;AACA;AACA;AACA;;EAEI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACI,MAAMvI,KAAKA,CAACuI,KAAK,EAAe;IAAA,IAAbE,MAAM,GAAAjI,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,CAAC,CAAC;IAC1B,IAAIkI,iBAAiB,GAAGD,MAAM,CAACC,iBAAiB,IAAI,KAAK;IACzD,IAAIC,cAAc,GAAGF,MAAM,CAACE,cAAc,IAAI,CAAC;IAC/C,IAAIC,eAAe,GAAGH,MAAM,CAACG,eAAe,IAAI,IAAI;IACpD,IAAIC,cAAc,GAAGJ,MAAM,CAACI,cAAc,IAAI,IAAI;IAClD,IAAIC,oBAAoB,GAAGL,MAAM,CAACK,oBAAoB,IAAI,KAAK;IAE/D,IAAIC,QAAQ,GAAGrK,GAAG,CAAC+J,MAAM,EAAE,UAAU,EAAE,IAAI,CAAC;IAC5C,IAAI7I,IAAI,GAAGlB,GAAG,CAAC+J,MAAM,EAAE,MAAM,EAAE,IAAI,CAAC;IAEpC,IAAIM,QAAQ,IAAInJ,IAAI,IAAI8I,iBAAiB,EAAE;MACvC,IAAID,MAAM,CAACO,kBAAkB,EAAE;QAC3B,MAAM,IAAI1E,KAAK,CAAC,iGAAiG,CAAC;MACtH;MACA;MACA,IAAI2E,kBAAkB,GAAG,IAAI,CAACpJ,SAAS,CAACqJ,sBAAsB,CAAC;QAAEH,QAAQ;QAAEnJ,IAAI;QAAEuJ,aAAa,EAAE,CAACT;MAAkB,CAAC,CAAC;MAErH,IAAGO,kBAAkB,CAACxI,MAAM,GAAG,CAAC,EAAC;QAC7BgI,MAAM,CAACO,kBAAkB,GAAGC,kBAAkB;MAClD;IACJ;IAEA,IAAIG,MAAM,GAAG,CAACjK,KAAK,CAACC,OAAO,CAACmJ,KAAK,CAAC;IAClC,IAAIa,MAAM,EAAE;MACR;MACAb,KAAK,GAAG,CAACA,KAAK,CAAC;IACnB;IAEA,MAAMC,aAAa,GAAG,IAAI,CAACH,SAAS,CAACgB,iBAAiB,CAACzI,MAAM,CAAC4H,aAAa;IAC3E,MAAMc,cAAc,GAAG,IAAI,CAACjB,SAAS,CAACgB,iBAAiB,CAACzI,MAAM,CAAC2I,YAAY,GAAG,IAAI,CAACzJ,KAAK,CAACc,MAAM,CAAC4I,oBAAoB;IAEpH,IAAI3I,QAAQ,GAAG,EAAE;IACjB,KAAK,IAAI4I,GAAG,IAAIlB,KAAK,EAAE;MACnBkB,GAAG,GAAG,MAAM,IAAI,CAACnB,WAAW,CAACmB,GAAG,EAAEjB,aAAa,CAAC;;MAEhD;MACA,IAAIkB,MAAM,GAAG,EAAE;MACf,IAAIf,cAAc,GAAG,CAAC,EAAE;QACpB,IAAIC,eAAe,KAAK,IAAI,EAAE;UAC1BA,eAAe,GAAGD,cAAc,GAAG,CAAC;QACxC,CAAC,MAAM,IAAIA,cAAc,IAAIC,eAAe,EAAE;UAC1C,MAAMtE,KAAK,CAAC,yDAAyD,CAAC;QAC1E;;QAEA;;QAEA,MAAMqF,MAAM,GAAGnB,aAAa,GAAGG,cAAc;QAC7C,MAAMiB,MAAM,GAAGpB,aAAa,GAAGI,eAAe;QAC9C,MAAMiB,IAAI,GAAGF,MAAM,GAAG,CAAC,GAAGC,MAAM;QAChC,IAAIE,MAAM,GAAG,CAAC;;QAEd;;QAEA,OAAOA,MAAM,GAAGL,GAAG,CAAChJ,MAAM,EAAE;UACxB,IAAIsJ,MAAM,GAAGN,GAAG,CAACO,QAAQ,CAACF,MAAM,EAAEA,MAAM,GAAGH,MAAM,CAAC;UAClD,IAAIM,OAAO,GAAG,MAAM,IAAI,CAAC5B,SAAS,CAAC0B,MAAM,CAAC;UAE1C,IAAIG,OAAO,GAAGJ,MAAM,KAAK,CAAC;UAC1B,IAAIK,MAAM,GAAGL,MAAM,GAAGD,IAAI,IAAIJ,GAAG,CAAChJ,MAAM;UACxCiJ,MAAM,CAACrI,IAAI,CAAC;YACRuI,MAAM,EAAE,CACJG,MAAM,CAACtJ,MAAM,EACbyJ,OAAO,GAAG,CAAC,GAAGN,MAAM,EACpBO,MAAM,GAAG,CAAC,GAAGP,MAAM,CACtB;YACDQ,cAAc,EAAEH,OAAO,CAACG,cAAc;YACtCC,OAAO,EAAEF;UACb,CAAC,CAAC;UACFL,MAAM,IAAID,IAAI;QAClB;MAEJ,CAAC,MAAM;QACHH,MAAM,GAAG,CAAC;UACNE,MAAM,EAAE,CAACH,GAAG,CAAChJ,MAAM,EAAE,CAAC,EAAE,CAAC,CAAC;UAC1B2J,cAAc,EAAE,CAAC,MAAM,IAAI,CAAC/B,SAAS,CAACoB,GAAG,CAAC,EAAEW,cAAc;UAC1DC,OAAO,EAAE;QACb,CAAC,CAAC;MACN;;MAEA;MACA,KAAK,IAAIC,KAAK,IAAIZ,MAAM,EAAE;QACtB;QACA,IAAIzI,IAAI,GAAG,MAAM,IAAI,CAACnB,KAAK,CAACwF,QAAQ,CAACgF,KAAK,CAACF,cAAc,EAAE3B,MAAM,CAAC;;QAElE;QACA6B,KAAK,CAACzI,MAAM,GAAGZ,IAAI,CAAC,CAAC,CAAC;;QAEtB;QACAqJ,KAAK,CAACV,MAAM,GAAGU,KAAK,CAACV,MAAM,CAACrK,GAAG,CAACC,CAAC,IAAIA,CAAC,GAAGgJ,aAAa,CAAC;QAEvD,IAAIK,cAAc,KAAK,IAAI,EAAE;UACzBA,cAAc,CAACyB,KAAK,CAAC;QACzB;MACJ;;MAEA;MACA;MACA,IAAI,CAACC,SAAS,EAAEC,QAAQ,CAAC,GAAG,IAAI,CAAC3K,SAAS,CAAC4K,WAAW,CAACf,MAAM,EAAE;QAC3DJ,cAAc,EAAEA,cAAc;QAC9BZ,iBAAiB,EAAEA,iBAAiB;QACpCI,oBAAoB,EAAEA;MAC1B,CAAC,CAAC;MAEFjI,QAAQ,CAACQ,IAAI,CAAC;QAAEmE,IAAI,EAAE+E,SAAS;QAAE,GAAGC;MAAS,CAAC,CAAC;IACnD;IACA,OAAOpB,MAAM,GAAGvI,QAAQ,CAAC,CAAC,CAAC,GAAGA,QAAQ;EAC1C;AACJ;;AAEA;AACA;AACA;AACA;AACA,OAAO,MAAM6J,mBAAmB,SAAShL,QAAQ,CAAC;EAC9C;AACJ;AACA;AACA;AACA;AACA;AACA;EACIC,WAAWA,CAACC,IAAI,EAAEC,SAAS,EAAEC,KAAK,EAAEuI,SAAS,EAAE;IAC3C,KAAK,CAACzI,IAAI,EAAEC,SAAS,EAAEC,KAAK,CAAC;IAC7B,IAAI,CAACuI,SAAS,GAAGA,SAAS;EAC9B;;EAEA;AACJ;AACA;AACA;AACA;AACA;EACI,MAAMrI,KAAKA,CAACd,MAAM,EAAwB;IAAA,IAAtB6F,eAAe,GAAAvE,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,CAAC,CAAC;IACpC,IAAIgB,SAAS,GAAGrC,KAAK,CAACC,OAAO,CAACF,MAAM,CAAC;IAErCA,MAAM,GAAG,MAAMD,aAAa,CAACC,MAAM,CAAC;IAEpC,IAAI;MAAEyL;IAAa,CAAC,GAAG,MAAM,IAAI,CAACtC,SAAS,CAACnJ,MAAM,CAAC;IAEnD,IAAI2B,QAAQ,GAAG,EAAE;IACjB,KAAK,IAAIC,KAAK,IAAI6J,YAAY,EAAE;MAC5B7J,KAAK,CAACY,IAAI,GAAG,CAAC,CAAC,EAAE,GAAGZ,KAAK,CAACY,IAAI,CAAC;MAC/B,IAAIoB,MAAM,GAAG,MAAM,IAAI,CAAChD,KAAK,CAACwF,QAAQ,CAACxE,KAAK,EAAEiE,eAAe,CAAC;MAC9D,IAAImB,OAAO,GAAG,IAAI,CAACrG,SAAS,CAAC0F,YAAY,CAACzC,MAAM,EAAE;QAC9CR,mBAAmB,EAAE;MACzB,CAAC,CAAC,CAAC/C,GAAG,CAACC,CAAC,IAAI;QACR,OAAO;UAAE+G,cAAc,EAAE/G,CAAC,CAACyG,IAAI,CAAC;QAAE,CAAC;MACvC,CAAC,CAAC;MACFpF,QAAQ,CAACQ,IAAI,CAAC6E,OAAO,CAAC;IAC1B;IAEA,OAAO1E,SAAS,GAAGX,QAAQ,GAAGA,QAAQ,CAAC,CAAC,CAAC;EAC7C;AACJ;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAM+J,2BAA2B,SAASlL,QAAQ,CAAC;EACtD;AACJ;AACA;AACA;AACA;AACA;EACIC,WAAWA,CAACC,IAAI,EAAEE,KAAK,EAAEuI,SAAS,EAAE;IAChC,KAAK,CAACzI,IAAI,EAAE,IAAI,EAAEE,KAAK,CAAC,CAAC,CAAC;IAC1B,IAAI,CAACuI,SAAS,GAAGA,SAAS;EAC9B;;EAEA;AACJ;AACA;AACA;AACA;AACA;AACA;EACI,MAAMrI,KAAKA,CAACd,MAAM,EAEV;IAAA,IAFY;MAChBqB,IAAI,GAAG;IACX,CAAC,GAAAC,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,CAAC,CAAC;IACF,IAAIgB,SAAS,GAAGrC,KAAK,CAACC,OAAO,CAACF,MAAM,CAAC;IACrCA,MAAM,GAAG,MAAMD,aAAa,CAACC,MAAM,CAAC;IAEpC,IAAI;MAAEyL;IAAa,CAAC,GAAG,MAAM,IAAI,CAACtC,SAAS,CAACnJ,MAAM,CAAC;IACnD,IAAI4D,MAAM,GAAG,MAAM,IAAI,CAAChD,KAAK,CAAC;MAAE6K;IAAa,CAAC,CAAC;IAE/C,IAAIhK,QAAQ,GAAG,IAAI,CAACb,KAAK,CAACc,MAAM,CAACD,QAAQ;IACzC,IAAIE,QAAQ,GAAG,EAAE;IACjB,KAAK,IAAIC,KAAK,IAAIgC,MAAM,CAAC/B,MAAM,EAAE;MAC7B,IAAIC,MAAM,GAAGnC,WAAW,CAACF,OAAO,CAACmC,KAAK,CAACG,IAAI,CAAC,EAAEV,IAAI,CAAC;MAEnD,IAAIW,IAAI,GAAGF,MAAM,CAACzB,GAAG,CAAC,UAAUC,CAAC,EAAE;QAC/B,OAAO;UACH2B,KAAK,EAAER,QAAQ,CAACnB,CAAC,CAAC,CAAC,CAAC,CAAC;UACrB4B,KAAK,EAAE5B,CAAC,CAAC,CAAC;QACd,CAAC;MACL,CAAC,CAAC;MACF,IAAIe,IAAI,KAAK,CAAC,EAAE;QACZM,QAAQ,CAACQ,IAAI,CAAC,GAAGH,IAAI,CAAC;MAC1B,CAAC,MAAM;QACHL,QAAQ,CAACQ,IAAI,CAACH,IAAI,CAAC;MACvB;IACJ;IAEA,OAAOM,SAAS,IAAIjB,IAAI,KAAK,CAAC,GAAGM,QAAQ,GAAGA,QAAQ,CAAC,CAAC,CAAC;EAC3D;AAEJ;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMgK,yBAAyB,SAASnL,QAAQ,CAAC;EACpD;AACJ;AACA;AACA;AACA;AACA;EACIC,WAAWA,CAACC,IAAI,EAAEE,KAAK,EAAEuI,SAAS,EAAE;IAChC,KAAK,CAACzI,IAAI,EAAE,IAAI,EAAEE,KAAK,CAAC,CAAC,CAAC;IAC1B,IAAI,CAACuI,SAAS,GAAGA,SAAS;IAE1B,IAAI,CAACyC,gBAAgB,GAAG;MACpB;MACAC,QAAQ,EAAE,oCAAoC;MAC9CC,QAAQ,EAAE,oCAAoC;MAC9CC,QAAQ,EAAE;IACd,CAAC;EACL;;EAEA;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACI,MAAMjL,KAAKA,CAACd,MAAM,EAOV;IAAA,IAPY;MAChBgM,SAAS,GAAG,GAAG;MACfC,cAAc,GAAG,GAAG;MACpBC,2BAA2B,GAAG,GAAG;MACjCC,iBAAiB,GAAG,IAAI;MACxBC,YAAY,GAAG,IAAI;MACnBC,OAAO,GAAG,IAAI,CAAE;IACpB,CAAC,GAAA/K,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,CAAC,CAAC;IACF,IAAIgB,SAAS,GAAGrC,KAAK,CAACC,OAAO,CAACF,MAAM,CAAC;IAErC,IAAIsC,SAAS,IAAItC,MAAM,CAACuB,MAAM,KAAK,CAAC,EAAE;MAClC,MAAM6D,KAAK,CAAC,wEAAwE,CAAC;IACzF;IAEApF,MAAM,GAAG,MAAMD,aAAa,CAACC,MAAM,CAAC;IACpC,IAAIsM,UAAU,GAAGtM,MAAM,CAACK,GAAG,CAACC,CAAC,IAAI,CAACA,CAAC,CAACiM,MAAM,EAAEjM,CAAC,CAACkM,KAAK,CAAC,CAAC;IAErD,IAAI;MAAEf,YAAY;MAAEgB;IAAW,CAAC,GAAG,MAAM,IAAI,CAACtD,SAAS,CAACnJ,MAAM,CAAC;IAC/D,IAAI4D,MAAM,GAAG,MAAM,IAAI,CAAChD,KAAK,CAAC;MAAE6K,YAAY;MAAEgB;IAAW,CAAC,CAAC;IAE3D,IAAIC,EAAE,GAAG,IAAI;IACb,IAAIL,OAAO,KAAK,IAAI,EAAE;MAClBK,EAAE,GAAG,IAAI,CAACd,gBAAgB,CAACS,OAAO,CAAC;IACvC,CAAC,MAAM;MACH,KAAK,IAAI,CAAC3L,IAAI,EAAEiM,IAAI,CAAC,IAAInF,MAAM,CAACE,OAAO,CAAC,IAAI,CAACkE,gBAAgB,CAAC,EAAE;QAC5D,IAAIe,IAAI,IAAI,IAAI,CAACxD,SAAS,CAACgB,iBAAiB,EAAE;UAC1CuC,EAAE,GAAG,IAAI,CAACvD,SAAS,CAACgB,iBAAiB,CAACwC,IAAI,CAAC,CAACC,IAAI,CAAC,IAAI,CAACzD,SAAS,CAACgB,iBAAiB,CAAC;UAClFkC,OAAO,GAAG3L,IAAI;UACd;QACJ;MACJ;IACJ;;IAEA;IACA,IAAImM,UAAU,GAAG,EAAE;IAEnB,IAAIR,OAAO,KAAK,UAAU,IAAIA,OAAO,KAAK,UAAU,EAAE;MAElD,IAAIS,SAAS,GAAGJ,EAAE,CACd9I,MAAM,EACNoI,SAAS,EACTC,cAAc,EACdC,2BAA2B,EAC3BC,iBAAiB,EACjBC,YAAY,IAAIE,UAAU,CAAE;MAChC,CAAC,CAAC,CAAC,CAAC;MAEJ,IAAIS,YAAY,GAAGD,SAAS,CAACC,YAAY;MACzC,IAAItL,QAAQ,GAAG,IAAI,CAACb,KAAK,CAACc,MAAM,CAACD,QAAQ;MAEzC,KAAK,IAAIuL,OAAO,IAAIF,SAAS,CAACG,aAAa,EAAE;QACzC,IAAIC,QAAQ,GAAG,IAAIC,iBAAiB,CAACJ,YAAY,CAAChL,IAAI,CAACR,MAAM,CAAC;QAC9D,KAAK,IAAIgB,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGwK,YAAY,CAAChL,IAAI,CAACR,MAAM,EAAE,EAAEgB,CAAC,EAAE;UAC/C,IAAIwK,YAAY,CAAChL,IAAI,CAACQ,CAAC,CAAC,KAAKyK,OAAO,CAACI,EAAE,EAAE;YACrCF,QAAQ,CAAC3K,CAAC,CAAC,GAAG,GAAG;UACrB;QACJ;QAEA,IAAI8K,IAAI,GAAG,IAAIvN,QAAQ,CAACoN,QAAQ,EAAEH,YAAY,CAACvK,IAAI,CAAC,CAAC,CAAC,EAAEuK,YAAY,CAACvK,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC;QAEhFqK,UAAU,CAAC1K,IAAI,CAAC;UACZD,KAAK,EAAE8K,OAAO,CAAC9K,KAAK;UACpBD,KAAK,EAAER,QAAQ,CAACuL,OAAO,CAACM,QAAQ,CAAC;UACjCD,IAAI,EAAEA;QACV,CAAC,CAAC;MACN;IAEJ,CAAC,MAAM,IAAIhB,OAAO,KAAK,UAAU,EAAE;MAC/B,MAAMjH,KAAK,CAAE,0CAAyC,CAAC;IAE3D,CAAC,MAAM;MACH,MAAMA,KAAK,CAAE,WAAUiH,OAAQ,iBAAgB,CAAC;IACpD;IAEA,OAAOQ,UAAU;EACrB;AACJ;;AAGA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMU,mCAAmC,SAAS/M,QAAQ,CAAC;EAE9D;AACJ;AACA;AACA;AACA;AACA;AACA;EACIC,WAAWA,CAACC,IAAI,EAAEC,SAAS,EAAEC,KAAK,EAAEuI,SAAS,EAAE;IAC3C,KAAK,CAACzI,IAAI,EAAEC,SAAS,EAAEC,KAAK,CAAC;IAC7B,IAAI,CAACuI,SAAS,GAAGA,SAAS;EAC9B;;EAEA;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;EACI;EACA,MAAMrI,KAAKA,CAACd,MAAM,EAAEkI,gBAAgB,EAE5B;IAAA,IAF8B;MAClCC,mBAAmB,GAAG;IAC1B,CAAC,GAAA7G,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,CAAC,CAAC;IACF,IAAIgB,SAAS,GAAGrC,KAAK,CAACC,OAAO,CAACF,MAAM,CAAC;IACrCA,MAAM,GAAG,MAAMD,aAAa,CAACC,MAAM,CAAC;;IAEpC;IACA,IAAIe,KAAK,GAAGmH,gBAAgB,CAAC7H,GAAG,CAC5BC,CAAC,IAAI6H,mBAAmB,CAACG,OAAO,CAAC,IAAI,EAAEhI,CAAC,CAC5C,CAAC;;IAED;IACA,IAAIkN,WAAW,GAAG,IAAI,CAAC7M,SAAS,CAACI,KAAK,EAAE;MACpCE,OAAO,EAAE,IAAI;MACbC,UAAU,EAAE;IAChB,CAAC,CAAC;;IAEF;IACA,IAAI;MAAEuK;IAAa,CAAC,GAAG,MAAM,IAAI,CAACtC,SAAS,CAACnJ,MAAM,CAAC;;IAEnD;IACA,IAAI4D,MAAM,GAAG,MAAM,IAAI,CAAChD,KAAK,CAAC;MAAE,GAAG4M,WAAW;MAAE/B;IAAa,CAAC,CAAC;;IAE/D;IACA,IAAI9J,QAAQ,GAAG,EAAE;IACjB,KAAK,IAAIC,KAAK,IAAIgC,MAAM,CAAC6J,gBAAgB,EAAE;MACvC;MACA,IAAIC,KAAK,GAAGjO,OAAO,CAACmC,KAAK,CAACG,IAAI,CAAC;MAE/BJ,QAAQ,CAACQ,IAAI,CAAC,CAAC,GAAGuL,KAAK,CAAC,CAACrN,GAAG,CAAC,CAACC,CAAC,EAAEiC,CAAC,KAAK;QACnC,OAAO;UACHL,KAAK,EAAE5B,CAAC;UACR2B,KAAK,EAAEiG,gBAAgB,CAAC3F,CAAC;QAC7B,CAAC;MACL,CAAC,CAAC,CAAC;IACP;IAEA,OAAOD,SAAS,GAAGX,QAAQ,GAAGA,QAAQ,CAAC,CAAC,CAAC;EAC7C;AACJ;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMgM,uBAAuB,SAASnN,QAAQ,CAAC;EAClD;AACJ;AACA;AACA;AACA;AACA;EACIC,WAAWA,CAACC,IAAI,EAAEE,KAAK,EAAEuI,SAAS,EAAE;IAChC,KAAK,CAACzI,IAAI,EAAE,IAAI,EAAEE,KAAK,CAAC,CAAC,CAAC;IAC1B,IAAI,CAACuI,SAAS,GAAGA,SAAS;EAC9B;;EAEA;AACJ;AACA;AACA;AACA;AACA;AACA;EACI,MAAMrI,KAAKA,CAACd,MAAM,EAGV;IAAA,IAHY;MAChBgM,SAAS,GAAG,GAAG;MACf4B,UAAU,GAAG;IACjB,CAAC,GAAAtM,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,CAAC,CAAC;IACF,IAAIgB,SAAS,GAAGrC,KAAK,CAACC,OAAO,CAACF,MAAM,CAAC;IAErC,IAAIsC,SAAS,IAAItC,MAAM,CAACuB,MAAM,KAAK,CAAC,EAAE;MAClC,MAAM6D,KAAK,CAAC,sEAAsE,CAAC;IACvF;IACApF,MAAM,GAAG,MAAMD,aAAa,CAACC,MAAM,CAAC;IAEpC,IAAIsM,UAAU,GAAGsB,UAAU,GAAG,IAAI,GAAG5N,MAAM,CAACK,GAAG,CAACC,CAAC,IAAI,CAACA,CAAC,CAACiM,MAAM,EAAEjM,CAAC,CAACkM,KAAK,CAAC,CAAC;IAEzE,IAAI;MAAEf,YAAY;MAAEgB;IAAW,CAAC,GAAG,MAAM,IAAI,CAACtD,SAAS,CAACnJ,MAAM,CAAC;IAC/D,IAAI4D,MAAM,GAAG,MAAM,IAAI,CAAChD,KAAK,CAAC;MAAE6K,YAAY;MAAEgB;IAAW,CAAC,CAAC;;IAE3D;IACA,IAAIK,SAAS,GAAG,IAAI,CAAC3D,SAAS,CAACgB,iBAAiB,CAAC0D,6BAA6B,CAACjK,MAAM,EAAEoI,SAAS,EAAEM,UAAU,CAAC;;IAE7G;IACA,IAAI7K,QAAQ,GAAG,IAAI,CAACb,KAAK,CAACc,MAAM,CAACD,QAAQ;IACzCqL,SAAS,CAACgB,OAAO,CAACxN,CAAC,IAAIA,CAAC,CAACsI,MAAM,GAAGtI,CAAC,CAACyN,OAAO,CAAC1N,GAAG,CAAC2N,CAAC,IAAIvM,QAAQ,CAACuM,CAAC,CAAC,CAAC,CAAC;IAElE,OAAO1L,SAAS,GAAGwK,SAAS,GAAGA,SAAS,CAAC,CAAC,CAAC;EAC/C;AACJ;AAEA,MAAMmB,eAAe,GAAG;EACpB,qBAAqB,EAAE;IACnB,WAAW,EAAE5P,aAAa;IAC1B,UAAU,EAAE+C,0BAA0B;IACtC,OAAO,EAAE5C,kCAAkC;IAC3C,SAAS,EAAE;MACP;MACA;MACA,OAAO,EAAE;IACb,CAAC;IACD,MAAM,EAAE;EACZ,CAAC;EACD,sBAAsB,EAAE;IACpB,WAAW,EAAEH,aAAa;IAC1B,UAAU,EAAE+D,2BAA2B;IACvC,OAAO,EAAE3D,+BAA+B;IACxC,SAAS,EAAE;MACP;MACA;MACA,OAAO,EAAE;IACb,CAAC;IACD,MAAM,EAAE;EACZ,CAAC;EACD,oBAAoB,EAAE;IAClB,WAAW,EAAEJ,aAAa;IAC1B,UAAU,EAAEmF,yBAAyB;IACrC,OAAO,EAAE9E,6BAA6B;IACtC,SAAS,EAAE;MACP;MACA;MACA,OAAO,EAAE;IACb,CAAC;IACD,MAAM,EAAE;EACZ,CAAC;EAED,WAAW,EAAE;IACT,WAAW,EAAEL,aAAa;IAC1B,UAAU,EAAE4G,gBAAgB;IAC5B,OAAO,EAAEtG,oBAAoB;IAC7B,SAAS,EAAE;MACP;MACA;MACA,OAAO,EAAE;IACb,CAAC;IACD,MAAM,EAAE;EACZ,CAAC;EACD,eAAe,EAAE;IACb,WAAW,EAAEN,aAAa;IAC1B,UAAU,EAAEkI,qBAAqB;IACjC,OAAO,EAAE3H,qBAAqB;IAC9B,SAAS,EAAE;MACP;MACA;MACA,OAAO,EAAE;IACb,CAAC;IACD,MAAM,EAAE;EACZ,CAAC;EACD,aAAa,EAAE;IACX,WAAW,EAAEP,aAAa;IAC1B,UAAU,EAAE4H,mBAAmB;IAC/B,OAAO,EAAErH,qBAAqB;IAC9B,SAAS,EAAE;MACP;MACA;MACA,OAAO,EAAE;IACb,CAAC;IACD,MAAM,EAAE;EACZ,CAAC;EACD,sBAAsB,EAAE;IACpB,WAAW,EAAEP,aAAa;IAC1B,UAAU,EAAEsH,2BAA2B;IACvC,OAAO,EAAE/G,qBAAqB;IAC9B,SAAS,EAAE;MACP;MACA;MACA,OAAO,EAAE;IACb,CAAC;IACD,MAAM,EAAE;EACZ,CAAC;EACD,iBAAiB,EAAE;IACf,WAAW,EAAEP,aAAa;IAC1B,UAAU,EAAEmI,sBAAsB;IAClC,OAAO,EAAE3H,oBAAoB;IAC7B,SAAS,EAAE;MACP;MACA;MACA,OAAO,EAAE;IACb,CAAC;IACD,MAAM,EAAE;EACZ,CAAC;EACD,0BAA0B,EAAE;IACxB,WAAW,EAAER,aAAa;IAC1B,UAAU,EAAEiJ,8BAA8B;IAC1C,OAAO,EAAE9I,kCAAkC;IAC3C,SAAS,EAAE;MACP;MACA;MACA,OAAO,EAAE;IACb,CAAC;IACD,MAAM,EAAE;EACZ,CAAC;EAED,8BAA8B,EAAE;IAC5B,WAAW,EAAEH,aAAa;IAC1B,UAAU,EAAE6K,kCAAkC;IAC9C,OAAO,EAAEtK,qBAAqB;IAC9B,WAAW,EAAEO,aAAa;IAC1B,SAAS,EAAE;MACP;MACA;MACA,OAAO,EAAE;IACb,CAAC;IACD,MAAM,EAAE;EACZ,CAAC;EAED,eAAe,EAAE;IACb,WAAW,EAAEd,aAAa;IAC1B,UAAU,EAAEmN,mBAAmB;IAC/B,OAAO,EAAE1M,sBAAsB;IAC/B,WAAW,EAAEK,aAAa;IAC1B,SAAS,EAAE;MACP;MACA;MACA,OAAO,EAAE;IACb,CAAC;IACD,MAAM,EAAE;EACZ,CAAC;EAED,sBAAsB,EAAE;IACpB;IACA,UAAU,EAAEuM,2BAA2B;IACvC,OAAO,EAAE3M,+BAA+B;IACxC,WAAW,EAAEI,aAAa;IAC1B,SAAS,EAAE;MACP;MACA;MACA,OAAO,EAAE;IACb,CAAC;IACD,MAAM,EAAE;EACZ,CAAC;EAED,oBAAoB,EAAE;IAClB;IACA,UAAU,EAAEwM,yBAAyB;IACrC,OAAO,EAAE3M,6BAA6B;IACtC,WAAW,EAAEG,aAAa;IAC1B,SAAS,EAAE;MACP;MACA;MACA,OAAO,EAAE;IACb,CAAC;IACD,MAAM,EAAE;EACZ,CAAC;EAED,gCAAgC,EAAE;IAC9B;IACA,WAAW,EAAEd,aAAa;IAC1B,UAAU,EAAEkP,mCAAmC;IAC/C,OAAO,EAAEhP,SAAS;IAClB,WAAW,EAAEY,aAAa;IAC1B,SAAS,EAAE;MACP;MACA;MACA,OAAO,EAAE;IACb,CAAC;IACD,MAAM,EAAE;EACZ,CAAC;EAED,kBAAkB,EAAE;IAChB;IACA,UAAU,EAAEwO,uBAAuB;IACnC,OAAO,EAAE1O,2BAA2B;IACpC,WAAW,EAAEE,aAAa;IAC1B,SAAS,EAAE;MACP;MACA;MACA,OAAO,EAAE;IACb,CAAC;IACD,MAAM,EAAE;EACZ,CAAC;EAED;EACA,oBAAoB,EAAE;IAClB,WAAW,EAAEd,aAAa;IAC1B,UAAU,EAAEwK,yBAAyB;IACrC,OAAO,EAAEtK,SAAS;IAClB,SAAS,EAAE;MACP;MACA;MACA,OAAO,EAAE;IACb,CAAC;IACD,MAAM,EAAE;EACZ;AACJ,CAAC;AAGD,MAAM2P,YAAY,GAAG;EACjB,oBAAoB,EAAE,qBAAqB;EAC3C,KAAK,EAAE,sBAAsB;EAC7B,KAAK,EAAE,2BAA2B;EAClC,KAAK,EAAE,8BAA8B;EAErC;EACA,YAAY,EAAE;AAClB,CAAC;;AAED;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,eAAeC,QAAQA,CAC1BzN,IAAI,EAUN;EAAA,IATEE,KAAK,GAAAU,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,IAAI;EAAA,IACZ;IACI8M,SAAS,GAAG,IAAI;IAChBC,iBAAiB,GAAG,IAAI;IACxB3M,MAAM,GAAG,IAAI;IACb4M,SAAS,GAAG,IAAI;IAChBC,gBAAgB,GAAG,KAAK;IACxBC,QAAQ,GAAG;EACf,CAAC,GAAAlN,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,CAAC,CAAC;EAEN;;EAEA;EACAZ,IAAI,GAAGwN,YAAY,CAACxN,IAAI,CAAC,IAAIA,IAAI;;EAEjC;EACA,IAAI+N,YAAY,GAAGR,eAAe,CAACvN,IAAI,CAACgO,KAAK,CAAC,GAAG,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;EACzD,IAAI,CAACD,YAAY,EAAE;IACf,MAAMrJ,KAAK,CAAE,yBAAwB1E,IAAK,qBAAoB8G,MAAM,CAACmH,IAAI,CAACV,eAAe,CAAE,GAAE,CAAC;EAClG;;EAEA;EACA,IAAI,CAACrN,KAAK,EAAE;IACRA,KAAK,GAAG6N,YAAY,CAACG,OAAO,CAAChO,KAAK;IAClCmH,OAAO,CAAC8G,GAAG,CAAE,6CAA4CjO,KAAM,IAAG,CAAC;EACvE;EAEA,IAAIkO,cAAc,GAAGL,YAAY,CAAC9N,SAAS;EAC3C,IAAIoO,UAAU,GAAGN,YAAY,CAAC7N,KAAK;EACnC,IAAIoO,aAAa,GAAGP,YAAY,CAACN,QAAQ;EACzC,IAAIc,cAAc,GAAGR,YAAY,CAACtF,SAAS;EAE3C,IAAI+F,QAAQ,GAAG,EAAE;EAEjB,IAAIC,iBAAiB,GAAG;IACpBf,SAAS;IACTC,iBAAiB;IACjB3M,MAAM;IACN4M,SAAS;IACTC,gBAAgB;IAChBC;EACJ,CAAC;EACD,IAAIM,cAAc,EAAE;IAChBI,QAAQ,CAAC/M,IAAI,CACT2M,cAAc,CAACM,eAAe,CAACxO,KAAK,EAAEuO,iBAAiB,CAC3D,CAAC;EACL;EACA,IAAIJ,UAAU,EAAE;IACZG,QAAQ,CAAC/M,IAAI,CACT4M,UAAU,CAACK,eAAe,CAACxO,KAAK,EAAEuO,iBAAiB,CACvD,CAAC;EACL;EAEA,IAAIF,cAAc,EAAE;IAChBC,QAAQ,CAAC/M,IAAI,CACT8M,cAAc,CAACG,eAAe,CAACxO,KAAK,EAAEuO,iBAAiB,CAC3D,CAAC;EACL;;EAEA;EACA,IAAIE,KAAK,GAAG,MAAMlP,OAAO,CAACC,GAAG,CAAC8O,QAAQ,CAAC;EAEvC3P,gBAAgB,CAAC8O,iBAAiB,EAAE;IAChC,QAAQ,EAAE,OAAO;IACjB,MAAM,EAAE3N,IAAI;IACZ,OAAO,EAAEE;EACb,CAAC,CAAC;EAEF,OAAO,IAAIoO,aAAa,CAACtO,IAAI,EAAE,GAAG2O,KAAK,CAAC;AAE5C;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS9K,OAAOA,CAAA,EAAO;EAAA,SAAA+K,IAAA,GAAAhO,SAAA,CAAAC,MAAA,EAAHkD,CAAC,OAAAxE,KAAA,CAAAqP,IAAA,GAAA1J,IAAA,MAAAA,IAAA,GAAA0J,IAAA,EAAA1J,IAAA;IAADnB,CAAC,CAAAmB,IAAA,IAAAtE,SAAA,CAAAsE,IAAA;EAAA;EACjB;EACA;EACA,OAAOnB,CAAC,CAAC8K,MAAM,CAAC,CAAC9K,CAAC,EAAEC,CAAC,KAAKD,CAAC,CAAC+K,OAAO,CAACC,CAAC,IAAI/K,CAAC,CAACrE,GAAG,CAACqP,CAAC,IAAI,CAACD,CAAC,EAAEC,CAAC,CAAC,CAAC,CAAC,CAAC;AACjE"},"metadata":{},"sourceType":"module","externalDependencies":[]}