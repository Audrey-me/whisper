{"ast":null,"code":"/**\n * @file Processors are used to prepare non-textual inputs (e.g., image or audio) for a model.\n * \n * **Example:** Using a `WhisperProcessor` to prepare an audio input for a model.\n * ```javascript\n * import { AutoProcessor, read_audio } from '@xenova/transformers';\n *\n * let processor = await AutoProcessor.from_pretrained('openai/whisper-tiny.en');\n * let audio = await read_audio('https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac', 16000);\n * let { input_features } = await processor(audio);\n * // Tensor {\n * //   data: Float32Array(240000) [0.4752984642982483, 0.5597258806228638, 0.56434166431427, ...],\n * //   dims: [1, 80, 3000],\n * //   type: 'float32',\n * //   size: 240000,\n * // }\n * ```\n * \n * @module processors\n */\nimport { Callable, calculateDimensions } from './utils/core.js';\nimport { getModelJSON } from './utils/hub.js';\nimport { max, softmax, FFT } from './utils/maths.js';\nimport { Tensor, transpose, cat, interpolate } from './utils/tensor.js';\nimport { RawImage } from './utils/image.js';\nimport { getMelFilters } from './utils/audio.js';\n\n/**\n * Base class for feature extractors.\n *\n * @extends Callable\n */\nexport class FeatureExtractor extends Callable {\n  /**\n   * Constructs a new FeatureExtractor instance.\n   *\n   * @param {Object} config The configuration for the feature extractor.\n   */\n  constructor(config) {\n    super();\n    this.config = config;\n  }\n}\n\n/**\n * Feature extractor for Vision Transformer (ViT) models.\n *\n * @extends FeatureExtractor\n */\nexport class ImageFeatureExtractor extends FeatureExtractor {\n  /**\n   * Constructs a new ViTFeatureExtractor instance.\n   *\n   * @param {Object} config The configuration for the feature extractor.\n   * @param {number[]} config.image_mean The mean values for image normalization.\n   * @param {number[]} config.image_std The standard deviation values for image normalization.\n   * @param {boolean} config.do_rescale Whether to rescale the image pixel values to the [0,1] range.\n   * @param {number} config.rescale_factor The factor to use for rescaling the image pixel values.\n   * @param {boolean} config.do_normalize Whether to normalize the image pixel values.\n   * @param {boolean} config.do_resize Whether to resize the image.\n   * @param {number} config.resample What method to use for resampling.\n   * @param {number} config.size The size to resize the image to.\n   */\n  constructor(config) {\n    super(config);\n    this.image_mean = this.config.image_mean;\n    this.image_std = this.config.image_std;\n    this.resample = this.config.resample ?? 2; // 2 => bilinear\n    this.do_rescale = this.config.do_rescale ?? true;\n    this.rescale_factor = this.config.rescale_factor ?? 1 / 255;\n    this.do_normalize = this.config.do_normalize;\n    this.do_resize = this.config.do_resize;\n    this.size = this.config.size;\n    this.do_center_crop = this.config.do_center_crop;\n    this.crop_size = this.config.crop_size;\n    this.do_convert_rgb = this.config.do_convert_rgb ?? true;\n    this.pad_size = this.config.pad_size;\n    this.do_pad = (this.config.do_pad ?? false) && this.pad_size;\n  }\n\n  /**\n   * Preprocesses the given image.\n   *\n   * @param {RawImage} image The image to preprocess.\n   * @returns {Promise<any>} The preprocessed image as a Tensor.\n   */\n  async preprocess(image) {\n    // First, convert image to RGB if specified in config.\n    if (this.do_convert_rgb) {\n      image = image.rgb();\n    }\n    const srcWidth = image.width; // original width\n    const srcHeight = image.height; // original height\n\n    // Next, resize all images\n    if (this.do_resize) {\n      // TODO:\n      // For efficiency reasons, it might be best to merge the resize and center crop operations into one.\n\n      // `this.size` comes in many forms, so we need to handle them all here:\n      // 1. `this.size` is an integer, in which case we resize the image to be a square \n\n      let shortest_edge;\n      let longest_edge;\n\n      // Support both formats for backwards compatibility\n      if (Number.isInteger(this.size)) {\n        shortest_edge = this.size;\n        longest_edge = this.config.max_size ?? shortest_edge;\n      } else {\n        // Extract known properties from `this.size`\n        shortest_edge = this.size.shortest_edge;\n        longest_edge = this.size.longest_edge;\n      }\n\n      // If `longest_edge` and `shortest_edge` are set, maintain aspect ratio and resize to `shortest_edge`\n      // while keeping the largest dimension <= `longest_edge`\n      if (shortest_edge !== undefined || longest_edge !== undefined) {\n        // http://opensourcehacker.com/2011/12/01/calculate-aspect-ratio-conserving-resize-for-images-in-javascript/\n        // Try resize so that shortest edge is `this.shortest_edge` (target)\n        const shortResizeFactor = shortest_edge === undefined ? 1 // If `shortest_edge` is not set, don't upscale\n        : Math.max(shortest_edge / srcWidth, shortest_edge / srcHeight);\n        const newWidth = srcWidth * shortResizeFactor;\n        const newHeight = srcHeight * shortResizeFactor;\n\n        // The new width and height might be greater than `this.longest_edge`, so\n        // we downscale again to ensure the largest dimension is `this.longest_edge` \n        const longResizeFactor = longest_edge === undefined ? 1 // If `longest_edge` is not set, don't downscale\n        : Math.min(longest_edge / newWidth, longest_edge / newHeight);\n\n        // Perform resize\n        image = await image.resize(Math.floor(newWidth * longResizeFactor), Math.floor(newHeight * longResizeFactor), {\n          resample: this.resample\n        });\n      } else if (this.size.width !== undefined && this.size.height !== undefined) {\n        // If `width` and `height` are set, resize to those dimensions\n        image = await image.resize(this.size.width, this.size.height, {\n          resample: this.resample\n        });\n      } else {\n        throw new Error(`Could not resize image due to unsupported \\`this.size\\` option in config: ${JSON.stringify(this.size)}`);\n      }\n    }\n    if (this.do_center_crop) {\n      let crop_width;\n      let crop_height;\n      if (Number.isInteger(this.crop_size)) {\n        crop_width = this.crop_size;\n        crop_height = this.crop_size;\n      } else {\n        crop_width = this.crop_size.width;\n        crop_height = this.crop_size.height;\n      }\n      image = await image.center_crop(crop_width, crop_height);\n    }\n    let reshaped_input_size = [image.height, image.width];\n\n    // TODO is it okay to pad before rescaling/normalizing?\n    if (this.do_pad) {\n      let left = 0;\n      let right = this.pad_size.width - image.width;\n      let top = 0;\n      let bottom = this.pad_size.height - image.height;\n      image = await image.pad([left, right, top, bottom]);\n    }\n    const pixelData = Float32Array.from(image.data);\n    if (this.do_rescale) {\n      for (let i = 0; i < pixelData.length; ++i) {\n        pixelData[i] = this.rescale_factor * pixelData[i];\n      }\n    }\n    if (this.do_normalize) {\n      let image_mean = this.image_mean;\n      if (!Array.isArray(this.image_mean)) {\n        image_mean = new Array(image.channels).fill(image_mean);\n      }\n      let image_std = this.image_std;\n      if (!Array.isArray(this.image_std)) {\n        image_std = new Array(image.channels).fill(image_mean);\n      }\n      if (image_mean.length !== image.channels || image_std.length !== image.channels) {\n        throw new Error(`When set to arrays, the length of \\`image_mean\\` (${image_mean.length}) and \\`image_std\\` (${image_std.length}) must match the number of channels in the image (${image.channels}).`);\n      }\n      for (let i = 0; i < pixelData.length; i += image.channels) {\n        for (let j = 0; j < image.channels; ++j) {\n          pixelData[i + j] = (pixelData[i + j] - this.image_mean[j]) / this.image_std[j];\n        }\n      }\n    }\n\n    // convert to channel dimension format:\n    let imgDims = [image.height, image.width, image.channels];\n    let img = new Tensor('float32', pixelData, imgDims);\n    let transposed = transpose(img, [2, 0, 1]); // hwc -> chw\n\n    return {\n      original_size: [srcHeight, srcWidth],\n      reshaped_input_size: reshaped_input_size,\n      pixel_values: transposed\n    };\n  }\n\n  /**\n   * Calls the feature extraction process on an array of image\n   * URLs, preprocesses each image, and concatenates the resulting\n   * features into a single Tensor.\n   * @param {any} images The URL(s) of the image(s) to extract features from.\n   * @returns {Promise<Object>} An object containing the concatenated pixel values (and other metadata) of the preprocessed images.\n   */\n  async _call(images) {\n    if (!Array.isArray(images)) {\n      images = [images];\n    }\n    let imageData = await Promise.all(images.map(x => this.preprocess(x)));\n\n    // TODO:\n\n    // Concatenate pixel values\n    // TEMP: Add batch dimension so that concat works\n    imageData.forEach(x => x.pixel_values.dims = [1, ...x.pixel_values.dims]);\n    let pixel_values = cat(imageData.map(x => x.pixel_values));\n    return {\n      pixel_values: pixel_values,\n      // Original sizes of images\n      original_sizes: imageData.map(x => x.original_size),\n      // Reshaped sizes of images, before padding or cropping\n      reshaped_input_sizes: imageData.map(x => x.reshaped_input_size)\n    };\n  }\n}\nexport class ViTFeatureExtractor extends ImageFeatureExtractor {}\n\n/**\n * Detr Feature Extractor.\n *\n * @extends ImageFeatureExtractor\n */\nexport class DetrFeatureExtractor extends ImageFeatureExtractor {\n  /**\n   * Calls the feature extraction process on an array of image\n   * URLs, preprocesses each image, and concatenates the resulting\n   * features into a single Tensor.\n   * @param {any} urls The URL(s) of the image(s) to extract features from.\n   * @returns {Promise<Object>} An object containing the concatenated pixel values of the preprocessed images.\n   */\n  async _call(urls) {\n    let result = await super._call(urls);\n\n    // TODO support differently-sized images, for now assume all images are the same size.\n    // TODO support different mask sizes (not just 64x64)\n    // Currently, just fill pixel mask with 1s\n    let maskSize = [result.pixel_values.dims[0], 64, 64];\n    result.pixel_mask = new Tensor('int64',\n    // TODO: fix error below\n    new BigInt64Array(maskSize.reduce((a, b) => a * b)).fill(1n), maskSize);\n    return result;\n  }\n\n  /**\n   * @param {number[]} arr The URL(s) of the image(s) to extract features from.\n   * @returns {number[]} An object containing the concatenated pixel values of the preprocessed images.\n   */\n  center_to_corners_format(_ref) {\n    let [centerX, centerY, width, height] = _ref;\n    return [centerX - width / 2, centerY - height / 2, centerX + width / 2, centerY + height / 2];\n  }\n\n  /**\n   * Post-processes the outputs of the model (for object detection).\n   * @param {Object} outputs The outputs of the model that must be post-processed\n   * @param {Tensor} outputs.logits The logits\n   * @param {Tensor} outputs.pred_boxes The predicted boxes.\n   * @return {Object[]} An array of objects containing the post-processed outputs.\n   */\n  post_process_object_detection(outputs) {\n    let threshold = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0.5;\n    let target_sizes = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;\n    const out_logits = outputs.logits;\n    const out_bbox = outputs.pred_boxes;\n    const [batch_size, num_boxes, num_classes] = out_logits.dims;\n    if (target_sizes !== null && target_sizes.length !== batch_size) {\n      throw Error(\"Make sure that you pass in as many target sizes as the batch dimension of the logits\");\n    }\n    let toReturn = [];\n    for (let i = 0; i < batch_size; ++i) {\n      let target_size = target_sizes !== null ? target_sizes[i] : null;\n      let info = {\n        boxes: [],\n        classes: [],\n        scores: []\n      };\n      let logits = out_logits[i];\n      let bbox = out_bbox[i];\n      for (let j = 0; j < num_boxes; ++j) {\n        let logit = logits[j];\n\n        // Get most probable class\n        let maxIndex = max(logit.data)[1];\n        if (maxIndex === num_classes - 1) {\n          // This is the background class, skip it\n          continue;\n        }\n\n        // Compute softmax over classes\n        let probs = softmax(logit.data);\n        let score = probs[maxIndex];\n        if (score > threshold) {\n          // Some class has a high enough probability\n          /** @type {number[]} */\n          let box = bbox[j].data;\n\n          // convert to [x0, y0, x1, y1] format\n          box = this.center_to_corners_format(box);\n          if (target_size !== null) {\n            box = box.map((x, i) => x * target_size[(i + 1) % 2]);\n          }\n          info.boxes.push(box);\n          info.classes.push(maxIndex);\n          info.scores.push(score);\n        }\n      }\n      toReturn.push(info);\n    }\n    return toReturn;\n  }\n\n  /**\n   * Binarize the given masks using `object_mask_threshold`, it returns the associated values of `masks`, `scores` and `labels`.\n   * @param {Tensor} class_logits The class logits.\n   * @param {Tensor} mask_logits The mask logits.\n   * @param {number} object_mask_threshold A number between 0 and 1 used to binarize the masks.\n   * @param {number} num_labels The number of labels.\n   * @returns {[Tensor[], number[], number[]]} The binarized masks, the scores, and the labels.\n   */\n  remove_low_and_no_objects(class_logits, mask_logits, object_mask_threshold, num_labels) {\n    let mask_probs_item = [];\n    let pred_scores_item = [];\n    let pred_labels_item = [];\n    for (let j = 0; j < class_logits.dims[0]; ++j) {\n      let cls = class_logits[j];\n      let mask = mask_logits[j];\n      let pred_label = max(cls.data)[1];\n      if (pred_label === num_labels) {\n        // Is the background, so we ignore it\n        continue;\n      }\n      let scores = softmax(cls.data);\n      let pred_score = scores[pred_label];\n      if (pred_score > object_mask_threshold) {\n        mask_probs_item.push(mask);\n        pred_scores_item.push(pred_score);\n        pred_labels_item.push(pred_label);\n      }\n    }\n    return [mask_probs_item, pred_scores_item, pred_labels_item];\n  }\n\n  /**\n   * Checks whether the segment is valid or not.\n   * @param {Int32Array} mask_labels Labels for each pixel in the mask.\n   * @param {Tensor[]} mask_probs Probabilities for each pixel in the masks.\n   * @param {number} k The class id of the segment.\n   * @param {number} mask_threshold The mask threshold.\n   * @param {number} overlap_mask_area_threshold The overlap mask area threshold.\n   * @returns {[boolean, number[]]} Whether the segment is valid or not, and the indices of the valid labels.\n   */\n  check_segment_validity(mask_labels, mask_probs, k) {\n    let mask_threshold = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 0.5;\n    let overlap_mask_area_threshold = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : 0.8;\n    // mask_k is a 1D array of indices, indicating where the mask is equal to k\n    let mask_k = [];\n    let mask_k_area = 0;\n    let original_area = 0;\n\n    // Compute the area of all the stuff in query k\n    for (let i = 0; i < mask_labels.length; ++i) {\n      if (mask_labels[i] === k) {\n        mask_k.push(i);\n        ++mask_k_area;\n      }\n      if (mask_probs[k].data[i] >= mask_threshold) {\n        ++original_area;\n      }\n    }\n    let mask_exists = mask_k_area > 0 && original_area > 0;\n\n    // Eliminate disconnected tiny segments\n    if (mask_exists) {\n      // Perform additional check\n      let area_ratio = mask_k_area / original_area;\n      mask_exists = area_ratio > overlap_mask_area_threshold;\n    }\n    return [mask_exists, mask_k];\n  }\n\n  /**\n   * Computes the segments.\n   * @param {Tensor[]} mask_probs The mask probabilities.\n   * @param {number[]} pred_scores The predicted scores.\n   * @param {number[]} pred_labels The predicted labels.\n   * @param {number} mask_threshold The mask threshold.\n   * @param {number} overlap_mask_area_threshold The overlap mask area threshold.\n   * @param {Set<number>} label_ids_to_fuse The label ids to fuse.\n   * @param {number[]} target_size The target size of the image.\n   * @returns {[Tensor, Array<{id: number, label_id: number, score: number}>]} The computed segments.\n   */\n  compute_segments(mask_probs, pred_scores, pred_labels, mask_threshold, overlap_mask_area_threshold) {\n    let label_ids_to_fuse = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : null;\n    let target_size = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : null;\n    let [height, width] = target_size ?? mask_probs[0].dims;\n    let segmentation = new Tensor('int32', new Int32Array(height * width), [height, width]);\n    let segments = [];\n\n    // 1. If target_size is not null, we need to resize the masks to the target size\n    if (target_size !== null) {\n      // resize the masks to the target size\n      for (let i = 0; i < mask_probs.length; ++i) {\n        mask_probs[i] = interpolate(mask_probs[i], target_size, 'bilinear', false);\n      }\n    }\n\n    // 2. Weigh each mask by its prediction score\n    // NOTE: `mask_probs` is updated in-place\n    // \n    // Temporary storage for the best label/scores for each pixel ([height, width]):\n    let mask_labels = new Int32Array(mask_probs[0].data.length);\n    let bestScores = new Float32Array(mask_probs[0].data.length);\n    for (let i = 0; i < mask_probs.length; ++i) {\n      let score = pred_scores[i];\n      for (let j = 0; j < mask_probs[i].data.length; ++j) {\n        mask_probs[i].data[j] *= score;\n        if (mask_probs[i].data[j] > bestScores[j]) {\n          mask_labels[j] = i;\n          bestScores[j] = mask_probs[i].data[j];\n        }\n      }\n    }\n    let current_segment_id = 0;\n\n    // let stuff_memory_list = {}\n    for (let k = 0; k < pred_labels.length; ++k) {\n      let pred_class = pred_labels[k];\n\n      // TODO add `should_fuse`\n      // let should_fuse = pred_class in label_ids_to_fuse\n\n      // Check if mask exists and large enough to be a segment\n      let [mask_exists, mask_k] = this.check_segment_validity(mask_labels, mask_probs, k, mask_threshold, overlap_mask_area_threshold);\n      if (!mask_exists) {\n        // Nothing to see here\n        continue;\n      }\n\n      // TODO\n      // if (pred_class in stuff_memory_list) {\n      //     current_segment_id = stuff_memory_list[pred_class]\n      // } else {\n      //     current_segment_id += 1;\n      // }\n      ++current_segment_id;\n\n      // Add current object segment to final segmentation map\n      for (let index of mask_k) {\n        segmentation.data[index] = current_segment_id;\n      }\n      segments.push({\n        id: current_segment_id,\n        label_id: pred_class,\n        // was_fused: should_fuse, TODO\n        score: pred_scores[k]\n      });\n\n      // TODO\n      // if(should_fuse){\n      //     stuff_memory_list[pred_class] = current_segment_id\n      // }\n    }\n\n    return [segmentation, segments];\n  }\n\n  /**\n   * Post-process the model output to generate the final panoptic segmentation.\n   * @param {*} outputs The model output to post process\n   * @param {number} [threshold=0.5] The probability score threshold to keep predicted instance masks.\n   * @param {number} [mask_threshold=0.5] Threshold to use when turning the predicted masks into binary values.\n   * @param {number} [overlap_mask_area_threshold=0.8] The overlap mask area threshold to merge or discard small disconnected parts within each binary instance mask.\n   * @param {Set<number>} [label_ids_to_fuse=null] The labels in this state will have all their instances be fused together.\n   * @param {number[][]} [target_sizes=null] The target sizes to resize the masks to.\n   * @returns {Array<{ segmentation: Tensor, segments_info: Array<{id: number, label_id: number, score: number}>}>}\n   */\n  post_process_panoptic_segmentation(outputs) {\n    let threshold = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0.5;\n    let mask_threshold = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0.5;\n    let overlap_mask_area_threshold = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 0.8;\n    let label_ids_to_fuse = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : null;\n    let target_sizes = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : null;\n    if (label_ids_to_fuse === null) {\n      console.warn(\"`label_ids_to_fuse` unset. No instance will be fused.\");\n      label_ids_to_fuse = new Set();\n    }\n    const class_queries_logits = outputs.logits; // [batch_size, num_queries, num_classes+1]\n    const masks_queries_logits = outputs.pred_masks; // [batch_size, num_queries, height, width]\n\n    const mask_probs = masks_queries_logits.sigmoid(); // [batch_size, num_queries, height, width]\n\n    let [batch_size, num_queries, num_labels] = class_queries_logits.dims;\n    num_labels -= 1; // Remove last class (background)\n\n    if (target_sizes !== null && target_sizes.length !== batch_size) {\n      throw Error(\"Make sure that you pass in as many target sizes as the batch dimension of the logits\");\n    }\n    let toReturn = [];\n    for (let i = 0; i < batch_size; ++i) {\n      let target_size = target_sizes !== null ? target_sizes[i] : null;\n      let class_logits = class_queries_logits[i];\n      let mask_logits = mask_probs[i];\n      let [mask_probs_item, pred_scores_item, pred_labels_item] = this.remove_low_and_no_objects(class_logits, mask_logits, threshold, num_labels);\n      if (pred_labels_item.length === 0) {\n        // No mask found\n        let [height, width] = target_size ?? mask_logits.dims.slice(-2);\n        let segmentation = new Tensor('int32', new Int32Array(height * width).fill(-1), [height, width]);\n        toReturn.push({\n          segmentation: segmentation,\n          segments_info: []\n        });\n        continue;\n      }\n\n      // Get segmentation map and segment information of batch item\n      let [segmentation, segments] = this.compute_segments(mask_probs_item, pred_scores_item, pred_labels_item, mask_threshold, overlap_mask_area_threshold, label_ids_to_fuse, target_size);\n      toReturn.push({\n        segmentation: segmentation,\n        segments_info: segments\n      });\n    }\n    return toReturn;\n  }\n  post_process_instance_segmentation() {\n    // TODO\n    throw Error(\"Not implemented yet\");\n  }\n}\nexport class SamImageProcessor extends ImageFeatureExtractor {\n  async _call(images, input_points) {\n    let {\n      pixel_values,\n      original_sizes,\n      reshaped_input_sizes\n    } = await super._call(images);\n    let shape = calculateDimensions(input_points);\n    if (shape.length === 3) {\n      // Correct user's input\n      shape = [1, ...shape];\n      input_points = [input_points];\n    } else if (shape.length !== 4) {\n      throw Error(\"The input_points must be a 4D tensor of shape `batch_size`, `point_batch_size`, `nb_points_per_image`, `2`.\");\n    }\n\n    // Reshape input points\n    for (let i = 0; i < input_points.length; ++i) {\n      // batch_size\n      let originalImageSize = original_sizes[i];\n      let reshapedImageSize = reshaped_input_sizes[i];\n      let resizeFactors = [reshapedImageSize[0] / originalImageSize[0], reshapedImageSize[1] / originalImageSize[1]];\n      for (let j = 0; j < input_points[i].length; ++j) {\n        // point_batch_size\n        for (let k = 0; k < input_points[i][j].length; ++k) {\n          // nb_points_per_image\n          for (let w = 0; w < input_points[i][j][k].length; ++w) {\n            // 2\n            input_points[i][j][k][w] *= resizeFactors[w];\n          }\n        }\n      }\n    }\n    let input_points_tensor = new Tensor('int64', BigInt64Array.from(input_points.flat(Infinity).map(x => BigInt(Math.round(x)))), shape);\n\n    // TODO: allowed to be floats?\n    // let input_points_tensor = new Tensor(\n    //     'float32',\n    //     Float32Array.from(input_points.flat(Infinity)),\n    //     shape\n    // )\n\n    return {\n      pixel_values,\n      original_sizes: original_sizes,\n      reshaped_input_sizes: reshaped_input_sizes,\n      input_points: input_points_tensor\n    };\n  }\n\n  /**\n   * Remove padding and upscale masks to the original image size.\n   * @param {Tensor} masks Batched masks from the mask_decoder in (batch_size, num_channels, height, width) format.\n   * @param {number[][]} original_sizes The original sizes of each image before it was resized to the model's expected input shape, in (height, width) format.\n   * @param {number[][]} reshaped_input_sizes The size of each image as it is fed to the model, in (height, width) format. Used to remove padding.\n   * @param {Object} options Optional parameters for post-processing.\n   * @param {number} [options.mask_threshold] The threshold to use for binarizing the masks.\n   * @param {boolean} [options.binarize] Whether to binarize the masks.\n   * @param {Object} [options.pad_size] The target size the images were padded to before being passed to the model. If `null`, the target size is assumed to be the processor's `pad_size`.\n   * @param {number} [options.pad_size.height] The height the images were padded to.\n   * @param {number} [options.pad_size.width] The width the images were padded to.\n   * @returns {Tensor[]} Batched masks in batch_size, num_channels, height, width) format, where (height, width) is given by original_size.\n   */\n  post_process_masks(masks, original_sizes, reshaped_input_sizes) {\n    let {\n      mask_threshold = 0.0,\n      binarize = true,\n      pad_size = null\n    } = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : {};\n    // masks: [1, 1, 3, 256, 256]\n\n    let output_masks = [];\n    pad_size = pad_size ?? this.pad_size;\n    let target_image_size = [pad_size.height, pad_size.width];\n    for (let i = 0; i < original_sizes.length; ++i) {\n      let original_size = original_sizes[i];\n      let reshaped_input_size = reshaped_input_sizes[i];\n      let mask = masks[i]; // [b, c, h, w]\n\n      // TODO: improve\n      let interpolated_masks = [];\n      for (let j = 0; j < mask.dims[0]; ++j) {\n        let m = mask[j]; // 3d tensor\n\n        // Upscale mask to padded size\n        let interpolated_mask = interpolate(m, target_image_size, 'bilinear', false);\n\n        // Crop mask\n        interpolated_mask = interpolated_mask.slice(null, [0, reshaped_input_size[0]], [0, reshaped_input_size[1]]);\n\n        // Downscale mask\n        interpolated_mask = interpolate(mask, original_size, 'bilinear', false);\n        if (binarize) {\n          interpolated_mask = new Tensor('bool', Array.from(interpolated_mask.data).map(x => x > mask_threshold), interpolated_mask.dims);\n        }\n\n        // add back batch dim for concat\n        interpolated_mask.dims = [1, ...interpolated_mask.dims];\n        interpolated_masks.push(interpolated_mask);\n      }\n      let concatenated = cat(interpolated_masks);\n      output_masks.push(concatenated);\n    }\n    return output_masks;\n  }\n}\nexport class WhisperFeatureExtractor extends FeatureExtractor {\n  constructor(config) {\n    super(config);\n\n    // Prefer given `mel_filters` from preprocessor_config.json, or calculate them if they don't exist.\n    this.config.mel_filters ??= getMelFilters(this.config.sampling_rate, this.config.n_fft, this.config.feature_size);\n  }\n  /**\n   * Calculates the index offset for a given index and window size.\n   * @param {number} i The index.\n   * @param {number} w The window size.\n   * @returns {number} The index offset.\n   */\n  calcOffset(i, w) {\n    return Math.abs((i + w) % (2 * w) - w);\n  }\n\n  /**\n   * Pads an array with a reflected version of itself on both ends.\n   * @param {Float32Array} array The array to pad.\n   * @param {number} left The amount of padding to add to the left.\n   * @param {number} right The amount of padding to add to the right.\n   * @returns {Float32Array} The padded array.\n   */\n  padReflect(array, left, right) {\n    const padded = new Float32Array(array.length + left + right);\n    const w = array.length - 1;\n    for (let i = 0; i < array.length; ++i) {\n      padded[left + i] = array[i];\n    }\n    for (let i = 1; i <= left; ++i) {\n      padded[left - i] = array[this.calcOffset(i, w)];\n    }\n    for (let i = 1; i <= right; ++i) {\n      padded[w + left + i] = array[this.calcOffset(w - i, w)];\n    }\n    return padded;\n  }\n\n  /**\n   * Calculates the complex Short-Time Fourier Transform (STFT) of the given framed signal.\n   * \n   * @param {number[][]} frames A 2D array representing the signal frames.\n   * @param {number[]} window A 1D array representing the window to be applied to the frames.\n   * @returns {Object} An object with the following properties:\n   * - data: A 1D array representing the complex STFT of the signal.\n   * - dims: An array representing the dimensions of the STFT data, i.e. [num_frames, num_fft_bins].\n   */\n  stft(frames, window) {\n    // Calculates the complex Short-Time Fourier Transform (STFT) of the given framed signal.\n    // \n    // NOTE: Since the window width is not a power of 2, we must \n    // perform Fast Fourier Transform with chirp-z transform:\n    // https://math.stackexchange.com/questions/77118/non-power-of-2-ffts/77156#77156\n\n    // Helper variables\n    const fft_size = this.config.n_fft;\n    const a = 2 * (fft_size - 1);\n    const b = 2 * (2 * fft_size - 1);\n    const nextP2 = 2 ** Math.ceil(Math.log2(b));\n    const num_fft_bins = fft_size + 2;\n\n    // Preallocate array to store output\n    // double since we store complex numbers\n    const data = new Float32Array(num_fft_bins * frames.length);\n\n    // Define buffers\n    // Compute chirp for transform\n    const chirp = new Float32Array(b);\n    const ichirp = new Float32Array(nextP2);\n    const buffer1 = new Float32Array(nextP2);\n    const buffer2 = new Float32Array(nextP2);\n    const outBuffer = new Float32Array(nextP2);\n    const outBuffer2 = new Float32Array(nextP2);\n    const outBuffer3 = new Float32Array(nextP2);\n\n    // Compute complex exponentiation\n    const theta = -2 * Math.PI / fft_size;\n    const baseR = Math.cos(theta);\n    const baseI = Math.sin(theta);\n\n    // Precompute helper for chirp-z transform\n    for (let i = 0; i < b >> 1; ++i) {\n      // Compute complex power:\n      const e = (i + 1 - fft_size) ** 2 / 2.0;\n\n      // Compute the modulus and argument of the result\n      const result_mod = Math.sqrt(baseR ** 2 + baseI ** 2) ** e;\n      const result_arg = e * Math.atan2(baseI, baseR);\n\n      // Convert the result back to rectangular form\n      // and assign to chirp and ichirp\n      let i2 = 2 * i;\n      chirp[i2] = result_mod * Math.cos(result_arg);\n      chirp[i2 + 1] = result_mod * Math.sin(result_arg);\n\n      // conjugate\n      ichirp[i2] = chirp[i2];\n      ichirp[i2 + 1] = -chirp[i2 + 1];\n    }\n    const slicedChirp = chirp.subarray(a, b);\n\n    // create object to perform Fast Fourier Transforms\n    // with `nextP2` complex numbers\n    const f = new FFT(nextP2 >> 1);\n    // TODO: decide between Float32Array and Float64Array\n    f.transform(outBuffer, ichirp);\n    for (let i = 0; i < frames.length; ++i) {\n      const frame = frames[i];\n      for (let j = 0; j < slicedChirp.length; j += 2) {\n        const j2 = j + 1;\n        const j3 = j >> 1;\n        const a_real = frame[j3] * window[j3];\n        buffer1[j] = a_real * slicedChirp[j];\n        buffer1[j2] = a_real * slicedChirp[j2];\n      }\n      // TODO: decide between Float32Array and Float64Array\n      f.transform(outBuffer2, buffer1);\n      for (let j = 0; j < outBuffer.length; j += 2) {\n        const j2 = j + 1;\n        buffer2[j] = outBuffer2[j] * outBuffer[j] - outBuffer2[j2] * outBuffer[j2];\n        buffer2[j2] = outBuffer2[j] * outBuffer[j2] + outBuffer2[j2] * outBuffer[j];\n      }\n      // TODO: decide between Float32Array and Float64Array\n      f.inverseTransform(outBuffer3, buffer2);\n      const offset = i * num_fft_bins;\n      for (let j = 0; j < num_fft_bins; j += 2) {\n        const a_real = outBuffer3[j + a];\n        const a_imag = outBuffer3[j + a + 1];\n        const b_real = slicedChirp[j];\n        const b_imag = slicedChirp[j + 1];\n\n        // TODO write as transpose\n        const o1 = offset + j;\n        data[o1] = a_real * b_real - a_imag * b_imag;\n        data[o1 + 1] = a_real * b_imag + a_imag * b_real;\n      }\n    }\n    return {\n      data: data,\n      dims: [frames.length, num_fft_bins] // [3001, 402]\n    };\n  }\n\n  /**\n   * Creates an array of frames from a given waveform.\n   *\n   * @param {Float32Array} waveform The waveform to create frames from.\n   * @param {boolean} [center=true] Whether to center the frames on their corresponding positions in the waveform. Defaults to true.\n   * @returns {Array} An array of frames.\n   */\n  fram_wave(waveform) {\n    let center = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : true;\n    const frames = [];\n    const half_window = Math.floor((this.config.n_fft - 1) / 2) + 1;\n    const waveformLength = waveform.length;\n    for (let i = 0; i < waveformLength + 1; i += this.config.hop_length) {\n      let frame;\n      if (center) {\n        let frameStart = i > half_window ? i - half_window : 0;\n        let frameEnd = i < waveformLength - half_window ? i + half_window : waveformLength;\n        frame = waveform.subarray(frameStart, frameEnd);\n        if (frameStart === 0) {\n          frame = this.padReflect(frame, -i + half_window, 0);\n        } else if (frameEnd === waveformLength) {\n          frame = this.padReflect(frame, 0, i - waveformLength + half_window);\n        }\n      } else {\n        frame = new Float32Array(this.config.n_fft);\n        const frameArray = waveform.subarray(i, i + this.config.n_fft);\n        if (frameArray.length < this.config.n_fft) {\n          frame.set(frameArray);\n          frame.fill(0, frameArray.length, this.config.n_fft);\n        } else {\n          frame = frameArray;\n        }\n      }\n      frames.push(frame);\n    }\n    return frames;\n  }\n\n  /**\n   * Generates a Hanning window of length M.\n   *\n   * @param {number} M The length of the Hanning window to generate.\n   * @returns {*} The generated Hanning window.\n   */\n  hanning(M) {\n    if (M < 1) {\n      return [];\n    }\n    if (M === 1) {\n      return [1];\n    }\n    const denom = M - 1;\n    const cos_vals = new Float32Array(denom);\n    for (let i = 0; i < denom; ++i) {\n      const n = 2 * i - M + 1;\n      cos_vals[i] = 0.5 + 0.5 * Math.cos(Math.PI * n / denom);\n    }\n    return cos_vals;\n  }\n\n  /**\n   * Computes the log-Mel spectrogram of the provided audio waveform.\n   * @param {Float32Array} waveform The audio waveform to process.\n   * @returns {{data: Float32Array, dims: number[]}} An object containing the log-Mel spectrogram data as a Float32Array and its dimensions as an array of numbers.\n   */\n  _extract_fbank_features(waveform) {\n    // Compute the log-Mel spectrogram of the provided audio\n\n    const buffer = new Float32Array(this.config.n_samples);\n    buffer.set(waveform);\n    const window = this.hanning(this.config.n_fft + 1);\n    const frames = this.fram_wave(buffer);\n    const stft = this.stft(frames, window);\n    const stftData = stft.data;\n    const d1 = stft.dims[0] - 1; // Ignore last row\n    const d2 = stft.dims[1] >> 1; // Only need to store real numbers now\n\n    // compute magnitudes\n    // NOTE: Unlinke the original implementation, we do not\n    // transpose since we perform matrix multiplication later\n    const magnitudes = new Float32Array(d1 * d2);\n    for (let i = 0; i < d1; ++i) {\n      for (let j = 0; j < d2; ++j) {\n        // let outOffset = (j * d1 + i); // transpose\n        let outOffset = i * d2 + j;\n        let inOffset = outOffset << 1; // * 2 since complex\n        let magnitude = stftData[inOffset] ** 2 + stftData[inOffset + 1] ** 2;\n        magnitudes[outOffset] = magnitude;\n      }\n    }\n    const mel_filters = this.config.mel_filters;\n    const num_mel_filters = mel_filters.length;\n    const mel_spec = new Float32Array(num_mel_filters * d1);\n    let mIndex = 0;\n\n    // Perform matrix muliplication:\n    // mel_spec = filters @ magnitudes\n    //  - filters.shape=(80, 201)\n    //  - magnitudes.shape=(201, 3000)\n    //  - mel_spec.shape=(80, 3000)\n    for (let i = 0; i < num_mel_filters; ++i) {\n      const mel_filter = mel_filters[i];\n      for (let j = 0; j < d1; ++j) {\n        let sum = 0;\n\n        // perform dot product\n        for (let k = 0; k < d2; ++k) {\n          sum += mel_filter[k] * magnitudes[j * d2 + k];\n        }\n        mel_spec[mIndex++] = sum;\n      }\n    }\n    const a_min = 1e-10;\n    const log_spec = new Float32Array(mel_spec.length);\n    let maxLogSpec = 0;\n    for (let i = 0; i < mel_spec.length; ++i) {\n      const clipped = Math.max(a_min, mel_spec[i]);\n      const log10 = Math.log10(clipped);\n      log_spec[i] = log10;\n      maxLogSpec = Math.max(log10, maxLogSpec);\n    }\n    for (let i = 0; i < log_spec.length; ++i) {\n      log_spec[i] = Math.max(log_spec[i], maxLogSpec - 8);\n      log_spec[i] = (log_spec[i] + 4) / 4;\n    }\n    return {\n      data: log_spec,\n      dims: [num_mel_filters, d1]\n    };\n  }\n\n  /**\n   * Asynchronously extracts features from a given audio using the provided configuration.\n   * @param {Float32Array} audio The audio data as a Float32Array.\n   * @returns {Promise<{ input_features: Tensor }>} A Promise resolving to an object containing the extracted input features as a Tensor.\n  */\n  async _call(audio) {\n    // audio is a float32array\n\n    if (audio.length > this.config.n_samples) {\n      console.warn(\"Attempting to extract features for audio longer than 30 seconds. \" + \"If using a pipeline to extract transcript from a long audio clip, \" + \"remember to specify `chunk_length_s` and/or `stride_length_s`.\");\n    }\n    let waveform = audio.slice(0, this.config.n_samples);\n    let features = this._extract_fbank_features(waveform);\n    return {\n      input_features: new Tensor('float32', features.data, [1, ...features.dims])\n    };\n  }\n}\n\n/**\n * Represents a Processor that extracts features from an input.\n * @extends Callable\n */\nexport class Processor extends Callable {\n  /**\n   * Creates a new Processor with the given feature extractor.\n   * @param {FeatureExtractor} feature_extractor The function used to extract features from the input.\n   */\n  constructor(feature_extractor) {\n    super();\n    this.feature_extractor = feature_extractor;\n    // TODO use tokenizer here?\n  }\n\n  /**\n   * Calls the feature_extractor function with the given input.\n   * @param {any} input The input to extract features from.\n   * @returns {Promise<any>} A Promise that resolves with the extracted features.\n   */\n  async _call(input) {\n    return await this.feature_extractor(input);\n  }\n}\nexport class SamProcessor extends Processor {\n  async _call(images, input_points) {\n    return await this.feature_extractor(images, input_points);\n  }\n\n  /**\n   * @borrows SamImageProcessor#post_process_masks as post_process_masks\n   */\n  post_process_masks() {\n    // @ts-ignore\n    return this.feature_extractor.post_process_masks(...arguments);\n  }\n}\n\n/**\n * Represents a WhisperProcessor that extracts features from an audio input.\n * @extends Processor\n */\nexport class WhisperProcessor extends Processor {\n  /**\n   * Calls the feature_extractor function with the given audio input.\n   * @param {any} audio The audio input to extract features from.\n   * @returns {Promise<any>} A Promise that resolves with the extracted features.\n   */\n  async _call(audio) {\n    return await this.feature_extractor(audio);\n  }\n}\n\n//////////////////////////////////////////////////\n/**\n * @typedef {import('./utils/hub.js').PretrainedOptions} PretrainedOptions\n */\n/**\n * Helper class which is used to instantiate pretrained processors with the `from_pretrained` function.\n * The chosen processor class is determined by the type specified in the processor config.\n * \n * **Example:** Load a processor using `from_pretrained`.\n * ```javascript\n * let processor = await AutoProcessor.from_pretrained('openai/whisper-tiny.en');\n * ```\n * \n * **Example:** Run an image through a processor.\n * ```javascript\n * let processor = await AutoProcessor.from_pretrained('Xenova/clip-vit-base-patch16');\n * let image = await RawImage.read('https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/football-match.jpg');\n * let image_inputs = await processor(image);\n * // {\n * //   \"pixel_values\": {\n * //     \"dims\": [ 1, 3, 224, 224 ],\n * //     \"type\": \"float32\",\n * //     \"data\": Float32Array [ -1.558687686920166, -1.558687686920166, -1.5440893173217773, ... ],\n * //     \"size\": 150528\n * //   },\n * //   \"original_sizes\": [\n * //     [ 533, 800 ]\n * //   ],\n * //   \"reshaped_input_sizes\": [\n * //     [ 224, 224 ]\n * //   ]\n * // }\n * ```\n */\nexport class AutoProcessor {\n  static FEATURE_EXTRACTOR_CLASS_MAPPING = {\n    'WhisperFeatureExtractor': WhisperFeatureExtractor,\n    'ViTFeatureExtractor': ViTFeatureExtractor,\n    'DetrFeatureExtractor': DetrFeatureExtractor,\n    'SamImageProcessor': SamImageProcessor\n  };\n  static PROCESSOR_CLASS_MAPPING = {\n    'WhisperProcessor': WhisperProcessor,\n    'SamProcessor': SamProcessor\n  };\n\n  /**\n   * Instantiate one of the processor classes of the library from a pretrained model.\n   * \n   * The processor class to instantiate is selected based on the `feature_extractor_type` property of the config object\n   * (either passed as an argument or loaded from `pretrained_model_name_or_path` if possible)\n   * \n   * @param {string} pretrained_model_name_or_path The name or path of the pretrained model. Can be either:\n   * - A string, the *model id* of a pretrained processor hosted inside a model repo on huggingface.co.\n   *   Valid model ids can be located at the root-level, like `bert-base-uncased`, or namespaced under a\n   *   user or organization name, like `dbmdz/bert-base-german-cased`.\n   * - A path to a *directory* containing processor files, e.g., `./my_model_directory/`.\n   * @param {PretrainedOptions} options Additional options for loading the processor.\n   * \n   * @returns {Promise<Processor>} A new instance of the Processor class.\n   */\n  static async from_pretrained(pretrained_model_name_or_path) {\n    let {\n      progress_callback = null,\n      config = null,\n      cache_dir = null,\n      local_files_only = false,\n      revision = 'main'\n    } = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    let preprocessorConfig = config ?? (await getModelJSON(pretrained_model_name_or_path, 'preprocessor_config.json', true, {\n      progress_callback,\n      config,\n      cache_dir,\n      local_files_only,\n      revision\n    }));\n\n    // Determine feature extractor class\n    // TODO: Ensure backwards compatibility with old configs\n    let key = preprocessorConfig.feature_extractor_type ?? preprocessorConfig.image_processor_type;\n    let feature_extractor_class = this.FEATURE_EXTRACTOR_CLASS_MAPPING[key];\n    if (!feature_extractor_class) {\n      if (preprocessorConfig.size !== undefined) {\n        // Assume ImageFeatureExtractor\n        console.warn('Feature extractor type not specified, assuming ImageFeatureExtractor due to size parameter in config.');\n        feature_extractor_class = ImageFeatureExtractor;\n      } else {\n        throw new Error(`Unknown Feature Extractor type: ${preprocessorConfig.feature_extractor_type}`);\n      }\n    }\n\n    // If no associated processor class, use default\n    let processor_class = this.PROCESSOR_CLASS_MAPPING[preprocessorConfig.processor_class] ?? Processor;\n\n    // Instantiate processor and feature extractor\n    let feature_extractor = new feature_extractor_class(preprocessorConfig);\n    return new processor_class(feature_extractor);\n  }\n}\n//////////////////////////////////////////////////","map":{"version":3,"names":["Callable","calculateDimensions","getModelJSON","max","softmax","FFT","Tensor","transpose","cat","interpolate","RawImage","getMelFilters","FeatureExtractor","constructor","config","ImageFeatureExtractor","image_mean","image_std","resample","do_rescale","rescale_factor","do_normalize","do_resize","size","do_center_crop","crop_size","do_convert_rgb","pad_size","do_pad","preprocess","image","rgb","srcWidth","width","srcHeight","height","shortest_edge","longest_edge","Number","isInteger","max_size","undefined","shortResizeFactor","Math","newWidth","newHeight","longResizeFactor","min","resize","floor","Error","JSON","stringify","crop_width","crop_height","center_crop","reshaped_input_size","left","right","top","bottom","pad","pixelData","Float32Array","from","data","i","length","Array","isArray","channels","fill","j","imgDims","img","transposed","original_size","pixel_values","_call","images","imageData","Promise","all","map","x","forEach","dims","original_sizes","reshaped_input_sizes","ViTFeatureExtractor","DetrFeatureExtractor","urls","result","maskSize","pixel_mask","BigInt64Array","reduce","a","b","center_to_corners_format","_ref","centerX","centerY","post_process_object_detection","outputs","threshold","arguments","target_sizes","out_logits","logits","out_bbox","pred_boxes","batch_size","num_boxes","num_classes","toReturn","target_size","info","boxes","classes","scores","bbox","logit","maxIndex","probs","score","box","push","remove_low_and_no_objects","class_logits","mask_logits","object_mask_threshold","num_labels","mask_probs_item","pred_scores_item","pred_labels_item","cls","mask","pred_label","pred_score","check_segment_validity","mask_labels","mask_probs","k","mask_threshold","overlap_mask_area_threshold","mask_k","mask_k_area","original_area","mask_exists","area_ratio","compute_segments","pred_scores","pred_labels","label_ids_to_fuse","segmentation","Int32Array","segments","bestScores","current_segment_id","pred_class","index","id","label_id","post_process_panoptic_segmentation","console","warn","Set","class_queries_logits","masks_queries_logits","pred_masks","sigmoid","num_queries","slice","segments_info","post_process_instance_segmentation","SamImageProcessor","input_points","shape","originalImageSize","reshapedImageSize","resizeFactors","w","input_points_tensor","flat","Infinity","BigInt","round","post_process_masks","masks","binarize","output_masks","target_image_size","interpolated_masks","m","interpolated_mask","concatenated","WhisperFeatureExtractor","mel_filters","sampling_rate","n_fft","feature_size","calcOffset","abs","padReflect","array","padded","stft","frames","window","fft_size","nextP2","ceil","log2","num_fft_bins","chirp","ichirp","buffer1","buffer2","outBuffer","outBuffer2","outBuffer3","theta","PI","baseR","cos","baseI","sin","e","result_mod","sqrt","result_arg","atan2","i2","slicedChirp","subarray","f","transform","frame","j2","j3","a_real","inverseTransform","offset","a_imag","b_real","b_imag","o1","fram_wave","waveform","center","half_window","waveformLength","hop_length","frameStart","frameEnd","frameArray","set","hanning","M","denom","cos_vals","n","_extract_fbank_features","buffer","n_samples","stftData","d1","d2","magnitudes","outOffset","inOffset","magnitude","num_mel_filters","mel_spec","mIndex","mel_filter","sum","a_min","log_spec","maxLogSpec","clipped","log10","audio","features","input_features","Processor","feature_extractor","input","SamProcessor","WhisperProcessor","AutoProcessor","FEATURE_EXTRACTOR_CLASS_MAPPING","PROCESSOR_CLASS_MAPPING","from_pretrained","pretrained_model_name_or_path","progress_callback","cache_dir","local_files_only","revision","preprocessorConfig","key","feature_extractor_type","image_processor_type","feature_extractor_class","processor_class"],"sources":["/Users/phreetech13/Desktop/RealTimeAudioToText/node_modules/@xenova/transformers/src/processors.js"],"sourcesContent":["\n/**\n * @file Processors are used to prepare non-textual inputs (e.g., image or audio) for a model.\n * \n * **Example:** Using a `WhisperProcessor` to prepare an audio input for a model.\n * ```javascript\n * import { AutoProcessor, read_audio } from '@xenova/transformers';\n *\n * let processor = await AutoProcessor.from_pretrained('openai/whisper-tiny.en');\n * let audio = await read_audio('https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac', 16000);\n * let { input_features } = await processor(audio);\n * // Tensor {\n * //   data: Float32Array(240000) [0.4752984642982483, 0.5597258806228638, 0.56434166431427, ...],\n * //   dims: [1, 80, 3000],\n * //   type: 'float32',\n * //   size: 240000,\n * // }\n * ```\n * \n * @module processors\n */\nimport {\n    Callable,\n    calculateDimensions,\n} from './utils/core.js';\n\nimport {\n    getModelJSON,\n} from './utils/hub.js';\n\nimport {\n    max,\n    softmax,\n    FFT\n} from './utils/maths.js';\n\n\nimport { Tensor, transpose, cat, interpolate } from './utils/tensor.js';\n\nimport { RawImage } from './utils/image.js';\nimport { getMelFilters } from './utils/audio.js';\n\n\n/**\n * Base class for feature extractors.\n *\n * @extends Callable\n */\nexport class FeatureExtractor extends Callable {\n    /**\n     * Constructs a new FeatureExtractor instance.\n     *\n     * @param {Object} config The configuration for the feature extractor.\n     */\n    constructor(config) {\n        super();\n        this.config = config\n    }\n}\n\n/**\n * Feature extractor for Vision Transformer (ViT) models.\n *\n * @extends FeatureExtractor\n */\nexport class ImageFeatureExtractor extends FeatureExtractor {\n\n    /**\n     * Constructs a new ViTFeatureExtractor instance.\n     *\n     * @param {Object} config The configuration for the feature extractor.\n     * @param {number[]} config.image_mean The mean values for image normalization.\n     * @param {number[]} config.image_std The standard deviation values for image normalization.\n     * @param {boolean} config.do_rescale Whether to rescale the image pixel values to the [0,1] range.\n     * @param {number} config.rescale_factor The factor to use for rescaling the image pixel values.\n     * @param {boolean} config.do_normalize Whether to normalize the image pixel values.\n     * @param {boolean} config.do_resize Whether to resize the image.\n     * @param {number} config.resample What method to use for resampling.\n     * @param {number} config.size The size to resize the image to.\n     */\n    constructor(config) {\n        super(config);\n\n        this.image_mean = this.config.image_mean;\n        this.image_std = this.config.image_std;\n\n        this.resample = this.config.resample ?? 2; // 2 => bilinear\n        this.do_rescale = this.config.do_rescale ?? true;\n        this.rescale_factor = this.config.rescale_factor ?? (1 / 255);\n        this.do_normalize = this.config.do_normalize;\n\n        this.do_resize = this.config.do_resize;\n        this.size = this.config.size;\n\n        this.do_center_crop = this.config.do_center_crop;\n        this.crop_size = this.config.crop_size;\n        this.do_convert_rgb = this.config.do_convert_rgb ?? true;\n\n        this.pad_size = this.config.pad_size;\n        this.do_pad = (this.config.do_pad ?? false) && this.pad_size;\n    }\n\n    /**\n     * Preprocesses the given image.\n     *\n     * @param {RawImage} image The image to preprocess.\n     * @returns {Promise<any>} The preprocessed image as a Tensor.\n     */\n    async preprocess(image) {\n\n        // First, convert image to RGB if specified in config.\n        if (this.do_convert_rgb) {\n            image = image.rgb();\n        }\n\n        const srcWidth = image.width;   // original width\n        const srcHeight = image.height; // original height\n\n        // Next, resize all images\n        if (this.do_resize) {\n            // TODO:\n            // For efficiency reasons, it might be best to merge the resize and center crop operations into one.\n\n            // `this.size` comes in many forms, so we need to handle them all here:\n            // 1. `this.size` is an integer, in which case we resize the image to be a square \n\n            let shortest_edge;\n            let longest_edge;\n\n            // Support both formats for backwards compatibility\n            if (Number.isInteger(this.size)) {\n                shortest_edge = this.size;\n                longest_edge = this.config.max_size ?? shortest_edge;\n\n            } else {\n                // Extract known properties from `this.size`\n                shortest_edge = this.size.shortest_edge;\n                longest_edge = this.size.longest_edge;\n            }\n\n            // If `longest_edge` and `shortest_edge` are set, maintain aspect ratio and resize to `shortest_edge`\n            // while keeping the largest dimension <= `longest_edge`\n            if (shortest_edge !== undefined || longest_edge !== undefined) {\n                // http://opensourcehacker.com/2011/12/01/calculate-aspect-ratio-conserving-resize-for-images-in-javascript/\n                // Try resize so that shortest edge is `this.shortest_edge` (target)\n                const shortResizeFactor = shortest_edge === undefined\n                    ? 1 // If `shortest_edge` is not set, don't upscale\n                    : Math.max(shortest_edge / srcWidth, shortest_edge / srcHeight);\n\n                const newWidth = srcWidth * shortResizeFactor;\n                const newHeight = srcHeight * shortResizeFactor;\n\n                // The new width and height might be greater than `this.longest_edge`, so\n                // we downscale again to ensure the largest dimension is `this.longest_edge` \n                const longResizeFactor = longest_edge === undefined\n                    ? 1 // If `longest_edge` is not set, don't downscale\n                    : Math.min(longest_edge / newWidth, longest_edge / newHeight);\n\n                // Perform resize\n                image = await image.resize(Math.floor(newWidth * longResizeFactor), Math.floor(newHeight * longResizeFactor), {\n                    resample: this.resample,\n                });\n\n            } else if (this.size.width !== undefined && this.size.height !== undefined) {\n                // If `width` and `height` are set, resize to those dimensions\n                image = await image.resize(this.size.width, this.size.height, {\n                    resample: this.resample,\n                });\n            } else {\n                throw new Error(`Could not resize image due to unsupported \\`this.size\\` option in config: ${JSON.stringify(this.size)}`);\n            }\n        }\n\n        if (this.do_center_crop) {\n\n            let crop_width;\n            let crop_height;\n            if (Number.isInteger(this.crop_size)) {\n                crop_width = this.crop_size;\n                crop_height = this.crop_size;\n            } else {\n                crop_width = this.crop_size.width;\n                crop_height = this.crop_size.height;\n            }\n\n            image = await image.center_crop(crop_width, crop_height);\n        }\n\n        let reshaped_input_size = [image.height, image.width];\n\n        // TODO is it okay to pad before rescaling/normalizing?\n        if (this.do_pad) {\n            let left = 0;\n            let right = this.pad_size.width - image.width;\n            let top = 0;\n            let bottom = this.pad_size.height - image.height;\n\n            image = await image.pad([left, right, top, bottom]);\n        }\n\n        const pixelData = Float32Array.from(image.data);\n\n        if (this.do_rescale) {\n            for (let i = 0; i < pixelData.length; ++i) {\n                pixelData[i] = this.rescale_factor * pixelData[i];\n            }\n        }\n\n        if (this.do_normalize) {\n            let image_mean = this.image_mean;\n            if (!Array.isArray(this.image_mean)) {\n                image_mean = new Array(image.channels).fill(image_mean);\n            }\n\n            let image_std = this.image_std;\n            if (!Array.isArray(this.image_std)) {\n                image_std = new Array(image.channels).fill(image_mean);\n            }\n\n            if (image_mean.length !== image.channels || image_std.length !== image.channels) {\n                throw new Error(`When set to arrays, the length of \\`image_mean\\` (${image_mean.length}) and \\`image_std\\` (${image_std.length}) must match the number of channels in the image (${image.channels}).`);\n            }\n\n            for (let i = 0; i < pixelData.length; i += image.channels) {\n                for (let j = 0; j < image.channels; ++j) {\n                    pixelData[i + j] = (pixelData[i + j] - this.image_mean[j]) / this.image_std[j];\n                }\n            }\n        }\n\n        // convert to channel dimension format:\n        let imgDims = [image.height, image.width, image.channels];\n        let img = new Tensor('float32', pixelData, imgDims);\n        let transposed = transpose(img, [2, 0, 1]); // hwc -> chw\n\n        return {\n            original_size: [srcHeight, srcWidth],\n            reshaped_input_size: reshaped_input_size,\n            pixel_values: transposed,\n        }\n    }\n\n    /**\n     * Calls the feature extraction process on an array of image\n     * URLs, preprocesses each image, and concatenates the resulting\n     * features into a single Tensor.\n     * @param {any} images The URL(s) of the image(s) to extract features from.\n     * @returns {Promise<Object>} An object containing the concatenated pixel values (and other metadata) of the preprocessed images.\n     */\n    async _call(images) {\n        if (!Array.isArray(images)) {\n            images = [images];\n        }\n\n        let imageData = await Promise.all(images.map(x => this.preprocess(x)));\n\n        // TODO:\n\n        // Concatenate pixel values\n        // TEMP: Add batch dimension so that concat works\n        imageData.forEach(x => x.pixel_values.dims = [1, ...x.pixel_values.dims]);\n        let pixel_values = cat(imageData.map(x => x.pixel_values));\n\n        return {\n            pixel_values: pixel_values,\n\n            // Original sizes of images\n            original_sizes: imageData.map(x => x.original_size),\n\n            // Reshaped sizes of images, before padding or cropping\n            reshaped_input_sizes: imageData.map(x => x.reshaped_input_size),\n        }\n    }\n\n}\n\nexport class ViTFeatureExtractor extends ImageFeatureExtractor { }\n\n/**\n * Detr Feature Extractor.\n *\n * @extends ImageFeatureExtractor\n */\nexport class DetrFeatureExtractor extends ImageFeatureExtractor {\n    /**\n     * Calls the feature extraction process on an array of image\n     * URLs, preprocesses each image, and concatenates the resulting\n     * features into a single Tensor.\n     * @param {any} urls The URL(s) of the image(s) to extract features from.\n     * @returns {Promise<Object>} An object containing the concatenated pixel values of the preprocessed images.\n     */\n    async _call(urls) {\n        let result = await super._call(urls);\n\n        // TODO support differently-sized images, for now assume all images are the same size.\n        // TODO support different mask sizes (not just 64x64)\n        // Currently, just fill pixel mask with 1s\n        let maskSize = [result.pixel_values.dims[0], 64, 64];\n        result.pixel_mask = new Tensor(\n            'int64',\n            // TODO: fix error below\n            new BigInt64Array(maskSize.reduce((a, b) => a * b)).fill(1n),\n            maskSize\n        );\n\n        return result;\n    }\n\n    /**\n     * @param {number[]} arr The URL(s) of the image(s) to extract features from.\n     * @returns {number[]} An object containing the concatenated pixel values of the preprocessed images.\n     */\n    center_to_corners_format([centerX, centerY, width, height]) {\n        return [\n            centerX - width / 2,\n            centerY - height / 2,\n            centerX + width / 2,\n            centerY + height / 2\n        ];\n    }\n\n    /**\n     * Post-processes the outputs of the model (for object detection).\n     * @param {Object} outputs The outputs of the model that must be post-processed\n     * @param {Tensor} outputs.logits The logits\n     * @param {Tensor} outputs.pred_boxes The predicted boxes.\n     * @return {Object[]} An array of objects containing the post-processed outputs.\n     */\n    post_process_object_detection(outputs, threshold = 0.5, target_sizes = null) {\n        const out_logits = outputs.logits;\n        const out_bbox = outputs.pred_boxes;\n        const [batch_size, num_boxes, num_classes] = out_logits.dims;\n\n        if (target_sizes !== null && target_sizes.length !== batch_size) {\n            throw Error(\"Make sure that you pass in as many target sizes as the batch dimension of the logits\")\n        }\n        let toReturn = [];\n        for (let i = 0; i < batch_size; ++i) {\n            let target_size = target_sizes !== null ? target_sizes[i] : null;\n            let info = {\n                boxes: [],\n                classes: [],\n                scores: []\n            }\n            let logits = out_logits[i];\n            let bbox = out_bbox[i];\n\n            for (let j = 0; j < num_boxes; ++j) {\n                let logit = logits[j];\n\n                // Get most probable class\n                let maxIndex = max(logit.data)[1];\n\n                if (maxIndex === num_classes - 1) {\n                    // This is the background class, skip it\n                    continue;\n                }\n\n                // Compute softmax over classes\n                let probs = softmax(logit.data);\n\n                let score = probs[maxIndex];\n                if (score > threshold) {\n                    // Some class has a high enough probability\n                    /** @type {number[]} */\n                    let box = bbox[j].data;\n\n                    // convert to [x0, y0, x1, y1] format\n                    box = this.center_to_corners_format(box)\n                    if (target_size !== null) {\n                        box = box.map((x, i) => x * target_size[(i + 1) % 2])\n                    }\n\n                    info.boxes.push(box);\n                    info.classes.push(maxIndex);\n                    info.scores.push(score);\n                }\n            }\n            toReturn.push(info);\n        }\n        return toReturn;\n    }\n\n    /**\n     * Binarize the given masks using `object_mask_threshold`, it returns the associated values of `masks`, `scores` and `labels`.\n     * @param {Tensor} class_logits The class logits.\n     * @param {Tensor} mask_logits The mask logits.\n     * @param {number} object_mask_threshold A number between 0 and 1 used to binarize the masks.\n     * @param {number} num_labels The number of labels.\n     * @returns {[Tensor[], number[], number[]]} The binarized masks, the scores, and the labels.\n     */\n    remove_low_and_no_objects(class_logits, mask_logits, object_mask_threshold, num_labels) {\n\n        let mask_probs_item = [];\n        let pred_scores_item = [];\n        let pred_labels_item = [];\n\n        for (let j = 0; j < class_logits.dims[0]; ++j) {\n            let cls = class_logits[j];\n            let mask = mask_logits[j];\n\n            let pred_label = max(cls.data)[1];\n            if (pred_label === num_labels) {\n                // Is the background, so we ignore it\n                continue;\n            }\n\n            let scores = softmax(cls.data);\n            let pred_score = scores[pred_label];\n            if (pred_score > object_mask_threshold) {\n                mask_probs_item.push(mask);\n                pred_scores_item.push(pred_score);\n                pred_labels_item.push(pred_label);\n            }\n        }\n\n        return [mask_probs_item, pred_scores_item, pred_labels_item];\n\n    }\n\n    /**\n     * Checks whether the segment is valid or not.\n     * @param {Int32Array} mask_labels Labels for each pixel in the mask.\n     * @param {Tensor[]} mask_probs Probabilities for each pixel in the masks.\n     * @param {number} k The class id of the segment.\n     * @param {number} mask_threshold The mask threshold.\n     * @param {number} overlap_mask_area_threshold The overlap mask area threshold.\n     * @returns {[boolean, number[]]} Whether the segment is valid or not, and the indices of the valid labels.\n     */\n    check_segment_validity(\n        mask_labels,\n        mask_probs,\n        k,\n        mask_threshold = 0.5,\n        overlap_mask_area_threshold = 0.8\n    ) {\n        // mask_k is a 1D array of indices, indicating where the mask is equal to k\n        let mask_k = [];\n        let mask_k_area = 0;\n        let original_area = 0;\n\n        // Compute the area of all the stuff in query k\n        for (let i = 0; i < mask_labels.length; ++i) {\n            if (mask_labels[i] === k) {\n                mask_k.push(i);\n                ++mask_k_area;\n            }\n\n            if (mask_probs[k].data[i] >= mask_threshold) {\n                ++original_area;\n            }\n        }\n        let mask_exists = mask_k_area > 0 && original_area > 0;\n\n        // Eliminate disconnected tiny segments\n        if (mask_exists) {\n            // Perform additional check\n            let area_ratio = mask_k_area / original_area;\n            mask_exists = area_ratio > overlap_mask_area_threshold;\n        }\n\n        return [mask_exists, mask_k]\n    }\n\n    /**\n     * Computes the segments.\n     * @param {Tensor[]} mask_probs The mask probabilities.\n     * @param {number[]} pred_scores The predicted scores.\n     * @param {number[]} pred_labels The predicted labels.\n     * @param {number} mask_threshold The mask threshold.\n     * @param {number} overlap_mask_area_threshold The overlap mask area threshold.\n     * @param {Set<number>} label_ids_to_fuse The label ids to fuse.\n     * @param {number[]} target_size The target size of the image.\n     * @returns {[Tensor, Array<{id: number, label_id: number, score: number}>]} The computed segments.\n     */\n    compute_segments(\n        mask_probs,\n        pred_scores,\n        pred_labels,\n        mask_threshold,\n        overlap_mask_area_threshold,\n        label_ids_to_fuse = null,\n        target_size = null,\n    ) {\n        let [height, width] = target_size ?? mask_probs[0].dims;\n\n        let segmentation = new Tensor(\n            'int32',\n            new Int32Array(height * width),\n            [height, width]\n        );\n        let segments = [];\n\n        // 1. If target_size is not null, we need to resize the masks to the target size\n        if (target_size !== null) {\n            // resize the masks to the target size\n            for (let i = 0; i < mask_probs.length; ++i) {\n                mask_probs[i] = interpolate(mask_probs[i], target_size, 'bilinear', false);\n            }\n        }\n\n        // 2. Weigh each mask by its prediction score\n        // NOTE: `mask_probs` is updated in-place\n        // \n        // Temporary storage for the best label/scores for each pixel ([height, width]):\n        let mask_labels = new Int32Array(mask_probs[0].data.length);\n        let bestScores = new Float32Array(mask_probs[0].data.length);\n\n        for (let i = 0; i < mask_probs.length; ++i) {\n            let score = pred_scores[i];\n\n            for (let j = 0; j < mask_probs[i].data.length; ++j) {\n                mask_probs[i].data[j] *= score\n                if (mask_probs[i].data[j] > bestScores[j]) {\n                    mask_labels[j] = i;\n                    bestScores[j] = mask_probs[i].data[j];\n                }\n            }\n        }\n\n        let current_segment_id = 0;\n\n        // let stuff_memory_list = {}\n        for (let k = 0; k < pred_labels.length; ++k) {\n            let pred_class = pred_labels[k];\n\n            // TODO add `should_fuse`\n            // let should_fuse = pred_class in label_ids_to_fuse\n\n            // Check if mask exists and large enough to be a segment\n            let [mask_exists, mask_k] = this.check_segment_validity(\n                mask_labels,\n                mask_probs,\n                k,\n                mask_threshold,\n                overlap_mask_area_threshold\n            )\n\n            if (!mask_exists) {\n                // Nothing to see here\n                continue;\n            }\n\n            // TODO\n            // if (pred_class in stuff_memory_list) {\n            //     current_segment_id = stuff_memory_list[pred_class]\n            // } else {\n            //     current_segment_id += 1;\n            // }\n            ++current_segment_id;\n\n\n            // Add current object segment to final segmentation map\n            for (let index of mask_k) {\n                segmentation.data[index] = current_segment_id;\n            }\n\n            segments.push({\n                id: current_segment_id,\n                label_id: pred_class,\n                // was_fused: should_fuse, TODO\n                score: pred_scores[k],\n            })\n\n            // TODO\n            // if(should_fuse){\n            //     stuff_memory_list[pred_class] = current_segment_id\n            // }\n        }\n\n        return [segmentation, segments];\n    }\n\n    /**\n     * Post-process the model output to generate the final panoptic segmentation.\n     * @param {*} outputs The model output to post process\n     * @param {number} [threshold=0.5] The probability score threshold to keep predicted instance masks.\n     * @param {number} [mask_threshold=0.5] Threshold to use when turning the predicted masks into binary values.\n     * @param {number} [overlap_mask_area_threshold=0.8] The overlap mask area threshold to merge or discard small disconnected parts within each binary instance mask.\n     * @param {Set<number>} [label_ids_to_fuse=null] The labels in this state will have all their instances be fused together.\n     * @param {number[][]} [target_sizes=null] The target sizes to resize the masks to.\n     * @returns {Array<{ segmentation: Tensor, segments_info: Array<{id: number, label_id: number, score: number}>}>}\n     */\n    post_process_panoptic_segmentation(\n        outputs,\n        threshold = 0.5,\n        mask_threshold = 0.5,\n        overlap_mask_area_threshold = 0.8,\n        label_ids_to_fuse = null,\n        target_sizes = null,\n    ) {\n        if (label_ids_to_fuse === null) {\n            console.warn(\"`label_ids_to_fuse` unset. No instance will be fused.\")\n            label_ids_to_fuse = new Set();\n        }\n\n        const class_queries_logits = outputs.logits; // [batch_size, num_queries, num_classes+1]\n        const masks_queries_logits = outputs.pred_masks; // [batch_size, num_queries, height, width]\n\n        const mask_probs = masks_queries_logits.sigmoid()  // [batch_size, num_queries, height, width]\n\n        let [batch_size, num_queries, num_labels] = class_queries_logits.dims;\n        num_labels -= 1; // Remove last class (background)\n\n        if (target_sizes !== null && target_sizes.length !== batch_size) {\n            throw Error(\"Make sure that you pass in as many target sizes as the batch dimension of the logits\")\n        }\n\n        let toReturn = [];\n        for (let i = 0; i < batch_size; ++i) {\n            let target_size = target_sizes !== null ? target_sizes[i] : null;\n\n            let class_logits = class_queries_logits[i];\n            let mask_logits = mask_probs[i];\n\n            let [mask_probs_item, pred_scores_item, pred_labels_item] = this.remove_low_and_no_objects(class_logits, mask_logits, threshold, num_labels);\n\n            if (pred_labels_item.length === 0) {\n                // No mask found\n                let [height, width] = target_size ?? mask_logits.dims.slice(-2);\n\n                let segmentation = new Tensor(\n                    'int32',\n                    new Int32Array(height * width).fill(-1),\n                    [height, width]\n                )\n                toReturn.push({\n                    segmentation: segmentation,\n                    segments_info: []\n                });\n                continue;\n            }\n\n\n            // Get segmentation map and segment information of batch item\n            let [segmentation, segments] = this.compute_segments(\n                mask_probs_item,\n                pred_scores_item,\n                pred_labels_item,\n                mask_threshold,\n                overlap_mask_area_threshold,\n                label_ids_to_fuse,\n                target_size,\n            )\n\n            toReturn.push({\n                segmentation: segmentation,\n                segments_info: segments\n            })\n        }\n\n        return toReturn;\n    }\n\n    post_process_instance_segmentation() {\n        // TODO\n        throw Error(\"Not implemented yet\");\n    }\n}\n\nexport class SamImageProcessor extends ImageFeatureExtractor {\n    async _call(images, input_points) {\n        let {\n            pixel_values,\n            original_sizes,\n            reshaped_input_sizes,\n        } = await super._call(images);\n\n        let shape = calculateDimensions(input_points);\n\n        if (shape.length === 3) {\n            // Correct user's input\n            shape = [1, ...shape];\n            input_points = [input_points];\n        } else if (shape.length !== 4) {\n            throw Error(\"The input_points must be a 4D tensor of shape `batch_size`, `point_batch_size`, `nb_points_per_image`, `2`.\")\n        }\n\n        // Reshape input points\n        for (let i = 0; i < input_points.length; ++i) { // batch_size\n            let originalImageSize = original_sizes[i];\n            let reshapedImageSize = reshaped_input_sizes[i];\n\n            let resizeFactors = [\n                reshapedImageSize[0] / originalImageSize[0],\n                reshapedImageSize[1] / originalImageSize[1]\n            ]\n\n            for (let j = 0; j < input_points[i].length; ++j) { // point_batch_size\n                for (let k = 0; k < input_points[i][j].length; ++k) { // nb_points_per_image\n                    for (let w = 0; w < input_points[i][j][k].length; ++w) { // 2\n                        input_points[i][j][k][w] *= resizeFactors[w];\n                    }\n                }\n            }\n        }\n\n        let input_points_tensor = new Tensor(\n            'int64',\n            BigInt64Array.from(input_points.flat(Infinity)\n                .map(x => BigInt(Math.round(x)))),\n            shape\n        )\n\n        // TODO: allowed to be floats?\n        // let input_points_tensor = new Tensor(\n        //     'float32',\n        //     Float32Array.from(input_points.flat(Infinity)),\n        //     shape\n        // )\n\n        return {\n            pixel_values,\n            original_sizes: original_sizes,\n            reshaped_input_sizes: reshaped_input_sizes,\n            input_points: input_points_tensor\n        }\n    }\n\n    /**\n     * Remove padding and upscale masks to the original image size.\n     * @param {Tensor} masks Batched masks from the mask_decoder in (batch_size, num_channels, height, width) format.\n     * @param {number[][]} original_sizes The original sizes of each image before it was resized to the model's expected input shape, in (height, width) format.\n     * @param {number[][]} reshaped_input_sizes The size of each image as it is fed to the model, in (height, width) format. Used to remove padding.\n     * @param {Object} options Optional parameters for post-processing.\n     * @param {number} [options.mask_threshold] The threshold to use for binarizing the masks.\n     * @param {boolean} [options.binarize] Whether to binarize the masks.\n     * @param {Object} [options.pad_size] The target size the images were padded to before being passed to the model. If `null`, the target size is assumed to be the processor's `pad_size`.\n     * @param {number} [options.pad_size.height] The height the images were padded to.\n     * @param {number} [options.pad_size.width] The width the images were padded to.\n     * @returns {Tensor[]} Batched masks in batch_size, num_channels, height, width) format, where (height, width) is given by original_size.\n     */\n    post_process_masks(masks, original_sizes, reshaped_input_sizes, {\n        mask_threshold = 0.0,\n        binarize = true,\n        pad_size = null,\n    } = {}) {\n        // masks: [1, 1, 3, 256, 256]\n\n        let output_masks = [];\n\n        pad_size = pad_size ?? this.pad_size;\n\n        let target_image_size = [pad_size.height, pad_size.width];\n\n        for (let i = 0; i < original_sizes.length; ++i) {\n            let original_size = original_sizes[i];\n            let reshaped_input_size = reshaped_input_sizes[i];\n\n            let mask = masks[i]; // [b, c, h, w]\n\n            // TODO: improve\n            let interpolated_masks = [];\n            for (let j = 0; j < mask.dims[0]; ++j) {\n                let m = mask[j]; // 3d tensor\n\n                // Upscale mask to padded size\n                let interpolated_mask = interpolate(m, target_image_size, 'bilinear', false);\n\n                // Crop mask\n                interpolated_mask = interpolated_mask.slice(null, [0, reshaped_input_size[0]], [0, reshaped_input_size[1]]);\n\n                // Downscale mask\n                interpolated_mask = interpolate(mask, original_size, 'bilinear', false);\n\n                if (binarize) {\n                    interpolated_mask = new Tensor(\n                        'bool',\n                        Array.from(interpolated_mask.data).map(x => x > mask_threshold),\n                        interpolated_mask.dims\n                    )\n                }\n\n                // add back batch dim for concat\n                interpolated_mask.dims = [1, ...interpolated_mask.dims];\n\n                interpolated_masks.push(interpolated_mask);\n            }\n\n            let concatenated = cat(interpolated_masks);\n            output_masks.push(concatenated);\n        }\n\n        return output_masks;\n\n    }\n}\n\n\nexport class WhisperFeatureExtractor extends FeatureExtractor {\n\n    constructor(config) {\n        super(config);\n\n        // Prefer given `mel_filters` from preprocessor_config.json, or calculate them if they don't exist.\n        this.config.mel_filters ??= getMelFilters(this.config.sampling_rate, this.config.n_fft, this.config.feature_size);\n    }\n    /**\n     * Calculates the index offset for a given index and window size.\n     * @param {number} i The index.\n     * @param {number} w The window size.\n     * @returns {number} The index offset.\n     */\n    calcOffset(i, w) {\n        return Math.abs((i + w) % (2 * w) - w);\n    }\n\n    /**\n     * Pads an array with a reflected version of itself on both ends.\n     * @param {Float32Array} array The array to pad.\n     * @param {number} left The amount of padding to add to the left.\n     * @param {number} right The amount of padding to add to the right.\n     * @returns {Float32Array} The padded array.\n     */\n    padReflect(array, left, right) {\n        const padded = new Float32Array(array.length + left + right);\n        const w = array.length - 1;\n\n        for (let i = 0; i < array.length; ++i) {\n            padded[left + i] = array[i];\n        }\n\n        for (let i = 1; i <= left; ++i) {\n            padded[left - i] = array[this.calcOffset(i, w)];\n        }\n\n        for (let i = 1; i <= right; ++i) {\n            padded[w + left + i] = array[this.calcOffset(w - i, w)];\n        }\n\n        return padded;\n    }\n\n    /**\n     * Calculates the complex Short-Time Fourier Transform (STFT) of the given framed signal.\n     * \n     * @param {number[][]} frames A 2D array representing the signal frames.\n     * @param {number[]} window A 1D array representing the window to be applied to the frames.\n     * @returns {Object} An object with the following properties:\n     * - data: A 1D array representing the complex STFT of the signal.\n     * - dims: An array representing the dimensions of the STFT data, i.e. [num_frames, num_fft_bins].\n     */\n    stft(frames, window) {\n        // Calculates the complex Short-Time Fourier Transform (STFT) of the given framed signal.\n        // \n        // NOTE: Since the window width is not a power of 2, we must \n        // perform Fast Fourier Transform with chirp-z transform:\n        // https://math.stackexchange.com/questions/77118/non-power-of-2-ffts/77156#77156\n\n        // Helper variables\n        const fft_size = this.config.n_fft;\n        const a = 2 * (fft_size - 1);\n        const b = 2 * (2 * fft_size - 1);\n        const nextP2 = 2 ** (Math.ceil(Math.log2(b)))\n        const num_fft_bins = fft_size + 2;\n\n        // Preallocate array to store output\n        // double since we store complex numbers\n        const data = new Float32Array(num_fft_bins * frames.length);\n\n        // Define buffers\n        // Compute chirp for transform\n        const chirp = new Float32Array(b);\n        const ichirp = new Float32Array(nextP2);\n        const buffer1 = new Float32Array(nextP2);\n        const buffer2 = new Float32Array(nextP2);\n        const outBuffer = new Float32Array(nextP2);\n        const outBuffer2 = new Float32Array(nextP2);\n        const outBuffer3 = new Float32Array(nextP2);\n\n        // Compute complex exponentiation\n        const theta = -2 * Math.PI / fft_size;\n        const baseR = Math.cos(theta);\n        const baseI = Math.sin(theta);\n\n        // Precompute helper for chirp-z transform\n        for (let i = 0; i < b >> 1; ++i) {\n            // Compute complex power:\n            const e = (i + 1 - fft_size) ** 2 / 2.0;\n\n            // Compute the modulus and argument of the result\n            const result_mod = Math.sqrt(baseR ** 2 + baseI ** 2) ** e;\n            const result_arg = e * Math.atan2(baseI, baseR);\n\n            // Convert the result back to rectangular form\n            // and assign to chirp and ichirp\n            let i2 = 2 * i;\n            chirp[i2] = result_mod * Math.cos(result_arg);\n            chirp[i2 + 1] = result_mod * Math.sin(result_arg);\n\n            // conjugate\n            ichirp[i2] = chirp[i2];\n            ichirp[i2 + 1] = - chirp[i2 + 1];\n        }\n        const slicedChirp = chirp.subarray(a, b);\n\n        // create object to perform Fast Fourier Transforms\n        // with `nextP2` complex numbers\n        const f = new FFT(nextP2 >> 1);\n        // TODO: decide between Float32Array and Float64Array\n        f.transform(outBuffer, ichirp);\n\n        for (let i = 0; i < frames.length; ++i) {\n            const frame = frames[i];\n\n            for (let j = 0; j < slicedChirp.length; j += 2) {\n                const j2 = j + 1\n                const j3 = j >> 1;\n\n                const a_real = frame[j3] * window[j3];\n                buffer1[j] = a_real * slicedChirp[j];\n                buffer1[j2] = a_real * slicedChirp[j2];\n            }\n            // TODO: decide between Float32Array and Float64Array\n            f.transform(outBuffer2, buffer1);\n\n            for (let j = 0; j < outBuffer.length; j += 2) {\n                const j2 = j + 1;\n\n                buffer2[j] = outBuffer2[j] * outBuffer[j] - outBuffer2[j2] * outBuffer[j2]\n                buffer2[j2] = outBuffer2[j] * outBuffer[j2] + outBuffer2[j2] * outBuffer[j]\n            }\n            // TODO: decide between Float32Array and Float64Array\n            f.inverseTransform(outBuffer3, buffer2)\n\n            const offset = i * num_fft_bins;\n            for (let j = 0; j < num_fft_bins; j += 2) {\n                const a_real = outBuffer3[j + a];\n                const a_imag = outBuffer3[j + a + 1];\n                const b_real = slicedChirp[j];\n                const b_imag = slicedChirp[j + 1];\n\n                // TODO write as transpose\n                const o1 = offset + j;\n                data[o1] = a_real * b_real - a_imag * b_imag\n                data[o1 + 1] = a_real * b_imag + a_imag * b_real\n            }\n        }\n\n        return {\n            data: data,\n            dims: [frames.length, num_fft_bins] // [3001, 402]\n        };\n    }\n\n    /**\n     * Creates an array of frames from a given waveform.\n     *\n     * @param {Float32Array} waveform The waveform to create frames from.\n     * @param {boolean} [center=true] Whether to center the frames on their corresponding positions in the waveform. Defaults to true.\n     * @returns {Array} An array of frames.\n     */\n    fram_wave(waveform, center = true) {\n        const frames = [];\n        const half_window = Math.floor((this.config.n_fft - 1) / 2) + 1;\n        const waveformLength = waveform.length;\n\n        for (let i = 0; i < waveformLength + 1; i += this.config.hop_length) {\n\n            let frame;\n            if (center) {\n\n                let frameStart = i > half_window ? i - half_window : 0;\n                let frameEnd =\n                    i < waveformLength - half_window\n                        ? i + half_window\n                        : waveformLength;\n\n                frame = waveform.subarray(frameStart, frameEnd)\n\n                if (frameStart === 0) {\n                    frame = this.padReflect(\n                        frame,\n                        -i + half_window,\n                        0\n                    )\n\n                } else if (frameEnd === waveformLength) {\n                    frame = this.padReflect(\n                        frame,\n                        0,\n                        i - waveformLength + half_window\n                    )\n                }\n\n            } else {\n                frame = new Float32Array(this.config.n_fft);\n                const frameArray = waveform.subarray(i, i + this.config.n_fft);\n\n                if (frameArray.length < this.config.n_fft) {\n                    frame.set(frameArray);\n                    frame.fill(0, frameArray.length, this.config.n_fft)\n                } else {\n                    frame = frameArray;\n                }\n\n            }\n            frames.push(frame);\n        }\n\n        return frames;\n    }\n\n    /**\n     * Generates a Hanning window of length M.\n     *\n     * @param {number} M The length of the Hanning window to generate.\n     * @returns {*} The generated Hanning window.\n     */\n    hanning(M) {\n        if (M < 1) {\n            return [];\n        }\n        if (M === 1) {\n            return [1];\n        }\n        const denom = M - 1;\n        const cos_vals = new Float32Array(denom);\n        for (let i = 0; i < denom; ++i) {\n            const n = 2 * i - M + 1;\n            cos_vals[i] = 0.5 + 0.5 * Math.cos(Math.PI * n / denom);\n        }\n        return cos_vals;\n    }\n\n    /**\n     * Computes the log-Mel spectrogram of the provided audio waveform.\n     * @param {Float32Array} waveform The audio waveform to process.\n     * @returns {{data: Float32Array, dims: number[]}} An object containing the log-Mel spectrogram data as a Float32Array and its dimensions as an array of numbers.\n     */\n    _extract_fbank_features(waveform) {\n        // Compute the log-Mel spectrogram of the provided audio\n\n        const buffer = new Float32Array(this.config.n_samples);\n        buffer.set(waveform)\n\n        const window = this.hanning(this.config.n_fft + 1)\n        const frames = this.fram_wave(buffer)\n\n        const stft = this.stft(frames, window)\n\n        const stftData = stft.data;\n        const d1 = stft.dims[0] - 1; // Ignore last row\n        const d2 = stft.dims[1] >> 1; // Only need to store real numbers now\n\n        // compute magnitudes\n        // NOTE: Unlinke the original implementation, we do not\n        // transpose since we perform matrix multiplication later\n        const magnitudes = new Float32Array(d1 * d2);\n        for (let i = 0; i < d1; ++i) {\n            for (let j = 0; j < d2; ++j) {\n                // let outOffset = (j * d1 + i); // transpose\n                let outOffset = i * d2 + j;\n                let inOffset = outOffset << 1; // * 2 since complex\n                let magnitude = stftData[inOffset] ** 2 + stftData[inOffset + 1] ** 2\n                magnitudes[outOffset] = magnitude;\n            }\n        }\n\n        const mel_filters = this.config.mel_filters;\n        const num_mel_filters = mel_filters.length;\n\n        const mel_spec = new Float32Array(num_mel_filters * d1);\n        let mIndex = 0;\n\n        // Perform matrix muliplication:\n        // mel_spec = filters @ magnitudes\n        //  - filters.shape=(80, 201)\n        //  - magnitudes.shape=(201, 3000)\n        //  - mel_spec.shape=(80, 3000)\n        for (let i = 0; i < num_mel_filters; ++i) {\n            const mel_filter = mel_filters[i];\n\n            for (let j = 0; j < d1; ++j) {\n                let sum = 0;\n\n                // perform dot product\n                for (let k = 0; k < d2; ++k) {\n                    sum += mel_filter[k] * magnitudes[j * d2 + k];\n                }\n\n                mel_spec[mIndex++] = sum;\n            }\n        }\n\n        const a_min = 1e-10;\n        const log_spec = new Float32Array(mel_spec.length);\n\n        let maxLogSpec = 0;\n        for (let i = 0; i < mel_spec.length; ++i) {\n            const clipped = Math.max(a_min, mel_spec[i]);\n            const log10 = Math.log10(clipped);\n            log_spec[i] = log10;\n            maxLogSpec = Math.max(log10, maxLogSpec)\n        }\n\n        for (let i = 0; i < log_spec.length; ++i) {\n            log_spec[i] = Math.max(log_spec[i], maxLogSpec - 8);\n            log_spec[i] = (log_spec[i] + 4) / 4;\n        }\n\n        return {\n            data: log_spec,\n            dims: [num_mel_filters, d1]\n        };\n    }\n\n    /**\n     * Asynchronously extracts features from a given audio using the provided configuration.\n     * @param {Float32Array} audio The audio data as a Float32Array.\n     * @returns {Promise<{ input_features: Tensor }>} A Promise resolving to an object containing the extracted input features as a Tensor.\n    */\n    async _call(audio) {\n        // audio is a float32array\n\n        if (audio.length > this.config.n_samples) {\n            console.warn(\n                \"Attempting to extract features for audio longer than 30 seconds. \" +\n                \"If using a pipeline to extract transcript from a long audio clip, \" +\n                \"remember to specify `chunk_length_s` and/or `stride_length_s`.\"\n            );\n        }\n        let waveform = audio.slice(0, this.config.n_samples);\n\n        let features = this._extract_fbank_features(waveform);\n\n        return {\n            input_features: new Tensor('float32',\n                features.data,\n                [1, ...features.dims]\n            )\n        };\n    }\n}\n\n/**\n * Represents a Processor that extracts features from an input.\n * @extends Callable\n */\nexport class Processor extends Callable {\n    /**\n     * Creates a new Processor with the given feature extractor.\n     * @param {FeatureExtractor} feature_extractor The function used to extract features from the input.\n     */\n    constructor(feature_extractor) {\n        super();\n        this.feature_extractor = feature_extractor;\n        // TODO use tokenizer here?\n    }\n\n    /**\n     * Calls the feature_extractor function with the given input.\n     * @param {any} input The input to extract features from.\n     * @returns {Promise<any>} A Promise that resolves with the extracted features.\n     */\n    async _call(input) {\n        return await this.feature_extractor(input);\n    }\n}\n\nexport class SamProcessor extends Processor {\n\n    async _call(images, input_points) {\n        return await this.feature_extractor(images, input_points);\n    }\n\n    /**\n     * @borrows SamImageProcessor#post_process_masks as post_process_masks\n     */\n    post_process_masks(...args) {\n        // @ts-ignore\n        return this.feature_extractor.post_process_masks(...args);\n    }\n}\n\n/**\n * Represents a WhisperProcessor that extracts features from an audio input.\n * @extends Processor\n */\nexport class WhisperProcessor extends Processor {\n    /**\n     * Calls the feature_extractor function with the given audio input.\n     * @param {any} audio The audio input to extract features from.\n     * @returns {Promise<any>} A Promise that resolves with the extracted features.\n     */\n    async _call(audio) {\n        return await this.feature_extractor(audio)\n    }\n}\n\n//////////////////////////////////////////////////\n/**\n * @typedef {import('./utils/hub.js').PretrainedOptions} PretrainedOptions\n */\n/**\n * Helper class which is used to instantiate pretrained processors with the `from_pretrained` function.\n * The chosen processor class is determined by the type specified in the processor config.\n * \n * **Example:** Load a processor using `from_pretrained`.\n * ```javascript\n * let processor = await AutoProcessor.from_pretrained('openai/whisper-tiny.en');\n * ```\n * \n * **Example:** Run an image through a processor.\n * ```javascript\n * let processor = await AutoProcessor.from_pretrained('Xenova/clip-vit-base-patch16');\n * let image = await RawImage.read('https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/football-match.jpg');\n * let image_inputs = await processor(image);\n * // {\n * //   \"pixel_values\": {\n * //     \"dims\": [ 1, 3, 224, 224 ],\n * //     \"type\": \"float32\",\n * //     \"data\": Float32Array [ -1.558687686920166, -1.558687686920166, -1.5440893173217773, ... ],\n * //     \"size\": 150528\n * //   },\n * //   \"original_sizes\": [\n * //     [ 533, 800 ]\n * //   ],\n * //   \"reshaped_input_sizes\": [\n * //     [ 224, 224 ]\n * //   ]\n * // }\n * ```\n */\nexport class AutoProcessor {\n    static FEATURE_EXTRACTOR_CLASS_MAPPING = {\n        'WhisperFeatureExtractor': WhisperFeatureExtractor,\n        'ViTFeatureExtractor': ViTFeatureExtractor,\n        'DetrFeatureExtractor': DetrFeatureExtractor,\n\n        'SamImageProcessor': SamImageProcessor,\n    }\n\n    static PROCESSOR_CLASS_MAPPING = {\n        'WhisperProcessor': WhisperProcessor,\n        'SamProcessor': SamProcessor,\n    }\n\n    /**\n     * Instantiate one of the processor classes of the library from a pretrained model.\n     * \n     * The processor class to instantiate is selected based on the `feature_extractor_type` property of the config object\n     * (either passed as an argument or loaded from `pretrained_model_name_or_path` if possible)\n     * \n     * @param {string} pretrained_model_name_or_path The name or path of the pretrained model. Can be either:\n     * - A string, the *model id* of a pretrained processor hosted inside a model repo on huggingface.co.\n     *   Valid model ids can be located at the root-level, like `bert-base-uncased`, or namespaced under a\n     *   user or organization name, like `dbmdz/bert-base-german-cased`.\n     * - A path to a *directory* containing processor files, e.g., `./my_model_directory/`.\n     * @param {PretrainedOptions} options Additional options for loading the processor.\n     * \n     * @returns {Promise<Processor>} A new instance of the Processor class.\n     */\n    static async from_pretrained(pretrained_model_name_or_path, {\n        progress_callback = null,\n        config = null,\n        cache_dir = null,\n        local_files_only = false,\n        revision = 'main',\n    } = {}) {\n\n        let preprocessorConfig = config ?? await getModelJSON(pretrained_model_name_or_path, 'preprocessor_config.json', true, {\n            progress_callback,\n            config,\n            cache_dir,\n            local_files_only,\n            revision,\n        })\n\n        // Determine feature extractor class\n        // TODO: Ensure backwards compatibility with old configs\n        let key = preprocessorConfig.feature_extractor_type ?? preprocessorConfig.image_processor_type;\n        let feature_extractor_class = this.FEATURE_EXTRACTOR_CLASS_MAPPING[key];\n\n        if (!feature_extractor_class) {\n            if (preprocessorConfig.size !== undefined) {\n                // Assume ImageFeatureExtractor\n                console.warn('Feature extractor type not specified, assuming ImageFeatureExtractor due to size parameter in config.');\n                feature_extractor_class = ImageFeatureExtractor;\n            } else {\n                throw new Error(`Unknown Feature Extractor type: ${preprocessorConfig.feature_extractor_type}`);\n            }\n        }\n\n        // If no associated processor class, use default\n        let processor_class = this.PROCESSOR_CLASS_MAPPING[preprocessorConfig.processor_class] ?? Processor;\n\n        // Instantiate processor and feature extractor\n        let feature_extractor = new feature_extractor_class(preprocessorConfig);\n        return new processor_class(feature_extractor);\n    }\n}\n//////////////////////////////////////////////////\n\n"],"mappings":"AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SACIA,QAAQ,EACRC,mBAAmB,QAChB,iBAAiB;AAExB,SACIC,YAAY,QACT,gBAAgB;AAEvB,SACIC,GAAG,EACHC,OAAO,EACPC,GAAG,QACA,kBAAkB;AAGzB,SAASC,MAAM,EAAEC,SAAS,EAAEC,GAAG,EAAEC,WAAW,QAAQ,mBAAmB;AAEvE,SAASC,QAAQ,QAAQ,kBAAkB;AAC3C,SAASC,aAAa,QAAQ,kBAAkB;;AAGhD;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMC,gBAAgB,SAASZ,QAAQ,CAAC;EAC3C;AACJ;AACA;AACA;AACA;EACIa,WAAWA,CAACC,MAAM,EAAE;IAChB,KAAK,CAAC,CAAC;IACP,IAAI,CAACA,MAAM,GAAGA,MAAM;EACxB;AACJ;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMC,qBAAqB,SAASH,gBAAgB,CAAC;EAExD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACIC,WAAWA,CAACC,MAAM,EAAE;IAChB,KAAK,CAACA,MAAM,CAAC;IAEb,IAAI,CAACE,UAAU,GAAG,IAAI,CAACF,MAAM,CAACE,UAAU;IACxC,IAAI,CAACC,SAAS,GAAG,IAAI,CAACH,MAAM,CAACG,SAAS;IAEtC,IAAI,CAACC,QAAQ,GAAG,IAAI,CAACJ,MAAM,CAACI,QAAQ,IAAI,CAAC,CAAC,CAAC;IAC3C,IAAI,CAACC,UAAU,GAAG,IAAI,CAACL,MAAM,CAACK,UAAU,IAAI,IAAI;IAChD,IAAI,CAACC,cAAc,GAAG,IAAI,CAACN,MAAM,CAACM,cAAc,IAAK,CAAC,GAAG,GAAI;IAC7D,IAAI,CAACC,YAAY,GAAG,IAAI,CAACP,MAAM,CAACO,YAAY;IAE5C,IAAI,CAACC,SAAS,GAAG,IAAI,CAACR,MAAM,CAACQ,SAAS;IACtC,IAAI,CAACC,IAAI,GAAG,IAAI,CAACT,MAAM,CAACS,IAAI;IAE5B,IAAI,CAACC,cAAc,GAAG,IAAI,CAACV,MAAM,CAACU,cAAc;IAChD,IAAI,CAACC,SAAS,GAAG,IAAI,CAACX,MAAM,CAACW,SAAS;IACtC,IAAI,CAACC,cAAc,GAAG,IAAI,CAACZ,MAAM,CAACY,cAAc,IAAI,IAAI;IAExD,IAAI,CAACC,QAAQ,GAAG,IAAI,CAACb,MAAM,CAACa,QAAQ;IACpC,IAAI,CAACC,MAAM,GAAG,CAAC,IAAI,CAACd,MAAM,CAACc,MAAM,IAAI,KAAK,KAAK,IAAI,CAACD,QAAQ;EAChE;;EAEA;AACJ;AACA;AACA;AACA;AACA;EACI,MAAME,UAAUA,CAACC,KAAK,EAAE;IAEpB;IACA,IAAI,IAAI,CAACJ,cAAc,EAAE;MACrBI,KAAK,GAAGA,KAAK,CAACC,GAAG,CAAC,CAAC;IACvB;IAEA,MAAMC,QAAQ,GAAGF,KAAK,CAACG,KAAK,CAAC,CAAG;IAChC,MAAMC,SAAS,GAAGJ,KAAK,CAACK,MAAM,CAAC,CAAC;;IAEhC;IACA,IAAI,IAAI,CAACb,SAAS,EAAE;MAChB;MACA;;MAEA;MACA;;MAEA,IAAIc,aAAa;MACjB,IAAIC,YAAY;;MAEhB;MACA,IAAIC,MAAM,CAACC,SAAS,CAAC,IAAI,CAAChB,IAAI,CAAC,EAAE;QAC7Ba,aAAa,GAAG,IAAI,CAACb,IAAI;QACzBc,YAAY,GAAG,IAAI,CAACvB,MAAM,CAAC0B,QAAQ,IAAIJ,aAAa;MAExD,CAAC,MAAM;QACH;QACAA,aAAa,GAAG,IAAI,CAACb,IAAI,CAACa,aAAa;QACvCC,YAAY,GAAG,IAAI,CAACd,IAAI,CAACc,YAAY;MACzC;;MAEA;MACA;MACA,IAAID,aAAa,KAAKK,SAAS,IAAIJ,YAAY,KAAKI,SAAS,EAAE;QAC3D;QACA;QACA,MAAMC,iBAAiB,GAAGN,aAAa,KAAKK,SAAS,GAC/C,CAAC,CAAC;QAAA,EACFE,IAAI,CAACxC,GAAG,CAACiC,aAAa,GAAGJ,QAAQ,EAAEI,aAAa,GAAGF,SAAS,CAAC;QAEnE,MAAMU,QAAQ,GAAGZ,QAAQ,GAAGU,iBAAiB;QAC7C,MAAMG,SAAS,GAAGX,SAAS,GAAGQ,iBAAiB;;QAE/C;QACA;QACA,MAAMI,gBAAgB,GAAGT,YAAY,KAAKI,SAAS,GAC7C,CAAC,CAAC;QAAA,EACFE,IAAI,CAACI,GAAG,CAACV,YAAY,GAAGO,QAAQ,EAAEP,YAAY,GAAGQ,SAAS,CAAC;;QAEjE;QACAf,KAAK,GAAG,MAAMA,KAAK,CAACkB,MAAM,CAACL,IAAI,CAACM,KAAK,CAACL,QAAQ,GAAGE,gBAAgB,CAAC,EAAEH,IAAI,CAACM,KAAK,CAACJ,SAAS,GAAGC,gBAAgB,CAAC,EAAE;UAC1G5B,QAAQ,EAAE,IAAI,CAACA;QACnB,CAAC,CAAC;MAEN,CAAC,MAAM,IAAI,IAAI,CAACK,IAAI,CAACU,KAAK,KAAKQ,SAAS,IAAI,IAAI,CAAClB,IAAI,CAACY,MAAM,KAAKM,SAAS,EAAE;QACxE;QACAX,KAAK,GAAG,MAAMA,KAAK,CAACkB,MAAM,CAAC,IAAI,CAACzB,IAAI,CAACU,KAAK,EAAE,IAAI,CAACV,IAAI,CAACY,MAAM,EAAE;UAC1DjB,QAAQ,EAAE,IAAI,CAACA;QACnB,CAAC,CAAC;MACN,CAAC,MAAM;QACH,MAAM,IAAIgC,KAAK,CAAE,6EAA4EC,IAAI,CAACC,SAAS,CAAC,IAAI,CAAC7B,IAAI,CAAE,EAAC,CAAC;MAC7H;IACJ;IAEA,IAAI,IAAI,CAACC,cAAc,EAAE;MAErB,IAAI6B,UAAU;MACd,IAAIC,WAAW;MACf,IAAIhB,MAAM,CAACC,SAAS,CAAC,IAAI,CAACd,SAAS,CAAC,EAAE;QAClC4B,UAAU,GAAG,IAAI,CAAC5B,SAAS;QAC3B6B,WAAW,GAAG,IAAI,CAAC7B,SAAS;MAChC,CAAC,MAAM;QACH4B,UAAU,GAAG,IAAI,CAAC5B,SAAS,CAACQ,KAAK;QACjCqB,WAAW,GAAG,IAAI,CAAC7B,SAAS,CAACU,MAAM;MACvC;MAEAL,KAAK,GAAG,MAAMA,KAAK,CAACyB,WAAW,CAACF,UAAU,EAAEC,WAAW,CAAC;IAC5D;IAEA,IAAIE,mBAAmB,GAAG,CAAC1B,KAAK,CAACK,MAAM,EAAEL,KAAK,CAACG,KAAK,CAAC;;IAErD;IACA,IAAI,IAAI,CAACL,MAAM,EAAE;MACb,IAAI6B,IAAI,GAAG,CAAC;MACZ,IAAIC,KAAK,GAAG,IAAI,CAAC/B,QAAQ,CAACM,KAAK,GAAGH,KAAK,CAACG,KAAK;MAC7C,IAAI0B,GAAG,GAAG,CAAC;MACX,IAAIC,MAAM,GAAG,IAAI,CAACjC,QAAQ,CAACQ,MAAM,GAAGL,KAAK,CAACK,MAAM;MAEhDL,KAAK,GAAG,MAAMA,KAAK,CAAC+B,GAAG,CAAC,CAACJ,IAAI,EAAEC,KAAK,EAAEC,GAAG,EAAEC,MAAM,CAAC,CAAC;IACvD;IAEA,MAAME,SAAS,GAAGC,YAAY,CAACC,IAAI,CAAClC,KAAK,CAACmC,IAAI,CAAC;IAE/C,IAAI,IAAI,CAAC9C,UAAU,EAAE;MACjB,KAAK,IAAI+C,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGJ,SAAS,CAACK,MAAM,EAAE,EAAED,CAAC,EAAE;QACvCJ,SAAS,CAACI,CAAC,CAAC,GAAG,IAAI,CAAC9C,cAAc,GAAG0C,SAAS,CAACI,CAAC,CAAC;MACrD;IACJ;IAEA,IAAI,IAAI,CAAC7C,YAAY,EAAE;MACnB,IAAIL,UAAU,GAAG,IAAI,CAACA,UAAU;MAChC,IAAI,CAACoD,KAAK,CAACC,OAAO,CAAC,IAAI,CAACrD,UAAU,CAAC,EAAE;QACjCA,UAAU,GAAG,IAAIoD,KAAK,CAACtC,KAAK,CAACwC,QAAQ,CAAC,CAACC,IAAI,CAACvD,UAAU,CAAC;MAC3D;MAEA,IAAIC,SAAS,GAAG,IAAI,CAACA,SAAS;MAC9B,IAAI,CAACmD,KAAK,CAACC,OAAO,CAAC,IAAI,CAACpD,SAAS,CAAC,EAAE;QAChCA,SAAS,GAAG,IAAImD,KAAK,CAACtC,KAAK,CAACwC,QAAQ,CAAC,CAACC,IAAI,CAACvD,UAAU,CAAC;MAC1D;MAEA,IAAIA,UAAU,CAACmD,MAAM,KAAKrC,KAAK,CAACwC,QAAQ,IAAIrD,SAAS,CAACkD,MAAM,KAAKrC,KAAK,CAACwC,QAAQ,EAAE;QAC7E,MAAM,IAAIpB,KAAK,CAAE,qDAAoDlC,UAAU,CAACmD,MAAO,wBAAuBlD,SAAS,CAACkD,MAAO,qDAAoDrC,KAAK,CAACwC,QAAS,IAAG,CAAC;MAC1M;MAEA,KAAK,IAAIJ,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGJ,SAAS,CAACK,MAAM,EAAED,CAAC,IAAIpC,KAAK,CAACwC,QAAQ,EAAE;QACvD,KAAK,IAAIE,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG1C,KAAK,CAACwC,QAAQ,EAAE,EAAEE,CAAC,EAAE;UACrCV,SAAS,CAACI,CAAC,GAAGM,CAAC,CAAC,GAAG,CAACV,SAAS,CAACI,CAAC,GAAGM,CAAC,CAAC,GAAG,IAAI,CAACxD,UAAU,CAACwD,CAAC,CAAC,IAAI,IAAI,CAACvD,SAAS,CAACuD,CAAC,CAAC;QAClF;MACJ;IACJ;;IAEA;IACA,IAAIC,OAAO,GAAG,CAAC3C,KAAK,CAACK,MAAM,EAAEL,KAAK,CAACG,KAAK,EAAEH,KAAK,CAACwC,QAAQ,CAAC;IACzD,IAAII,GAAG,GAAG,IAAIpE,MAAM,CAAC,SAAS,EAAEwD,SAAS,EAAEW,OAAO,CAAC;IACnD,IAAIE,UAAU,GAAGpE,SAAS,CAACmE,GAAG,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;;IAE5C,OAAO;MACHE,aAAa,EAAE,CAAC1C,SAAS,EAAEF,QAAQ,CAAC;MACpCwB,mBAAmB,EAAEA,mBAAmB;MACxCqB,YAAY,EAAEF;IAClB,CAAC;EACL;;EAEA;AACJ;AACA;AACA;AACA;AACA;AACA;EACI,MAAMG,KAAKA,CAACC,MAAM,EAAE;IAChB,IAAI,CAACX,KAAK,CAACC,OAAO,CAACU,MAAM,CAAC,EAAE;MACxBA,MAAM,GAAG,CAACA,MAAM,CAAC;IACrB;IAEA,IAAIC,SAAS,GAAG,MAAMC,OAAO,CAACC,GAAG,CAACH,MAAM,CAACI,GAAG,CAACC,CAAC,IAAI,IAAI,CAACvD,UAAU,CAACuD,CAAC,CAAC,CAAC,CAAC;;IAEtE;;IAEA;IACA;IACAJ,SAAS,CAACK,OAAO,CAACD,CAAC,IAAIA,CAAC,CAACP,YAAY,CAACS,IAAI,GAAG,CAAC,CAAC,EAAE,GAAGF,CAAC,CAACP,YAAY,CAACS,IAAI,CAAC,CAAC;IACzE,IAAIT,YAAY,GAAGrE,GAAG,CAACwE,SAAS,CAACG,GAAG,CAACC,CAAC,IAAIA,CAAC,CAACP,YAAY,CAAC,CAAC;IAE1D,OAAO;MACHA,YAAY,EAAEA,YAAY;MAE1B;MACAU,cAAc,EAAEP,SAAS,CAACG,GAAG,CAACC,CAAC,IAAIA,CAAC,CAACR,aAAa,CAAC;MAEnD;MACAY,oBAAoB,EAAER,SAAS,CAACG,GAAG,CAACC,CAAC,IAAIA,CAAC,CAAC5B,mBAAmB;IAClE,CAAC;EACL;AAEJ;AAEA,OAAO,MAAMiC,mBAAmB,SAAS1E,qBAAqB,CAAC;;AAE/D;AACA;AACA;AACA;AACA;AACA,OAAO,MAAM2E,oBAAoB,SAAS3E,qBAAqB,CAAC;EAC5D;AACJ;AACA;AACA;AACA;AACA;AACA;EACI,MAAM+D,KAAKA,CAACa,IAAI,EAAE;IACd,IAAIC,MAAM,GAAG,MAAM,KAAK,CAACd,KAAK,CAACa,IAAI,CAAC;;IAEpC;IACA;IACA;IACA,IAAIE,QAAQ,GAAG,CAACD,MAAM,CAACf,YAAY,CAACS,IAAI,CAAC,CAAC,CAAC,EAAE,EAAE,EAAE,EAAE,CAAC;IACpDM,MAAM,CAACE,UAAU,GAAG,IAAIxF,MAAM,CAC1B,OAAO;IACP;IACA,IAAIyF,aAAa,CAACF,QAAQ,CAACG,MAAM,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKD,CAAC,GAAGC,CAAC,CAAC,CAAC,CAAC3B,IAAI,CAAC,EAAE,CAAC,EAC5DsB,QACJ,CAAC;IAED,OAAOD,MAAM;EACjB;;EAEA;AACJ;AACA;AACA;EACIO,wBAAwBA,CAAAC,IAAA,EAAoC;IAAA,IAAnC,CAACC,OAAO,EAAEC,OAAO,EAAErE,KAAK,EAAEE,MAAM,CAAC,GAAAiE,IAAA;IACtD,OAAO,CACHC,OAAO,GAAGpE,KAAK,GAAG,CAAC,EACnBqE,OAAO,GAAGnE,MAAM,GAAG,CAAC,EACpBkE,OAAO,GAAGpE,KAAK,GAAG,CAAC,EACnBqE,OAAO,GAAGnE,MAAM,GAAG,CAAC,CACvB;EACL;;EAEA;AACJ;AACA;AACA;AACA;AACA;AACA;EACIoE,6BAA6BA,CAACC,OAAO,EAAwC;IAAA,IAAtCC,SAAS,GAAAC,SAAA,CAAAvC,MAAA,QAAAuC,SAAA,QAAAjE,SAAA,GAAAiE,SAAA,MAAG,GAAG;IAAA,IAAEC,YAAY,GAAAD,SAAA,CAAAvC,MAAA,QAAAuC,SAAA,QAAAjE,SAAA,GAAAiE,SAAA,MAAG,IAAI;IACvE,MAAME,UAAU,GAAGJ,OAAO,CAACK,MAAM;IACjC,MAAMC,QAAQ,GAAGN,OAAO,CAACO,UAAU;IACnC,MAAM,CAACC,UAAU,EAAEC,SAAS,EAAEC,WAAW,CAAC,GAAGN,UAAU,CAACtB,IAAI;IAE5D,IAAIqB,YAAY,KAAK,IAAI,IAAIA,YAAY,CAACxC,MAAM,KAAK6C,UAAU,EAAE;MAC7D,MAAM9D,KAAK,CAAC,sFAAsF,CAAC;IACvG;IACA,IAAIiE,QAAQ,GAAG,EAAE;IACjB,KAAK,IAAIjD,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG8C,UAAU,EAAE,EAAE9C,CAAC,EAAE;MACjC,IAAIkD,WAAW,GAAGT,YAAY,KAAK,IAAI,GAAGA,YAAY,CAACzC,CAAC,CAAC,GAAG,IAAI;MAChE,IAAImD,IAAI,GAAG;QACPC,KAAK,EAAE,EAAE;QACTC,OAAO,EAAE,EAAE;QACXC,MAAM,EAAE;MACZ,CAAC;MACD,IAAIX,MAAM,GAAGD,UAAU,CAAC1C,CAAC,CAAC;MAC1B,IAAIuD,IAAI,GAAGX,QAAQ,CAAC5C,CAAC,CAAC;MAEtB,KAAK,IAAIM,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGyC,SAAS,EAAE,EAAEzC,CAAC,EAAE;QAChC,IAAIkD,KAAK,GAAGb,MAAM,CAACrC,CAAC,CAAC;;QAErB;QACA,IAAImD,QAAQ,GAAGxH,GAAG,CAACuH,KAAK,CAACzD,IAAI,CAAC,CAAC,CAAC,CAAC;QAEjC,IAAI0D,QAAQ,KAAKT,WAAW,GAAG,CAAC,EAAE;UAC9B;UACA;QACJ;;QAEA;QACA,IAAIU,KAAK,GAAGxH,OAAO,CAACsH,KAAK,CAACzD,IAAI,CAAC;QAE/B,IAAI4D,KAAK,GAAGD,KAAK,CAACD,QAAQ,CAAC;QAC3B,IAAIE,KAAK,GAAGpB,SAAS,EAAE;UACnB;UACA;UACA,IAAIqB,GAAG,GAAGL,IAAI,CAACjD,CAAC,CAAC,CAACP,IAAI;;UAEtB;UACA6D,GAAG,GAAG,IAAI,CAAC3B,wBAAwB,CAAC2B,GAAG,CAAC;UACxC,IAAIV,WAAW,KAAK,IAAI,EAAE;YACtBU,GAAG,GAAGA,GAAG,CAAC3C,GAAG,CAAC,CAACC,CAAC,EAAElB,CAAC,KAAKkB,CAAC,GAAGgC,WAAW,CAAC,CAAClD,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC;UACzD;UAEAmD,IAAI,CAACC,KAAK,CAACS,IAAI,CAACD,GAAG,CAAC;UACpBT,IAAI,CAACE,OAAO,CAACQ,IAAI,CAACJ,QAAQ,CAAC;UAC3BN,IAAI,CAACG,MAAM,CAACO,IAAI,CAACF,KAAK,CAAC;QAC3B;MACJ;MACAV,QAAQ,CAACY,IAAI,CAACV,IAAI,CAAC;IACvB;IACA,OAAOF,QAAQ;EACnB;;EAEA;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;EACIa,yBAAyBA,CAACC,YAAY,EAAEC,WAAW,EAAEC,qBAAqB,EAAEC,UAAU,EAAE;IAEpF,IAAIC,eAAe,GAAG,EAAE;IACxB,IAAIC,gBAAgB,GAAG,EAAE;IACzB,IAAIC,gBAAgB,GAAG,EAAE;IAEzB,KAAK,IAAI/D,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGyD,YAAY,CAAC3C,IAAI,CAAC,CAAC,CAAC,EAAE,EAAEd,CAAC,EAAE;MAC3C,IAAIgE,GAAG,GAAGP,YAAY,CAACzD,CAAC,CAAC;MACzB,IAAIiE,IAAI,GAAGP,WAAW,CAAC1D,CAAC,CAAC;MAEzB,IAAIkE,UAAU,GAAGvI,GAAG,CAACqI,GAAG,CAACvE,IAAI,CAAC,CAAC,CAAC,CAAC;MACjC,IAAIyE,UAAU,KAAKN,UAAU,EAAE;QAC3B;QACA;MACJ;MAEA,IAAIZ,MAAM,GAAGpH,OAAO,CAACoI,GAAG,CAACvE,IAAI,CAAC;MAC9B,IAAI0E,UAAU,GAAGnB,MAAM,CAACkB,UAAU,CAAC;MACnC,IAAIC,UAAU,GAAGR,qBAAqB,EAAE;QACpCE,eAAe,CAACN,IAAI,CAACU,IAAI,CAAC;QAC1BH,gBAAgB,CAACP,IAAI,CAACY,UAAU,CAAC;QACjCJ,gBAAgB,CAACR,IAAI,CAACW,UAAU,CAAC;MACrC;IACJ;IAEA,OAAO,CAACL,eAAe,EAAEC,gBAAgB,EAAEC,gBAAgB,CAAC;EAEhE;;EAEA;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACIK,sBAAsBA,CAClBC,WAAW,EACXC,UAAU,EACVC,CAAC,EAGH;IAAA,IAFEC,cAAc,GAAAtC,SAAA,CAAAvC,MAAA,QAAAuC,SAAA,QAAAjE,SAAA,GAAAiE,SAAA,MAAG,GAAG;IAAA,IACpBuC,2BAA2B,GAAAvC,SAAA,CAAAvC,MAAA,QAAAuC,SAAA,QAAAjE,SAAA,GAAAiE,SAAA,MAAG,GAAG;IAEjC;IACA,IAAIwC,MAAM,GAAG,EAAE;IACf,IAAIC,WAAW,GAAG,CAAC;IACnB,IAAIC,aAAa,GAAG,CAAC;;IAErB;IACA,KAAK,IAAIlF,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG2E,WAAW,CAAC1E,MAAM,EAAE,EAAED,CAAC,EAAE;MACzC,IAAI2E,WAAW,CAAC3E,CAAC,CAAC,KAAK6E,CAAC,EAAE;QACtBG,MAAM,CAACnB,IAAI,CAAC7D,CAAC,CAAC;QACd,EAAEiF,WAAW;MACjB;MAEA,IAAIL,UAAU,CAACC,CAAC,CAAC,CAAC9E,IAAI,CAACC,CAAC,CAAC,IAAI8E,cAAc,EAAE;QACzC,EAAEI,aAAa;MACnB;IACJ;IACA,IAAIC,WAAW,GAAGF,WAAW,GAAG,CAAC,IAAIC,aAAa,GAAG,CAAC;;IAEtD;IACA,IAAIC,WAAW,EAAE;MACb;MACA,IAAIC,UAAU,GAAGH,WAAW,GAAGC,aAAa;MAC5CC,WAAW,GAAGC,UAAU,GAAGL,2BAA2B;IAC1D;IAEA,OAAO,CAACI,WAAW,EAAEH,MAAM,CAAC;EAChC;;EAEA;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACIK,gBAAgBA,CACZT,UAAU,EACVU,WAAW,EACXC,WAAW,EACXT,cAAc,EACdC,2BAA2B,EAG7B;IAAA,IAFES,iBAAiB,GAAAhD,SAAA,CAAAvC,MAAA,QAAAuC,SAAA,QAAAjE,SAAA,GAAAiE,SAAA,MAAG,IAAI;IAAA,IACxBU,WAAW,GAAAV,SAAA,CAAAvC,MAAA,QAAAuC,SAAA,QAAAjE,SAAA,GAAAiE,SAAA,MAAG,IAAI;IAElB,IAAI,CAACvE,MAAM,EAAEF,KAAK,CAAC,GAAGmF,WAAW,IAAI0B,UAAU,CAAC,CAAC,CAAC,CAACxD,IAAI;IAEvD,IAAIqE,YAAY,GAAG,IAAIrJ,MAAM,CACzB,OAAO,EACP,IAAIsJ,UAAU,CAACzH,MAAM,GAAGF,KAAK,CAAC,EAC9B,CAACE,MAAM,EAAEF,KAAK,CAClB,CAAC;IACD,IAAI4H,QAAQ,GAAG,EAAE;;IAEjB;IACA,IAAIzC,WAAW,KAAK,IAAI,EAAE;MACtB;MACA,KAAK,IAAIlD,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG4E,UAAU,CAAC3E,MAAM,EAAE,EAAED,CAAC,EAAE;QACxC4E,UAAU,CAAC5E,CAAC,CAAC,GAAGzD,WAAW,CAACqI,UAAU,CAAC5E,CAAC,CAAC,EAAEkD,WAAW,EAAE,UAAU,EAAE,KAAK,CAAC;MAC9E;IACJ;;IAEA;IACA;IACA;IACA;IACA,IAAIyB,WAAW,GAAG,IAAIe,UAAU,CAACd,UAAU,CAAC,CAAC,CAAC,CAAC7E,IAAI,CAACE,MAAM,CAAC;IAC3D,IAAI2F,UAAU,GAAG,IAAI/F,YAAY,CAAC+E,UAAU,CAAC,CAAC,CAAC,CAAC7E,IAAI,CAACE,MAAM,CAAC;IAE5D,KAAK,IAAID,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG4E,UAAU,CAAC3E,MAAM,EAAE,EAAED,CAAC,EAAE;MACxC,IAAI2D,KAAK,GAAG2B,WAAW,CAACtF,CAAC,CAAC;MAE1B,KAAK,IAAIM,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGsE,UAAU,CAAC5E,CAAC,CAAC,CAACD,IAAI,CAACE,MAAM,EAAE,EAAEK,CAAC,EAAE;QAChDsE,UAAU,CAAC5E,CAAC,CAAC,CAACD,IAAI,CAACO,CAAC,CAAC,IAAIqD,KAAK;QAC9B,IAAIiB,UAAU,CAAC5E,CAAC,CAAC,CAACD,IAAI,CAACO,CAAC,CAAC,GAAGsF,UAAU,CAACtF,CAAC,CAAC,EAAE;UACvCqE,WAAW,CAACrE,CAAC,CAAC,GAAGN,CAAC;UAClB4F,UAAU,CAACtF,CAAC,CAAC,GAAGsE,UAAU,CAAC5E,CAAC,CAAC,CAACD,IAAI,CAACO,CAAC,CAAC;QACzC;MACJ;IACJ;IAEA,IAAIuF,kBAAkB,GAAG,CAAC;;IAE1B;IACA,KAAK,IAAIhB,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGU,WAAW,CAACtF,MAAM,EAAE,EAAE4E,CAAC,EAAE;MACzC,IAAIiB,UAAU,GAAGP,WAAW,CAACV,CAAC,CAAC;;MAE/B;MACA;;MAEA;MACA,IAAI,CAACM,WAAW,EAAEH,MAAM,CAAC,GAAG,IAAI,CAACN,sBAAsB,CACnDC,WAAW,EACXC,UAAU,EACVC,CAAC,EACDC,cAAc,EACdC,2BACJ,CAAC;MAED,IAAI,CAACI,WAAW,EAAE;QACd;QACA;MACJ;;MAEA;MACA;MACA;MACA;MACA;MACA;MACA,EAAEU,kBAAkB;;MAGpB;MACA,KAAK,IAAIE,KAAK,IAAIf,MAAM,EAAE;QACtBS,YAAY,CAAC1F,IAAI,CAACgG,KAAK,CAAC,GAAGF,kBAAkB;MACjD;MAEAF,QAAQ,CAAC9B,IAAI,CAAC;QACVmC,EAAE,EAAEH,kBAAkB;QACtBI,QAAQ,EAAEH,UAAU;QACpB;QACAnC,KAAK,EAAE2B,WAAW,CAACT,CAAC;MACxB,CAAC,CAAC;;MAEF;MACA;MACA;MACA;IACJ;;IAEA,OAAO,CAACY,YAAY,EAAEE,QAAQ,CAAC;EACnC;;EAEA;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACIO,kCAAkCA,CAC9B5D,OAAO,EAMT;IAAA,IALEC,SAAS,GAAAC,SAAA,CAAAvC,MAAA,QAAAuC,SAAA,QAAAjE,SAAA,GAAAiE,SAAA,MAAG,GAAG;IAAA,IACfsC,cAAc,GAAAtC,SAAA,CAAAvC,MAAA,QAAAuC,SAAA,QAAAjE,SAAA,GAAAiE,SAAA,MAAG,GAAG;IAAA,IACpBuC,2BAA2B,GAAAvC,SAAA,CAAAvC,MAAA,QAAAuC,SAAA,QAAAjE,SAAA,GAAAiE,SAAA,MAAG,GAAG;IAAA,IACjCgD,iBAAiB,GAAAhD,SAAA,CAAAvC,MAAA,QAAAuC,SAAA,QAAAjE,SAAA,GAAAiE,SAAA,MAAG,IAAI;IAAA,IACxBC,YAAY,GAAAD,SAAA,CAAAvC,MAAA,QAAAuC,SAAA,QAAAjE,SAAA,GAAAiE,SAAA,MAAG,IAAI;IAEnB,IAAIgD,iBAAiB,KAAK,IAAI,EAAE;MAC5BW,OAAO,CAACC,IAAI,CAAC,uDAAuD,CAAC;MACrEZ,iBAAiB,GAAG,IAAIa,GAAG,CAAC,CAAC;IACjC;IAEA,MAAMC,oBAAoB,GAAGhE,OAAO,CAACK,MAAM,CAAC,CAAC;IAC7C,MAAM4D,oBAAoB,GAAGjE,OAAO,CAACkE,UAAU,CAAC,CAAC;;IAEjD,MAAM5B,UAAU,GAAG2B,oBAAoB,CAACE,OAAO,CAAC,CAAC,EAAE;;IAEnD,IAAI,CAAC3D,UAAU,EAAE4D,WAAW,EAAExC,UAAU,CAAC,GAAGoC,oBAAoB,CAAClF,IAAI;IACrE8C,UAAU,IAAI,CAAC,CAAC,CAAC;;IAEjB,IAAIzB,YAAY,KAAK,IAAI,IAAIA,YAAY,CAACxC,MAAM,KAAK6C,UAAU,EAAE;MAC7D,MAAM9D,KAAK,CAAC,sFAAsF,CAAC;IACvG;IAEA,IAAIiE,QAAQ,GAAG,EAAE;IACjB,KAAK,IAAIjD,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG8C,UAAU,EAAE,EAAE9C,CAAC,EAAE;MACjC,IAAIkD,WAAW,GAAGT,YAAY,KAAK,IAAI,GAAGA,YAAY,CAACzC,CAAC,CAAC,GAAG,IAAI;MAEhE,IAAI+D,YAAY,GAAGuC,oBAAoB,CAACtG,CAAC,CAAC;MAC1C,IAAIgE,WAAW,GAAGY,UAAU,CAAC5E,CAAC,CAAC;MAE/B,IAAI,CAACmE,eAAe,EAAEC,gBAAgB,EAAEC,gBAAgB,CAAC,GAAG,IAAI,CAACP,yBAAyB,CAACC,YAAY,EAAEC,WAAW,EAAEzB,SAAS,EAAE2B,UAAU,CAAC;MAE5I,IAAIG,gBAAgB,CAACpE,MAAM,KAAK,CAAC,EAAE;QAC/B;QACA,IAAI,CAAChC,MAAM,EAAEF,KAAK,CAAC,GAAGmF,WAAW,IAAIc,WAAW,CAAC5C,IAAI,CAACuF,KAAK,CAAC,CAAC,CAAC,CAAC;QAE/D,IAAIlB,YAAY,GAAG,IAAIrJ,MAAM,CACzB,OAAO,EACP,IAAIsJ,UAAU,CAACzH,MAAM,GAAGF,KAAK,CAAC,CAACsC,IAAI,CAAC,CAAC,CAAC,CAAC,EACvC,CAACpC,MAAM,EAAEF,KAAK,CAClB,CAAC;QACDkF,QAAQ,CAACY,IAAI,CAAC;UACV4B,YAAY,EAAEA,YAAY;UAC1BmB,aAAa,EAAE;QACnB,CAAC,CAAC;QACF;MACJ;;MAGA;MACA,IAAI,CAACnB,YAAY,EAAEE,QAAQ,CAAC,GAAG,IAAI,CAACN,gBAAgB,CAChDlB,eAAe,EACfC,gBAAgB,EAChBC,gBAAgB,EAChBS,cAAc,EACdC,2BAA2B,EAC3BS,iBAAiB,EACjBtC,WACJ,CAAC;MAEDD,QAAQ,CAACY,IAAI,CAAC;QACV4B,YAAY,EAAEA,YAAY;QAC1BmB,aAAa,EAAEjB;MACnB,CAAC,CAAC;IACN;IAEA,OAAO1C,QAAQ;EACnB;EAEA4D,kCAAkCA,CAAA,EAAG;IACjC;IACA,MAAM7H,KAAK,CAAC,qBAAqB,CAAC;EACtC;AACJ;AAEA,OAAO,MAAM8H,iBAAiB,SAASjK,qBAAqB,CAAC;EACzD,MAAM+D,KAAKA,CAACC,MAAM,EAAEkG,YAAY,EAAE;IAC9B,IAAI;MACApG,YAAY;MACZU,cAAc;MACdC;IACJ,CAAC,GAAG,MAAM,KAAK,CAACV,KAAK,CAACC,MAAM,CAAC;IAE7B,IAAImG,KAAK,GAAGjL,mBAAmB,CAACgL,YAAY,CAAC;IAE7C,IAAIC,KAAK,CAAC/G,MAAM,KAAK,CAAC,EAAE;MACpB;MACA+G,KAAK,GAAG,CAAC,CAAC,EAAE,GAAGA,KAAK,CAAC;MACrBD,YAAY,GAAG,CAACA,YAAY,CAAC;IACjC,CAAC,MAAM,IAAIC,KAAK,CAAC/G,MAAM,KAAK,CAAC,EAAE;MAC3B,MAAMjB,KAAK,CAAC,6GAA6G,CAAC;IAC9H;;IAEA;IACA,KAAK,IAAIgB,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG+G,YAAY,CAAC9G,MAAM,EAAE,EAAED,CAAC,EAAE;MAAE;MAC5C,IAAIiH,iBAAiB,GAAG5F,cAAc,CAACrB,CAAC,CAAC;MACzC,IAAIkH,iBAAiB,GAAG5F,oBAAoB,CAACtB,CAAC,CAAC;MAE/C,IAAImH,aAAa,GAAG,CAChBD,iBAAiB,CAAC,CAAC,CAAC,GAAGD,iBAAiB,CAAC,CAAC,CAAC,EAC3CC,iBAAiB,CAAC,CAAC,CAAC,GAAGD,iBAAiB,CAAC,CAAC,CAAC,CAC9C;MAED,KAAK,IAAI3G,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGyG,YAAY,CAAC/G,CAAC,CAAC,CAACC,MAAM,EAAE,EAAEK,CAAC,EAAE;QAAE;QAC/C,KAAK,IAAIuE,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGkC,YAAY,CAAC/G,CAAC,CAAC,CAACM,CAAC,CAAC,CAACL,MAAM,EAAE,EAAE4E,CAAC,EAAE;UAAE;UAClD,KAAK,IAAIuC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGL,YAAY,CAAC/G,CAAC,CAAC,CAACM,CAAC,CAAC,CAACuE,CAAC,CAAC,CAAC5E,MAAM,EAAE,EAAEmH,CAAC,EAAE;YAAE;YACrDL,YAAY,CAAC/G,CAAC,CAAC,CAACM,CAAC,CAAC,CAACuE,CAAC,CAAC,CAACuC,CAAC,CAAC,IAAID,aAAa,CAACC,CAAC,CAAC;UAChD;QACJ;MACJ;IACJ;IAEA,IAAIC,mBAAmB,GAAG,IAAIjL,MAAM,CAChC,OAAO,EACPyF,aAAa,CAAC/B,IAAI,CAACiH,YAAY,CAACO,IAAI,CAACC,QAAQ,CAAC,CACzCtG,GAAG,CAACC,CAAC,IAAIsG,MAAM,CAAC/I,IAAI,CAACgJ,KAAK,CAACvG,CAAC,CAAC,CAAC,CAAC,CAAC,EACrC8F,KACJ,CAAC;;IAED;IACA;IACA;IACA;IACA;IACA;;IAEA,OAAO;MACHrG,YAAY;MACZU,cAAc,EAAEA,cAAc;MAC9BC,oBAAoB,EAAEA,oBAAoB;MAC1CyF,YAAY,EAAEM;IAClB,CAAC;EACL;;EAEA;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACIK,kBAAkBA,CAACC,KAAK,EAAEtG,cAAc,EAAEC,oBAAoB,EAItD;IAAA,IAJwD;MAC5DwD,cAAc,GAAG,GAAG;MACpB8C,QAAQ,GAAG,IAAI;MACfnK,QAAQ,GAAG;IACf,CAAC,GAAA+E,SAAA,CAAAvC,MAAA,QAAAuC,SAAA,QAAAjE,SAAA,GAAAiE,SAAA,MAAG,CAAC,CAAC;IACF;;IAEA,IAAIqF,YAAY,GAAG,EAAE;IAErBpK,QAAQ,GAAGA,QAAQ,IAAI,IAAI,CAACA,QAAQ;IAEpC,IAAIqK,iBAAiB,GAAG,CAACrK,QAAQ,CAACQ,MAAM,EAAER,QAAQ,CAACM,KAAK,CAAC;IAEzD,KAAK,IAAIiC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGqB,cAAc,CAACpB,MAAM,EAAE,EAAED,CAAC,EAAE;MAC5C,IAAIU,aAAa,GAAGW,cAAc,CAACrB,CAAC,CAAC;MACrC,IAAIV,mBAAmB,GAAGgC,oBAAoB,CAACtB,CAAC,CAAC;MAEjD,IAAIuE,IAAI,GAAGoD,KAAK,CAAC3H,CAAC,CAAC,CAAC,CAAC;;MAErB;MACA,IAAI+H,kBAAkB,GAAG,EAAE;MAC3B,KAAK,IAAIzH,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGiE,IAAI,CAACnD,IAAI,CAAC,CAAC,CAAC,EAAE,EAAEd,CAAC,EAAE;QACnC,IAAI0H,CAAC,GAAGzD,IAAI,CAACjE,CAAC,CAAC,CAAC,CAAC;;QAEjB;QACA,IAAI2H,iBAAiB,GAAG1L,WAAW,CAACyL,CAAC,EAAEF,iBAAiB,EAAE,UAAU,EAAE,KAAK,CAAC;;QAE5E;QACAG,iBAAiB,GAAGA,iBAAiB,CAACtB,KAAK,CAAC,IAAI,EAAE,CAAC,CAAC,EAAErH,mBAAmB,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAEA,mBAAmB,CAAC,CAAC,CAAC,CAAC,CAAC;;QAE3G;QACA2I,iBAAiB,GAAG1L,WAAW,CAACgI,IAAI,EAAE7D,aAAa,EAAE,UAAU,EAAE,KAAK,CAAC;QAEvE,IAAIkH,QAAQ,EAAE;UACVK,iBAAiB,GAAG,IAAI7L,MAAM,CAC1B,MAAM,EACN8D,KAAK,CAACJ,IAAI,CAACmI,iBAAiB,CAAClI,IAAI,CAAC,CAACkB,GAAG,CAACC,CAAC,IAAIA,CAAC,GAAG4D,cAAc,CAAC,EAC/DmD,iBAAiB,CAAC7G,IACtB,CAAC;QACL;;QAEA;QACA6G,iBAAiB,CAAC7G,IAAI,GAAG,CAAC,CAAC,EAAE,GAAG6G,iBAAiB,CAAC7G,IAAI,CAAC;QAEvD2G,kBAAkB,CAAClE,IAAI,CAACoE,iBAAiB,CAAC;MAC9C;MAEA,IAAIC,YAAY,GAAG5L,GAAG,CAACyL,kBAAkB,CAAC;MAC1CF,YAAY,CAAChE,IAAI,CAACqE,YAAY,CAAC;IACnC;IAEA,OAAOL,YAAY;EAEvB;AACJ;AAGA,OAAO,MAAMM,uBAAuB,SAASzL,gBAAgB,CAAC;EAE1DC,WAAWA,CAACC,MAAM,EAAE;IAChB,KAAK,CAACA,MAAM,CAAC;;IAEb;IACA,IAAI,CAACA,MAAM,CAACwL,WAAW,KAAK3L,aAAa,CAAC,IAAI,CAACG,MAAM,CAACyL,aAAa,EAAE,IAAI,CAACzL,MAAM,CAAC0L,KAAK,EAAE,IAAI,CAAC1L,MAAM,CAAC2L,YAAY,CAAC;EACrH;EACA;AACJ;AACA;AACA;AACA;AACA;EACIC,UAAUA,CAACxI,CAAC,EAAEoH,CAAC,EAAE;IACb,OAAO3I,IAAI,CAACgK,GAAG,CAAC,CAACzI,CAAC,GAAGoH,CAAC,KAAK,CAAC,GAAGA,CAAC,CAAC,GAAGA,CAAC,CAAC;EAC1C;;EAEA;AACJ;AACA;AACA;AACA;AACA;AACA;EACIsB,UAAUA,CAACC,KAAK,EAAEpJ,IAAI,EAAEC,KAAK,EAAE;IAC3B,MAAMoJ,MAAM,GAAG,IAAI/I,YAAY,CAAC8I,KAAK,CAAC1I,MAAM,GAAGV,IAAI,GAAGC,KAAK,CAAC;IAC5D,MAAM4H,CAAC,GAAGuB,KAAK,CAAC1I,MAAM,GAAG,CAAC;IAE1B,KAAK,IAAID,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG2I,KAAK,CAAC1I,MAAM,EAAE,EAAED,CAAC,EAAE;MACnC4I,MAAM,CAACrJ,IAAI,GAAGS,CAAC,CAAC,GAAG2I,KAAK,CAAC3I,CAAC,CAAC;IAC/B;IAEA,KAAK,IAAIA,CAAC,GAAG,CAAC,EAAEA,CAAC,IAAIT,IAAI,EAAE,EAAES,CAAC,EAAE;MAC5B4I,MAAM,CAACrJ,IAAI,GAAGS,CAAC,CAAC,GAAG2I,KAAK,CAAC,IAAI,CAACH,UAAU,CAACxI,CAAC,EAAEoH,CAAC,CAAC,CAAC;IACnD;IAEA,KAAK,IAAIpH,CAAC,GAAG,CAAC,EAAEA,CAAC,IAAIR,KAAK,EAAE,EAAEQ,CAAC,EAAE;MAC7B4I,MAAM,CAACxB,CAAC,GAAG7H,IAAI,GAAGS,CAAC,CAAC,GAAG2I,KAAK,CAAC,IAAI,CAACH,UAAU,CAACpB,CAAC,GAAGpH,CAAC,EAAEoH,CAAC,CAAC,CAAC;IAC3D;IAEA,OAAOwB,MAAM;EACjB;;EAEA;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACIC,IAAIA,CAACC,MAAM,EAAEC,MAAM,EAAE;IACjB;IACA;IACA;IACA;IACA;;IAEA;IACA,MAAMC,QAAQ,GAAG,IAAI,CAACpM,MAAM,CAAC0L,KAAK;IAClC,MAAMvG,CAAC,GAAG,CAAC,IAAIiH,QAAQ,GAAG,CAAC,CAAC;IAC5B,MAAMhH,CAAC,GAAG,CAAC,IAAI,CAAC,GAAGgH,QAAQ,GAAG,CAAC,CAAC;IAChC,MAAMC,MAAM,GAAG,CAAC,IAAKxK,IAAI,CAACyK,IAAI,CAACzK,IAAI,CAAC0K,IAAI,CAACnH,CAAC,CAAC,CAAE;IAC7C,MAAMoH,YAAY,GAAGJ,QAAQ,GAAG,CAAC;;IAEjC;IACA;IACA,MAAMjJ,IAAI,GAAG,IAAIF,YAAY,CAACuJ,YAAY,GAAGN,MAAM,CAAC7I,MAAM,CAAC;;IAE3D;IACA;IACA,MAAMoJ,KAAK,GAAG,IAAIxJ,YAAY,CAACmC,CAAC,CAAC;IACjC,MAAMsH,MAAM,GAAG,IAAIzJ,YAAY,CAACoJ,MAAM,CAAC;IACvC,MAAMM,OAAO,GAAG,IAAI1J,YAAY,CAACoJ,MAAM,CAAC;IACxC,MAAMO,OAAO,GAAG,IAAI3J,YAAY,CAACoJ,MAAM,CAAC;IACxC,MAAMQ,SAAS,GAAG,IAAI5J,YAAY,CAACoJ,MAAM,CAAC;IAC1C,MAAMS,UAAU,GAAG,IAAI7J,YAAY,CAACoJ,MAAM,CAAC;IAC3C,MAAMU,UAAU,GAAG,IAAI9J,YAAY,CAACoJ,MAAM,CAAC;;IAE3C;IACA,MAAMW,KAAK,GAAG,CAAC,CAAC,GAAGnL,IAAI,CAACoL,EAAE,GAAGb,QAAQ;IACrC,MAAMc,KAAK,GAAGrL,IAAI,CAACsL,GAAG,CAACH,KAAK,CAAC;IAC7B,MAAMI,KAAK,GAAGvL,IAAI,CAACwL,GAAG,CAACL,KAAK,CAAC;;IAE7B;IACA,KAAK,IAAI5J,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGgC,CAAC,IAAI,CAAC,EAAE,EAAEhC,CAAC,EAAE;MAC7B;MACA,MAAMkK,CAAC,GAAG,CAAClK,CAAC,GAAG,CAAC,GAAGgJ,QAAQ,KAAK,CAAC,GAAG,GAAG;;MAEvC;MACA,MAAMmB,UAAU,GAAG1L,IAAI,CAAC2L,IAAI,CAACN,KAAK,IAAI,CAAC,GAAGE,KAAK,IAAI,CAAC,CAAC,IAAIE,CAAC;MAC1D,MAAMG,UAAU,GAAGH,CAAC,GAAGzL,IAAI,CAAC6L,KAAK,CAACN,KAAK,EAAEF,KAAK,CAAC;;MAE/C;MACA;MACA,IAAIS,EAAE,GAAG,CAAC,GAAGvK,CAAC;MACdqJ,KAAK,CAACkB,EAAE,CAAC,GAAGJ,UAAU,GAAG1L,IAAI,CAACsL,GAAG,CAACM,UAAU,CAAC;MAC7ChB,KAAK,CAACkB,EAAE,GAAG,CAAC,CAAC,GAAGJ,UAAU,GAAG1L,IAAI,CAACwL,GAAG,CAACI,UAAU,CAAC;;MAEjD;MACAf,MAAM,CAACiB,EAAE,CAAC,GAAGlB,KAAK,CAACkB,EAAE,CAAC;MACtBjB,MAAM,CAACiB,EAAE,GAAG,CAAC,CAAC,GAAG,CAAElB,KAAK,CAACkB,EAAE,GAAG,CAAC,CAAC;IACpC;IACA,MAAMC,WAAW,GAAGnB,KAAK,CAACoB,QAAQ,CAAC1I,CAAC,EAAEC,CAAC,CAAC;;IAExC;IACA;IACA,MAAM0I,CAAC,GAAG,IAAIvO,GAAG,CAAC8M,MAAM,IAAI,CAAC,CAAC;IAC9B;IACAyB,CAAC,CAACC,SAAS,CAAClB,SAAS,EAAEH,MAAM,CAAC;IAE9B,KAAK,IAAItJ,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG8I,MAAM,CAAC7I,MAAM,EAAE,EAAED,CAAC,EAAE;MACpC,MAAM4K,KAAK,GAAG9B,MAAM,CAAC9I,CAAC,CAAC;MAEvB,KAAK,IAAIM,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGkK,WAAW,CAACvK,MAAM,EAAEK,CAAC,IAAI,CAAC,EAAE;QAC5C,MAAMuK,EAAE,GAAGvK,CAAC,GAAG,CAAC;QAChB,MAAMwK,EAAE,GAAGxK,CAAC,IAAI,CAAC;QAEjB,MAAMyK,MAAM,GAAGH,KAAK,CAACE,EAAE,CAAC,GAAG/B,MAAM,CAAC+B,EAAE,CAAC;QACrCvB,OAAO,CAACjJ,CAAC,CAAC,GAAGyK,MAAM,GAAGP,WAAW,CAAClK,CAAC,CAAC;QACpCiJ,OAAO,CAACsB,EAAE,CAAC,GAAGE,MAAM,GAAGP,WAAW,CAACK,EAAE,CAAC;MAC1C;MACA;MACAH,CAAC,CAACC,SAAS,CAACjB,UAAU,EAAEH,OAAO,CAAC;MAEhC,KAAK,IAAIjJ,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGmJ,SAAS,CAACxJ,MAAM,EAAEK,CAAC,IAAI,CAAC,EAAE;QAC1C,MAAMuK,EAAE,GAAGvK,CAAC,GAAG,CAAC;QAEhBkJ,OAAO,CAAClJ,CAAC,CAAC,GAAGoJ,UAAU,CAACpJ,CAAC,CAAC,GAAGmJ,SAAS,CAACnJ,CAAC,CAAC,GAAGoJ,UAAU,CAACmB,EAAE,CAAC,GAAGpB,SAAS,CAACoB,EAAE,CAAC;QAC1ErB,OAAO,CAACqB,EAAE,CAAC,GAAGnB,UAAU,CAACpJ,CAAC,CAAC,GAAGmJ,SAAS,CAACoB,EAAE,CAAC,GAAGnB,UAAU,CAACmB,EAAE,CAAC,GAAGpB,SAAS,CAACnJ,CAAC,CAAC;MAC/E;MACA;MACAoK,CAAC,CAACM,gBAAgB,CAACrB,UAAU,EAAEH,OAAO,CAAC;MAEvC,MAAMyB,MAAM,GAAGjL,CAAC,GAAGoJ,YAAY;MAC/B,KAAK,IAAI9I,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG8I,YAAY,EAAE9I,CAAC,IAAI,CAAC,EAAE;QACtC,MAAMyK,MAAM,GAAGpB,UAAU,CAACrJ,CAAC,GAAGyB,CAAC,CAAC;QAChC,MAAMmJ,MAAM,GAAGvB,UAAU,CAACrJ,CAAC,GAAGyB,CAAC,GAAG,CAAC,CAAC;QACpC,MAAMoJ,MAAM,GAAGX,WAAW,CAAClK,CAAC,CAAC;QAC7B,MAAM8K,MAAM,GAAGZ,WAAW,CAAClK,CAAC,GAAG,CAAC,CAAC;;QAEjC;QACA,MAAM+K,EAAE,GAAGJ,MAAM,GAAG3K,CAAC;QACrBP,IAAI,CAACsL,EAAE,CAAC,GAAGN,MAAM,GAAGI,MAAM,GAAGD,MAAM,GAAGE,MAAM;QAC5CrL,IAAI,CAACsL,EAAE,GAAG,CAAC,CAAC,GAAGN,MAAM,GAAGK,MAAM,GAAGF,MAAM,GAAGC,MAAM;MACpD;IACJ;IAEA,OAAO;MACHpL,IAAI,EAAEA,IAAI;MACVqB,IAAI,EAAE,CAAC0H,MAAM,CAAC7I,MAAM,EAAEmJ,YAAY,CAAC,CAAC;IACxC,CAAC;EACL;;EAEA;AACJ;AACA;AACA;AACA;AACA;AACA;EACIkC,SAASA,CAACC,QAAQ,EAAiB;IAAA,IAAfC,MAAM,GAAAhJ,SAAA,CAAAvC,MAAA,QAAAuC,SAAA,QAAAjE,SAAA,GAAAiE,SAAA,MAAG,IAAI;IAC7B,MAAMsG,MAAM,GAAG,EAAE;IACjB,MAAM2C,WAAW,GAAGhN,IAAI,CAACM,KAAK,CAAC,CAAC,IAAI,CAACnC,MAAM,CAAC0L,KAAK,GAAG,CAAC,IAAI,CAAC,CAAC,GAAG,CAAC;IAC/D,MAAMoD,cAAc,GAAGH,QAAQ,CAACtL,MAAM;IAEtC,KAAK,IAAID,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG0L,cAAc,GAAG,CAAC,EAAE1L,CAAC,IAAI,IAAI,CAACpD,MAAM,CAAC+O,UAAU,EAAE;MAEjE,IAAIf,KAAK;MACT,IAAIY,MAAM,EAAE;QAER,IAAII,UAAU,GAAG5L,CAAC,GAAGyL,WAAW,GAAGzL,CAAC,GAAGyL,WAAW,GAAG,CAAC;QACtD,IAAII,QAAQ,GACR7L,CAAC,GAAG0L,cAAc,GAAGD,WAAW,GAC1BzL,CAAC,GAAGyL,WAAW,GACfC,cAAc;QAExBd,KAAK,GAAGW,QAAQ,CAACd,QAAQ,CAACmB,UAAU,EAAEC,QAAQ,CAAC;QAE/C,IAAID,UAAU,KAAK,CAAC,EAAE;UAClBhB,KAAK,GAAG,IAAI,CAAClC,UAAU,CACnBkC,KAAK,EACL,CAAC5K,CAAC,GAAGyL,WAAW,EAChB,CACJ,CAAC;QAEL,CAAC,MAAM,IAAII,QAAQ,KAAKH,cAAc,EAAE;UACpCd,KAAK,GAAG,IAAI,CAAClC,UAAU,CACnBkC,KAAK,EACL,CAAC,EACD5K,CAAC,GAAG0L,cAAc,GAAGD,WACzB,CAAC;QACL;MAEJ,CAAC,MAAM;QACHb,KAAK,GAAG,IAAI/K,YAAY,CAAC,IAAI,CAACjD,MAAM,CAAC0L,KAAK,CAAC;QAC3C,MAAMwD,UAAU,GAAGP,QAAQ,CAACd,QAAQ,CAACzK,CAAC,EAAEA,CAAC,GAAG,IAAI,CAACpD,MAAM,CAAC0L,KAAK,CAAC;QAE9D,IAAIwD,UAAU,CAAC7L,MAAM,GAAG,IAAI,CAACrD,MAAM,CAAC0L,KAAK,EAAE;UACvCsC,KAAK,CAACmB,GAAG,CAACD,UAAU,CAAC;UACrBlB,KAAK,CAACvK,IAAI,CAAC,CAAC,EAAEyL,UAAU,CAAC7L,MAAM,EAAE,IAAI,CAACrD,MAAM,CAAC0L,KAAK,CAAC;QACvD,CAAC,MAAM;UACHsC,KAAK,GAAGkB,UAAU;QACtB;MAEJ;MACAhD,MAAM,CAACjF,IAAI,CAAC+G,KAAK,CAAC;IACtB;IAEA,OAAO9B,MAAM;EACjB;;EAEA;AACJ;AACA;AACA;AACA;AACA;EACIkD,OAAOA,CAACC,CAAC,EAAE;IACP,IAAIA,CAAC,GAAG,CAAC,EAAE;MACP,OAAO,EAAE;IACb;IACA,IAAIA,CAAC,KAAK,CAAC,EAAE;MACT,OAAO,CAAC,CAAC,CAAC;IACd;IACA,MAAMC,KAAK,GAAGD,CAAC,GAAG,CAAC;IACnB,MAAME,QAAQ,GAAG,IAAItM,YAAY,CAACqM,KAAK,CAAC;IACxC,KAAK,IAAIlM,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGkM,KAAK,EAAE,EAAElM,CAAC,EAAE;MAC5B,MAAMoM,CAAC,GAAG,CAAC,GAAGpM,CAAC,GAAGiM,CAAC,GAAG,CAAC;MACvBE,QAAQ,CAACnM,CAAC,CAAC,GAAG,GAAG,GAAG,GAAG,GAAGvB,IAAI,CAACsL,GAAG,CAACtL,IAAI,CAACoL,EAAE,GAAGuC,CAAC,GAAGF,KAAK,CAAC;IAC3D;IACA,OAAOC,QAAQ;EACnB;;EAEA;AACJ;AACA;AACA;AACA;EACIE,uBAAuBA,CAACd,QAAQ,EAAE;IAC9B;;IAEA,MAAMe,MAAM,GAAG,IAAIzM,YAAY,CAAC,IAAI,CAACjD,MAAM,CAAC2P,SAAS,CAAC;IACtDD,MAAM,CAACP,GAAG,CAACR,QAAQ,CAAC;IAEpB,MAAMxC,MAAM,GAAG,IAAI,CAACiD,OAAO,CAAC,IAAI,CAACpP,MAAM,CAAC0L,KAAK,GAAG,CAAC,CAAC;IAClD,MAAMQ,MAAM,GAAG,IAAI,CAACwC,SAAS,CAACgB,MAAM,CAAC;IAErC,MAAMzD,IAAI,GAAG,IAAI,CAACA,IAAI,CAACC,MAAM,EAAEC,MAAM,CAAC;IAEtC,MAAMyD,QAAQ,GAAG3D,IAAI,CAAC9I,IAAI;IAC1B,MAAM0M,EAAE,GAAG5D,IAAI,CAACzH,IAAI,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC;IAC7B,MAAMsL,EAAE,GAAG7D,IAAI,CAACzH,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC;;IAE9B;IACA;IACA;IACA,MAAMuL,UAAU,GAAG,IAAI9M,YAAY,CAAC4M,EAAE,GAAGC,EAAE,CAAC;IAC5C,KAAK,IAAI1M,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGyM,EAAE,EAAE,EAAEzM,CAAC,EAAE;MACzB,KAAK,IAAIM,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGoM,EAAE,EAAE,EAAEpM,CAAC,EAAE;QACzB;QACA,IAAIsM,SAAS,GAAG5M,CAAC,GAAG0M,EAAE,GAAGpM,CAAC;QAC1B,IAAIuM,QAAQ,GAAGD,SAAS,IAAI,CAAC,CAAC,CAAC;QAC/B,IAAIE,SAAS,GAAGN,QAAQ,CAACK,QAAQ,CAAC,IAAI,CAAC,GAAGL,QAAQ,CAACK,QAAQ,GAAG,CAAC,CAAC,IAAI,CAAC;QACrEF,UAAU,CAACC,SAAS,CAAC,GAAGE,SAAS;MACrC;IACJ;IAEA,MAAM1E,WAAW,GAAG,IAAI,CAACxL,MAAM,CAACwL,WAAW;IAC3C,MAAM2E,eAAe,GAAG3E,WAAW,CAACnI,MAAM;IAE1C,MAAM+M,QAAQ,GAAG,IAAInN,YAAY,CAACkN,eAAe,GAAGN,EAAE,CAAC;IACvD,IAAIQ,MAAM,GAAG,CAAC;;IAEd;IACA;IACA;IACA;IACA;IACA,KAAK,IAAIjN,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG+M,eAAe,EAAE,EAAE/M,CAAC,EAAE;MACtC,MAAMkN,UAAU,GAAG9E,WAAW,CAACpI,CAAC,CAAC;MAEjC,KAAK,IAAIM,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGmM,EAAE,EAAE,EAAEnM,CAAC,EAAE;QACzB,IAAI6M,GAAG,GAAG,CAAC;;QAEX;QACA,KAAK,IAAItI,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG6H,EAAE,EAAE,EAAE7H,CAAC,EAAE;UACzBsI,GAAG,IAAID,UAAU,CAACrI,CAAC,CAAC,GAAG8H,UAAU,CAACrM,CAAC,GAAGoM,EAAE,GAAG7H,CAAC,CAAC;QACjD;QAEAmI,QAAQ,CAACC,MAAM,EAAE,CAAC,GAAGE,GAAG;MAC5B;IACJ;IAEA,MAAMC,KAAK,GAAG,KAAK;IACnB,MAAMC,QAAQ,GAAG,IAAIxN,YAAY,CAACmN,QAAQ,CAAC/M,MAAM,CAAC;IAElD,IAAIqN,UAAU,GAAG,CAAC;IAClB,KAAK,IAAItN,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGgN,QAAQ,CAAC/M,MAAM,EAAE,EAAED,CAAC,EAAE;MACtC,MAAMuN,OAAO,GAAG9O,IAAI,CAACxC,GAAG,CAACmR,KAAK,EAAEJ,QAAQ,CAAChN,CAAC,CAAC,CAAC;MAC5C,MAAMwN,KAAK,GAAG/O,IAAI,CAAC+O,KAAK,CAACD,OAAO,CAAC;MACjCF,QAAQ,CAACrN,CAAC,CAAC,GAAGwN,KAAK;MACnBF,UAAU,GAAG7O,IAAI,CAACxC,GAAG,CAACuR,KAAK,EAAEF,UAAU,CAAC;IAC5C;IAEA,KAAK,IAAItN,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGqN,QAAQ,CAACpN,MAAM,EAAE,EAAED,CAAC,EAAE;MACtCqN,QAAQ,CAACrN,CAAC,CAAC,GAAGvB,IAAI,CAACxC,GAAG,CAACoR,QAAQ,CAACrN,CAAC,CAAC,EAAEsN,UAAU,GAAG,CAAC,CAAC;MACnDD,QAAQ,CAACrN,CAAC,CAAC,GAAG,CAACqN,QAAQ,CAACrN,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC;IACvC;IAEA,OAAO;MACHD,IAAI,EAAEsN,QAAQ;MACdjM,IAAI,EAAE,CAAC2L,eAAe,EAAEN,EAAE;IAC9B,CAAC;EACL;;EAEA;AACJ;AACA;AACA;AACA;EACI,MAAM7L,KAAKA,CAAC6M,KAAK,EAAE;IACf;;IAEA,IAAIA,KAAK,CAACxN,MAAM,GAAG,IAAI,CAACrD,MAAM,CAAC2P,SAAS,EAAE;MACtCpG,OAAO,CAACC,IAAI,CACR,mEAAmE,GACnE,oEAAoE,GACpE,gEACJ,CAAC;IACL;IACA,IAAImF,QAAQ,GAAGkC,KAAK,CAAC9G,KAAK,CAAC,CAAC,EAAE,IAAI,CAAC/J,MAAM,CAAC2P,SAAS,CAAC;IAEpD,IAAImB,QAAQ,GAAG,IAAI,CAACrB,uBAAuB,CAACd,QAAQ,CAAC;IAErD,OAAO;MACHoC,cAAc,EAAE,IAAIvR,MAAM,CAAC,SAAS,EAChCsR,QAAQ,CAAC3N,IAAI,EACb,CAAC,CAAC,EAAE,GAAG2N,QAAQ,CAACtM,IAAI,CACxB;IACJ,CAAC;EACL;AACJ;;AAEA;AACA;AACA;AACA;AACA,OAAO,MAAMwM,SAAS,SAAS9R,QAAQ,CAAC;EACpC;AACJ;AACA;AACA;EACIa,WAAWA,CAACkR,iBAAiB,EAAE;IAC3B,KAAK,CAAC,CAAC;IACP,IAAI,CAACA,iBAAiB,GAAGA,iBAAiB;IAC1C;EACJ;;EAEA;AACJ;AACA;AACA;AACA;EACI,MAAMjN,KAAKA,CAACkN,KAAK,EAAE;IACf,OAAO,MAAM,IAAI,CAACD,iBAAiB,CAACC,KAAK,CAAC;EAC9C;AACJ;AAEA,OAAO,MAAMC,YAAY,SAASH,SAAS,CAAC;EAExC,MAAMhN,KAAKA,CAACC,MAAM,EAAEkG,YAAY,EAAE;IAC9B,OAAO,MAAM,IAAI,CAAC8G,iBAAiB,CAAChN,MAAM,EAAEkG,YAAY,CAAC;EAC7D;;EAEA;AACJ;AACA;EACIW,kBAAkBA,CAAA,EAAU;IACxB;IACA,OAAO,IAAI,CAACmG,iBAAiB,CAACnG,kBAAkB,CAAC,GAAAlF,SAAO,CAAC;EAC7D;AACJ;;AAEA;AACA;AACA;AACA;AACA,OAAO,MAAMwL,gBAAgB,SAASJ,SAAS,CAAC;EAC5C;AACJ;AACA;AACA;AACA;EACI,MAAMhN,KAAKA,CAAC6M,KAAK,EAAE;IACf,OAAO,MAAM,IAAI,CAACI,iBAAiB,CAACJ,KAAK,CAAC;EAC9C;AACJ;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMQ,aAAa,CAAC;EACvB,OAAOC,+BAA+B,GAAG;IACrC,yBAAyB,EAAE/F,uBAAuB;IAClD,qBAAqB,EAAE5G,mBAAmB;IAC1C,sBAAsB,EAAEC,oBAAoB;IAE5C,mBAAmB,EAAEsF;EACzB,CAAC;EAED,OAAOqH,uBAAuB,GAAG;IAC7B,kBAAkB,EAAEH,gBAAgB;IACpC,cAAc,EAAED;EACpB,CAAC;;EAED;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACI,aAAaK,eAAeA,CAACC,6BAA6B,EAMlD;IAAA,IANoD;MACxDC,iBAAiB,GAAG,IAAI;MACxB1R,MAAM,GAAG,IAAI;MACb2R,SAAS,GAAG,IAAI;MAChBC,gBAAgB,GAAG,KAAK;MACxBC,QAAQ,GAAG;IACf,CAAC,GAAAjM,SAAA,CAAAvC,MAAA,QAAAuC,SAAA,QAAAjE,SAAA,GAAAiE,SAAA,MAAG,CAAC,CAAC;IAEF,IAAIkM,kBAAkB,GAAG9R,MAAM,KAAI,MAAMZ,YAAY,CAACqS,6BAA6B,EAAE,0BAA0B,EAAE,IAAI,EAAE;MACnHC,iBAAiB;MACjB1R,MAAM;MACN2R,SAAS;MACTC,gBAAgB;MAChBC;IACJ,CAAC,CAAC;;IAEF;IACA;IACA,IAAIE,GAAG,GAAGD,kBAAkB,CAACE,sBAAsB,IAAIF,kBAAkB,CAACG,oBAAoB;IAC9F,IAAIC,uBAAuB,GAAG,IAAI,CAACZ,+BAA+B,CAACS,GAAG,CAAC;IAEvE,IAAI,CAACG,uBAAuB,EAAE;MAC1B,IAAIJ,kBAAkB,CAACrR,IAAI,KAAKkB,SAAS,EAAE;QACvC;QACA4H,OAAO,CAACC,IAAI,CAAC,uGAAuG,CAAC;QACrH0I,uBAAuB,GAAGjS,qBAAqB;MACnD,CAAC,MAAM;QACH,MAAM,IAAImC,KAAK,CAAE,mCAAkC0P,kBAAkB,CAACE,sBAAuB,EAAC,CAAC;MACnG;IACJ;;IAEA;IACA,IAAIG,eAAe,GAAG,IAAI,CAACZ,uBAAuB,CAACO,kBAAkB,CAACK,eAAe,CAAC,IAAInB,SAAS;;IAEnG;IACA,IAAIC,iBAAiB,GAAG,IAAIiB,uBAAuB,CAACJ,kBAAkB,CAAC;IACvE,OAAO,IAAIK,eAAe,CAAClB,iBAAiB,CAAC;EACjD;AACJ;AACA"},"metadata":{},"sourceType":"module","externalDependencies":[]}