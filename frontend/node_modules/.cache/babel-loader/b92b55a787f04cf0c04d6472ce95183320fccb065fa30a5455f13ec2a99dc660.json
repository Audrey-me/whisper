{"ast":null,"code":"/**\n * @file Helper module for `Tensor` processing.\n * \n * These functions and classes are only used internally, \n * meaning an end-user shouldn't need to access anything here.\n * \n * @module utils/tensor\n */\n\nimport { ONNX } from '../backends/onnx.js';\nimport { interpolate_data, transpose_data } from './maths.js';\n\n/**\n * @typedef {import('./maths.js').AnyTypedArray} AnyTypedArray\n */\n\n/** @type {Object} */\nconst ONNXTensor = ONNX.Tensor;\nexport class Tensor extends ONNXTensor {\n  /**\n   * Create a new Tensor or copy an existing Tensor.\n   * @param {[string, Array|AnyTypedArray, number[]]|[ONNXTensor]} args\n   */\n  constructor() {\n    for (var _len = arguments.length, args = new Array(_len), _key = 0; _key < _len; _key++) {\n      args[_key] = arguments[_key];\n    }\n    if (args[0] instanceof ONNX.Tensor) {\n      // Create shallow copy\n      super(args[0].type, args[0].data, args[0].dims);\n    } else {\n      // Create new\n      super(...args);\n    }\n    return new Proxy(this, {\n      get: (obj, key) => {\n        if (typeof key === 'string') {\n          let index = Number(key);\n          if (Number.isInteger(index)) {\n            // key is an integer (i.e., index)\n            return obj._getitem(index);\n          }\n        }\n        // @ts-ignore\n        return obj[key];\n      },\n      set: (obj, key, value) => {\n        // TODO allow setting of data\n\n        // @ts-ignore\n        return obj[key] = value;\n      }\n    });\n  }\n\n  /**\n   * Returns an iterator object for iterating over the tensor data in row-major order.\n   * If the tensor has more than one dimension, the iterator will yield subarrays.\n   * @returns {Iterator} An iterator object for iterating over the tensor data in row-major order.\n   */\n  *[Symbol.iterator]() {\n    const [iterLength, ...iterDims] = this.dims;\n    if (iterDims.length > 0) {\n      const iterSize = iterDims.reduce((a, b) => a * b);\n      for (let i = 0; i < iterLength; ++i) {\n        yield this._subarray(i, iterSize, iterDims);\n      }\n    } else {\n      yield* this.data;\n    }\n  }\n\n  /**\n   * Index into a Tensor object.\n   * @param {number} index The index to access.\n   * @returns {Tensor} The data at the specified index.\n   */\n  _getitem(index) {\n    const [iterLength, ...iterDims] = this.dims;\n    if (index >= iterLength || index < -iterLength) {\n      throw new Error(`Index ${index} is out of bounds for dimension 0 with size ${iterLength}`);\n    }\n    if (index < 0) {\n      // Negative indexing\n      index += iterLength;\n    }\n    if (iterDims.length > 0) {\n      const iterSize = iterDims.reduce((a, b) => a * b);\n      return this._subarray(index, iterSize, iterDims);\n    } else {\n      return new Tensor(this.type, [this.data[index]], iterDims);\n    }\n  }\n\n  /**\n   * @param {number|bigint} item The item to search for in the tensor\n   * @returns {number} The index of the first occurrence of item in the tensor data.\n   */\n  indexOf(item) {\n    for (let index = 0; index < this.data.length; ++index) {\n      // Note: == instead of === so we can match Ints with BigInts\n      if (this.data[index] == item) {\n        return index;\n      }\n    }\n    return -1;\n  }\n\n  /**\n   * @param {number} index \n   * @param {number} iterSize \n   * @param {any} iterDims \n   * @returns {Tensor}\n   */\n  _subarray(index, iterSize, iterDims) {\n    let data = this.data.subarray(index * iterSize, (index + 1) * iterSize);\n    return new Tensor(this.type, data, iterDims);\n  }\n\n  /**\n   * Returns the value of this tensor as a standard JavaScript Number. This only works\n   * for tensors with one element. For other cases, see `Tensor.tolist()`.\n   * @returns {number} The value of this tensor as a standard JavaScript Number.\n   * @throws {Error} If the tensor has more than one element.\n   */\n  item() {\n    if (this.data.length !== 1) {\n      throw new Error(`a Tensor with ${this.data.length} elements cannot be converted to Scalar`);\n    }\n    return this.data[0];\n  }\n\n  /**\n   * Convert tensor data to a n-dimensional JS list\n   * @returns {Array}\n   */\n  tolist() {\n    return reshape(this.data, this.dims);\n  }\n\n  /**\n   * Return a new Tensor with the sigmoid function applied to each element.\n   * @returns {Tensor} The tensor with the sigmoid function applied.\n   */\n  sigmoid() {\n    return this.clone().sigmoid_();\n  }\n\n  /**\n   * Applies the sigmoid function to the tensor in place.\n   * @returns {Tensor} Returns `this`.\n   */\n  sigmoid_() {\n    for (let i = 0; i < this.data.length; ++i) {\n      this.data[i] = 1 / (1 + Math.exp(-this.data[i]));\n    }\n    return this;\n  }\n  clone() {\n    return new Tensor(this.type, this.data.slice(), this.dims.slice());\n  }\n  slice() {\n    // This allows for slicing with ranges and numbers\n    let newTensorDims = [];\n    let newOffsets = [];\n\n    // slices is an array of numbers or arrays of numbers\n    // e.g., slices = [0, [1, 3], null, [0, 3]]\n    for (let sliceIndex = 0; sliceIndex < this.dims.length; ++sliceIndex) {\n      let slice = sliceIndex < 0 || arguments.length <= sliceIndex ? undefined : arguments[sliceIndex];\n      if (slice === null || slice === undefined) {\n        // null or undefined means take the whole dimension\n        newOffsets.push([0, this.dims[sliceIndex]]);\n        newTensorDims.push(this.dims[sliceIndex]);\n      } else if (typeof slice === 'number') {\n        if (slice < -this.dims[sliceIndex] || slice >= this.dims[sliceIndex]) {\n          throw new Error(`IndexError: index ${slice} is out of bounds for dimension ${sliceIndex} with size ${this.dims[sliceIndex]}`);\n        }\n        if (slice < 0) {\n          slice += this.dims[sliceIndex];\n        }\n\n        // A number means take a single element\n        newOffsets.push([slice, slice + 1]);\n      } else if (Array.isArray(slice) && slice.length === 2) {\n        // An array of length 2 means take a range of elements\n\n        if (slice[0] > slice[1]) {\n          throw new Error(`Invalid slice: ${slice}`);\n        }\n        let offsets = [Math.max(slice[0], 0), Math.min(slice[1], this.dims[sliceIndex])];\n        newOffsets.push(offsets);\n        newTensorDims.push(offsets[1] - offsets[0]);\n      } else {\n        throw new Error(`Invalid slice: ${slice}`);\n      }\n    }\n    let newDims = newOffsets.map(_ref => {\n      let [start, end] = _ref;\n      return end - start;\n    });\n    let newBufferSize = newDims.reduce((a, b) => a * b);\n\n    // Allocate memory\n    let data = new this.data.constructor(newBufferSize);\n\n    // Precompute strides\n    const stride = new Array(this.dims.length);\n    for (let i = newDims.length - 1, s2 = 1; i >= 0; --i) {\n      stride[i] = s2;\n      s2 *= this.dims[i];\n    }\n    for (let i = 0; i < newBufferSize; ++i) {\n      let originalIndex = 0;\n      for (let j = newDims.length - 1, num = i; j >= 0; --j) {\n        const size = newDims[j];\n        originalIndex += (num % size + newOffsets[j][0]) * stride[j];\n        num = Math.floor(num / size);\n      }\n      data[i] = this.data[originalIndex];\n    }\n    return new Tensor(this.type, data, newTensorDims);\n  }\n\n  /**\n   * Return a transposed version of this Tensor, according to the provided dimensions.\n   * @param  {...number} dims Dimensions to transpose.\n   * @returns {Tensor} The transposed tensor.\n   */\n  transpose() {\n    for (var _len2 = arguments.length, dims = new Array(_len2), _key2 = 0; _key2 < _len2; _key2++) {\n      dims[_key2] = arguments[_key2];\n    }\n    return transpose(this, dims);\n  }\n\n  // TODO add .max() and .min() methods\n\n  /**\n   * Returns the sum of each row of the input tensor in the given dimension dim.\n   * \n   * @param {number} [dim=null] The dimension or dimensions to reduce. If `null`, all dimensions are reduced.\n   * @param {boolean} keepdim Whether the output tensor has `dim` retained or not.\n   * @returns The summed tensor\n   */\n  sum() {\n    let dim = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : null;\n    let keepdim = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : false;\n    return this.norm(1, dim, keepdim);\n  }\n\n  /**\n   * Returns the matrix norm or vector norm of a given tensor.\n   * @param {number|string} [p='fro'] The order of norm\n   * @param {number} [dim=null] Specifies which dimension of the tensor to calculate the norm across.\n   * If dim is None, the norm will be calculated across all dimensions of input.\n   * @param {boolean} [keepdim=false] Whether the output tensors have dim retained or not.\n   * @returns {Tensor} The norm of the tensor.\n   */\n  norm() {\n    let p = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 'fro';\n    let dim = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;\n    let keepdim = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : false;\n    if (p === 'fro') {\n      // NOTE: Since we only support integer dims, Frobenius norm produces the same result as p=2.\n      p = 2;\n    } else if (typeof p === 'string') {\n      throw Error(`Unsupported norm: ${p}`);\n    }\n    if (dim === null) {\n      // @ts-ignore\n      let val = this.data.reduce((a, b) => a + b ** p, 0) ** (1 / p);\n      return new Tensor(this.type, [val], [1]);\n    }\n    if (dim < 0) {\n      // Negative indexing\n      dim += this.dims.length;\n    }\n\n    // Calculate the shape of the resulting array after summation\n    const resultDims = this.dims.slice(); // Copy the original dimensions\n    resultDims[dim] = 1; // Remove the specified axis\n\n    // Create a new array to store the accumulated values\n    const result = new this.data.constructor(this.data.length / this.dims[dim]);\n\n    // Iterate over the data array\n    for (let i = 0; i < this.data.length; ++i) {\n      // Calculate the index in the resulting array\n      let resultIndex = 0;\n      for (let j = this.dims.length - 1, num = i, resultMultiplier = 1; j >= 0; --j) {\n        const size = this.dims[j];\n        if (j !== dim) {\n          const index = num % size;\n          resultIndex += index * resultMultiplier;\n          resultMultiplier *= resultDims[j];\n        }\n        num = Math.floor(num / size);\n      }\n\n      // Accumulate the value at the current index\n      result[resultIndex] += this.data[i] ** p;\n    }\n    if (p !== 1) {\n      for (let i = 0; i < result.length; ++i) {\n        result[i] = result[i] ** (1 / p);\n      }\n    }\n    if (!keepdim) {\n      resultDims.splice(dim, 1);\n    }\n    return new Tensor(this.type, result, resultDims);\n  }\n\n  /**\n   * Performs `L_p` normalization of inputs over specified dimension. Operates in place.\n   * @param {number} [p=2] The exponent value in the norm formulation\n   * @param {number} [dim=1] The dimension to reduce\n   * @returns {Tensor} `this` for operation chaining.\n   */\n  normalize_() {\n    let p = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 2.0;\n    let dim = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 1;\n    if (dim < 0) {\n      // Negative indexing\n      dim += this.dims.length;\n    }\n    const norm = this.norm(p, dim, true);\n    for (let i = 0; i < this.data.length; ++i) {\n      // Calculate the index in the resulting array\n      let resultIndex = 0;\n      for (let j = this.dims.length - 1, num = i, resultMultiplier = 1; j >= 0; --j) {\n        const size = this.dims[j];\n        if (j !== dim) {\n          const index = num % size;\n          resultIndex += index * resultMultiplier;\n          resultMultiplier *= this.dims[j];\n        }\n        num = Math.floor(num / size);\n      }\n\n      // Divide by normalized value\n      this.data[i] /= norm.data[resultIndex];\n    }\n    return this;\n  }\n\n  /**\n   * Performs `L_p` normalization of inputs over specified dimension.\n   * @param {number} [p=2] The exponent value in the norm formulation\n   * @param {number} [dim=1] The dimension to reduce\n   * @returns {Tensor} The normalized tensor.\n   */\n  normalize() {\n    let p = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 2.0;\n    let dim = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 1;\n    return this.clone().normalize_(p, dim);\n  }\n\n  /**\n   * Compute and return the stride of this tensor.\n   * Stride is the jump necessary to go from one element to the next one in the specified dimension dim.\n   * @returns {number[]} The stride of this tensor.\n   */\n  stride() {\n    const stride = new Array(this.dims.length);\n    for (let i = this.dims.length - 1, s2 = 1; i >= 0; --i) {\n      stride[i] = s2;\n      s2 *= this.dims[i];\n    }\n    return stride;\n  }\n\n  /**\n   * Returns a tensor with all specified dimensions of input of size 1 removed.\n   * \n   * NOTE: The returned tensor shares the storage with the input tensor, so changing the contents of one will change the contents of the other.\n   * If you would like a copy, use `tensor.clone()` before squeezing.\n   * \n   * @param {number} [dim=null] If given, the input will be squeezed only in the specified dimensions.\n   * @returns The squeezed tensor\n   */\n  squeeze() {\n    let dim = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : null;\n    return new Tensor(this.type, this.data, calc_squeeze_dims(this.dims, dim));\n  }\n\n  /**\n   * In-place version of @see {@link Tensor.squeeze}\n   */\n  squeeze_() {\n    let dim = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : null;\n    this.dims = calc_squeeze_dims(this.dims, dim);\n    return this;\n  }\n\n  /**\n   * Returns a new tensor with a dimension of size one inserted at the specified position.\n   * \n   * NOTE: The returned tensor shares the same underlying data with this tensor.\n   * \n   * @param {number} dim The index at which to insert the singleton dimension\n   * @returns The unsqueezed tensor\n   */\n  unsqueeze() {\n    let dim = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : null;\n    return new Tensor(this.type, this.data, calc_unsqueeze_dims(this.dims, dim));\n  }\n\n  /**\n   * In-place version of @see {@link Tensor.unsqueeze}\n   */\n  unsqueeze_() {\n    let dim = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : null;\n    this.dims = calc_unsqueeze_dims(this.dims, dim);\n    return this;\n  }\n\n  /**\n   * In-place version of @see {@link Tensor.flatten}\n   */\n  flatten_() {\n    let start_dim = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 0;\n    let end_dim = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : -1;\n    // TODO validate inputs\n    end_dim = (end_dim + this.dims.length) % this.dims.length;\n    let dimsToKeepBefore = this.dims.slice(0, start_dim);\n    let dimsToFlatten = this.dims.slice(start_dim, end_dim + 1);\n    let dimsToKeepAfter = this.dims.slice(end_dim + 1);\n    this.dims = [...dimsToKeepBefore, dimsToFlatten.reduce((a, b) => a * b, 1), ...dimsToKeepAfter];\n    return this;\n  }\n\n  /**\n   * Flattens input by reshaping it into a one-dimensional tensor.\n   * If `start_dim` or `end_dim` are passed, only dimensions starting with `start_dim`\n   * and ending with `end_dim` are flattened. The order of elements in input is unchanged.\n   * @param {number} start_dim the first dim to flatten\n   * @param {number} end_dim the last dim to flatten\n   * @returns The flattened tensor.\n   */\n  flatten() {\n    let start_dim = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 0;\n    let end_dim = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : -1;\n    return this.clone().flatten_(start_dim, end_dim);\n  }\n\n  /**\n   * Returns a new tensor with the same data as the `self` tensor but of a different `shape`.\n   * @param  {...number} dims the desired size\n   * @returns {Tensor} The tensor with the same data but different shape\n   */\n  view() {\n    // TODO: validate dims\n    let inferredIndex = -1;\n    for (var _len3 = arguments.length, dims = new Array(_len3), _key3 = 0; _key3 < _len3; _key3++) {\n      dims[_key3] = arguments[_key3];\n    }\n    for (let i = 0; i < dims.length; ++i) {\n      if (dims[i] === -1) {\n        if (inferredIndex !== -1) {\n          throw new Error(\"Only one dimension can be inferred\");\n        }\n        inferredIndex = i;\n      }\n    }\n    if (inferredIndex !== -1) {\n      // Some dimension must be inferred\n      const productOther = dims.reduce((product, curr, index) => {\n        return index !== inferredIndex ? product * curr : product;\n      }, 1);\n      dims[inferredIndex] = this.data.length / productOther;\n    }\n    return new Tensor(this.type, this.data, dims); // NOTE: uses same underlying storage\n  }\n}\n\n/**\n * This creates a nested array of a given type and depth (see examples).\n * \n * @example\n *   NestArray<string, 1>; // string[]\n * @example\n *   NestArray<number, 2>; // number[][]\n * @example\n *   NestArray<string, 3>; // string[][][] etc.\n * @template T\n * @template {number} Depth\n * @template {never[]} [Acc=[]]\n * @typedef {Acc['length'] extends Depth ? T : NestArray<T[], Depth, [...Acc, never]>} NestArray\n */\n\n/**\n * Reshapes a 1-dimensional array into an n-dimensional array, according to the provided dimensions.\n *\n * @example\n *   reshape([10                    ], [1      ]); // Type: number[]      Value: [10]\n *   reshape([1, 2, 3, 4            ], [2, 2   ]); // Type: number[][]    Value: [[1, 2], [3, 4]]\n *   reshape([1, 2, 3, 4, 5, 6, 7, 8], [2, 2, 2]); // Type: number[][][]  Value: [[[1, 2], [3, 4]], [[5, 6], [7, 8]]]\n *   reshape([1, 2, 3, 4, 5, 6, 7, 8], [4, 2   ]); // Type: number[][]    Value: [[1, 2], [3, 4], [5, 6], [7, 8]]\n * @param {T[]} data The input array to reshape.\n * @param {DIM} dimensions The target shape/dimensions.\n * @template T\n * @template {[number]|[number, number]|[number, number, number]|[number, number, number, number]} DIM\n * @returns {NestArray<T, DIM[\"length\"]>} The reshaped array.\n */\nfunction reshape(data, dimensions) {\n  const totalElements = data.length;\n  const dimensionSize = dimensions.reduce((a, b) => a * b);\n  if (totalElements !== dimensionSize) {\n    throw Error(`cannot reshape array of size ${totalElements} into shape (${dimensions})`);\n  }\n\n  /** @type {any} */\n  let reshapedArray = data;\n  for (let i = dimensions.length - 1; i >= 0; i--) {\n    reshapedArray = reshapedArray.reduce((acc, val) => {\n      let lastArray = acc[acc.length - 1];\n      if (lastArray.length < dimensions[i]) {\n        lastArray.push(val);\n      } else {\n        acc.push([val]);\n      }\n      return acc;\n    }, [[]]);\n  }\n  return reshapedArray[0];\n}\n\n/**\n * Transposes a tensor according to the provided axes.\n * @param {any} tensor The input tensor to transpose.\n * @param {Array} axes The axes to transpose the tensor along.\n * @returns {Tensor} The transposed tensor.\n */\nexport function transpose(tensor, axes) {\n  const [transposedData, shape] = transpose_data(tensor.data, tensor.dims, axes);\n  return new Tensor(tensor.type, transposedData, shape);\n}\n\n/**\n * Concatenates an array of tensors along the 0th dimension.\n *\n * @param {any} tensors The array of tensors to concatenate.\n * @returns {Tensor} The concatenated tensor.\n */\nexport function cat(tensors) {\n  if (tensors.length === 0) {\n    return tensors[0];\n  }\n  // NOTE: tensors must be batched\n  // NOTE: currently only supports dim=0\n  // TODO: add support for dim != 0\n\n  let tensorType = tensors[0].type;\n  let tensorShape = [...tensors[0].dims];\n  tensorShape[0] = tensors.length;\n\n  // Calculate total size to allocate\n  let total = 0;\n  for (let t of tensors) {\n    total += t.data.length;\n  }\n\n  // Create output tensor of same type as first\n  let data = new tensors[0].data.constructor(total);\n  let offset = 0;\n  for (let t of tensors) {\n    data.set(t.data, offset);\n    offset += t.data.length;\n  }\n  return new Tensor(tensorType, data, tensorShape);\n}\n\n/**\n * Interpolates an Tensor to the given size.\n * @param {Tensor} input The input tensor to interpolate. Data must be channel-first (i.e., [c, h, w])\n * @param {number[]} size The output size of the image\n * @param {string} mode The interpolation mode\n * @param {boolean} align_corners Whether to align corners.\n * @returns {Tensor} The interpolated tensor.\n */\nexport function interpolate(input, _ref2) {\n  let [out_height, out_width] = _ref2;\n  let mode = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 'bilinear';\n  let align_corners = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : false;\n  // Input image dimensions\n  const in_channels = input.dims.at(-3) ?? 1;\n  const in_height = input.dims.at(-2);\n  const in_width = input.dims.at(-1);\n  let output = interpolate_data(input.data, [in_channels, in_height, in_width], [out_height, out_width], mode, align_corners);\n  return new Tensor(input.type, output, [in_channels, out_height, out_width]);\n}\n\n/**\n * Perform mean pooling of the last hidden state followed by a normalization step.\n * @param {Tensor} last_hidden_state Tensor of shape [batchSize, seqLength, embedDim]\n * @param {Tensor} attention_mask Tensor of shape [batchSize, seqLength]\n * @returns {Tensor} Returns a new Tensor of shape [batchSize, embedDim].\n */\nexport function mean_pooling(last_hidden_state, attention_mask) {\n  // last_hidden_state: [batchSize, seqLength, embedDim]\n  // attention_mask:    [batchSize, seqLength]\n\n  let shape = [last_hidden_state.dims[0], last_hidden_state.dims[2]];\n  let returnedData = new last_hidden_state.data.constructor(shape[0] * shape[1]);\n  let [batchSize, seqLength, embedDim] = last_hidden_state.dims;\n  let outIndex = 0;\n  for (let i = 0; i < batchSize; ++i) {\n    let offset = i * embedDim * seqLength;\n    for (let k = 0; k < embedDim; ++k) {\n      let sum = 0;\n      let count = 0;\n      let attnMaskOffset = i * seqLength;\n      let offset2 = offset + k;\n      // Pool over all words in sequence\n      for (let j = 0; j < seqLength; ++j) {\n        // index into attention mask\n        let attn = Number(attention_mask.data[attnMaskOffset + j]);\n        count += attn;\n        sum += last_hidden_state.data[offset2 + j * embedDim] * attn;\n      }\n      let avg = sum / count;\n      returnedData[outIndex++] = avg;\n    }\n  }\n  return new Tensor(last_hidden_state.type, returnedData, shape);\n}\n\n/**\n * Helper function to calculate new dimensions when performing a squeeze operation.\n * @param {number[]} dims The dimensions of the tensor.\n * @param {number|number[]|null} dim The dimension(s) to squeeze.\n * @returns The new dimensions.\n * @private\n */\nfunction calc_squeeze_dims(dims, dim) {\n  dims = dims.slice();\n  if (dim === null) {\n    dims = dims.filter(d => d !== 1);\n  } else if (typeof dim === 'number') {\n    if (dims[dim] === 1) {\n      dims.splice(dim, 1);\n    }\n  } else if (Array.isArray(dim)) {\n    dims = dims.filter((x, i) => {\n      return x !== 1 || !dim.includes(i);\n    });\n  }\n  return dims;\n}\n\n/**\n * Helper function to calculate new dimensions when performing an unsqueeze operation.\n * @param {number[]} dims The dimensions of the tensor.\n * @param {number} dim The dimension to unsqueeze.\n * @returns The new dimensions.\n * @private\n */\nfunction calc_unsqueeze_dims(dims, dim) {\n  // TODO: add bounds error checking\n\n  dims = dims.slice();\n  if (dim < 0) {\n    // Negative indexing, ensuring positive index\n    dim = (dim % dims.length + dims.length) % dims.length;\n  }\n\n  // Insert 1 into specified dimension\n  dims.splice(dim, 0, 1);\n  return dims;\n}","map":{"version":3,"names":["ONNX","interpolate_data","transpose_data","ONNXTensor","Tensor","constructor","_len","arguments","length","args","Array","_key","type","data","dims","Proxy","get","obj","key","index","Number","isInteger","_getitem","set","value","Symbol","iterator","iterLength","iterDims","iterSize","reduce","a","b","i","_subarray","Error","indexOf","item","subarray","tolist","reshape","sigmoid","clone","sigmoid_","Math","exp","slice","newTensorDims","newOffsets","sliceIndex","undefined","push","isArray","offsets","max","min","newDims","map","_ref","start","end","newBufferSize","stride","s2","originalIndex","j","num","size","floor","transpose","_len2","_key2","sum","dim","keepdim","norm","p","val","resultDims","result","resultIndex","resultMultiplier","splice","normalize_","normalize","squeeze","calc_squeeze_dims","squeeze_","unsqueeze","calc_unsqueeze_dims","unsqueeze_","flatten_","start_dim","end_dim","dimsToKeepBefore","dimsToFlatten","dimsToKeepAfter","flatten","view","inferredIndex","_len3","_key3","productOther","product","curr","dimensions","totalElements","dimensionSize","reshapedArray","acc","lastArray","tensor","axes","transposedData","shape","cat","tensors","tensorType","tensorShape","total","t","offset","interpolate","input","_ref2","out_height","out_width","mode","align_corners","in_channels","at","in_height","in_width","output","mean_pooling","last_hidden_state","attention_mask","returnedData","batchSize","seqLength","embedDim","outIndex","k","count","attnMaskOffset","offset2","attn","avg","filter","d","x","includes"],"sources":["/Users/phreetech13/Desktop/RealTimeAudioToText/node_modules/@xenova/transformers/src/utils/tensor.js"],"sourcesContent":["/**\n * @file Helper module for `Tensor` processing.\n * \n * These functions and classes are only used internally, \n * meaning an end-user shouldn't need to access anything here.\n * \n * @module utils/tensor\n */\n\nimport { ONNX } from '../backends/onnx.js';\n\nimport {\n    interpolate_data,\n    transpose_data\n} from './maths.js';\n\n\n/**\n * @typedef {import('./maths.js').AnyTypedArray} AnyTypedArray\n */\n\n/** @type {Object} */\nconst ONNXTensor = ONNX.Tensor;\n\nexport class Tensor extends ONNXTensor {\n    /**\n     * Create a new Tensor or copy an existing Tensor.\n     * @param {[string, Array|AnyTypedArray, number[]]|[ONNXTensor]} args\n     */\n    constructor(...args) {\n        if (args[0] instanceof ONNX.Tensor) {\n            // Create shallow copy\n            super(args[0].type, args[0].data, args[0].dims);\n\n        } else {\n            // Create new\n            super(...args);\n        }\n\n        return new Proxy(this, {\n            get: (obj, key) => {\n                if (typeof key === 'string') {\n                    let index = Number(key);\n                    if (Number.isInteger(index)) {\n                        // key is an integer (i.e., index)\n                        return obj._getitem(index);\n                    }\n                }\n                // @ts-ignore\n                return obj[key];\n            },\n            set: (obj, key, value) => {\n                // TODO allow setting of data\n\n                // @ts-ignore\n                return obj[key] = value;\n            }\n        });\n    }\n\n    /**\n     * Returns an iterator object for iterating over the tensor data in row-major order.\n     * If the tensor has more than one dimension, the iterator will yield subarrays.\n     * @returns {Iterator} An iterator object for iterating over the tensor data in row-major order.\n     */\n    *[Symbol.iterator]() {\n        const [iterLength, ...iterDims] = this.dims;\n\n        if (iterDims.length > 0) {\n            const iterSize = iterDims.reduce((a, b) => a * b);\n            for (let i = 0; i < iterLength; ++i) {\n                yield this._subarray(i, iterSize, iterDims);\n            }\n        } else {\n            yield* this.data\n        }\n\n    }\n\n    /**\n     * Index into a Tensor object.\n     * @param {number} index The index to access.\n     * @returns {Tensor} The data at the specified index.\n     */\n    _getitem(index) {\n        const [iterLength, ...iterDims] = this.dims;\n\n        if (index >= iterLength || index < -iterLength) {\n            throw new Error(`Index ${index} is out of bounds for dimension 0 with size ${iterLength}`);\n        }\n        if (index < 0) {\n            // Negative indexing\n            index += iterLength;\n        }\n\n        if (iterDims.length > 0) {\n            const iterSize = iterDims.reduce((a, b) => a * b);\n            return this._subarray(index, iterSize, iterDims);\n        } else {\n            return new Tensor(this.type, [this.data[index]], iterDims);\n        }\n    }\n\n    /**\n     * @param {number|bigint} item The item to search for in the tensor\n     * @returns {number} The index of the first occurrence of item in the tensor data.\n     */\n    indexOf(item) {\n        for (let index = 0; index < this.data.length; ++index) {\n            // Note: == instead of === so we can match Ints with BigInts\n            if (this.data[index] == item) {\n                return index;\n            }\n        }\n        return -1;\n    }\n\n    /**\n     * @param {number} index \n     * @param {number} iterSize \n     * @param {any} iterDims \n     * @returns {Tensor}\n     */\n    _subarray(index, iterSize, iterDims) {\n        let data = this.data.subarray(index * iterSize, (index + 1) * iterSize);\n        return new Tensor(this.type, data, iterDims);\n    }\n\n    /**\n     * Returns the value of this tensor as a standard JavaScript Number. This only works\n     * for tensors with one element. For other cases, see `Tensor.tolist()`.\n     * @returns {number} The value of this tensor as a standard JavaScript Number.\n     * @throws {Error} If the tensor has more than one element.\n     */\n    item() {\n        if (this.data.length !== 1) {\n            throw new Error(`a Tensor with ${this.data.length} elements cannot be converted to Scalar`);\n        }\n        return this.data[0];\n    }\n\n    /**\n     * Convert tensor data to a n-dimensional JS list\n     * @returns {Array}\n     */\n    tolist() {\n        return reshape(this.data, this.dims)\n    }\n\n    /**\n     * Return a new Tensor with the sigmoid function applied to each element.\n     * @returns {Tensor} The tensor with the sigmoid function applied.\n     */\n    sigmoid() {\n        return this.clone().sigmoid_();\n    }\n\n    /**\n     * Applies the sigmoid function to the tensor in place.\n     * @returns {Tensor} Returns `this`.\n     */\n    sigmoid_() {\n        for (let i = 0; i < this.data.length; ++i) {\n            this.data[i] = 1 / (1 + Math.exp(-this.data[i]));\n        }\n        return this;\n    }\n\n    clone() {\n        return new Tensor(this.type, this.data.slice(), this.dims.slice());\n    }\n\n    slice(...slices) {\n        // This allows for slicing with ranges and numbers\n        let newTensorDims = [];\n        let newOffsets = [];\n\n        // slices is an array of numbers or arrays of numbers\n        // e.g., slices = [0, [1, 3], null, [0, 3]]\n        for (let sliceIndex = 0; sliceIndex < this.dims.length; ++sliceIndex) {\n            let slice = slices[sliceIndex];\n\n            if (slice === null || slice === undefined) {\n                // null or undefined means take the whole dimension\n                newOffsets.push([0, this.dims[sliceIndex]]);\n                newTensorDims.push(this.dims[sliceIndex]);\n\n            } else if (typeof slice === 'number') {\n                if (slice < -this.dims[sliceIndex] || slice >= this.dims[sliceIndex]) {\n                    throw new Error(`IndexError: index ${slice} is out of bounds for dimension ${sliceIndex} with size ${this.dims[sliceIndex]}`);\n                }\n                if (slice < 0) {\n                    slice += this.dims[sliceIndex];\n                }\n\n                // A number means take a single element\n                newOffsets.push([slice, slice + 1]);\n\n            } else if (Array.isArray(slice) && slice.length === 2) {\n                // An array of length 2 means take a range of elements\n\n                if (slice[0] > slice[1]) {\n                    throw new Error(`Invalid slice: ${slice}`);\n                }\n\n                let offsets = [\n                    Math.max(slice[0], 0),\n                    Math.min(slice[1], this.dims[sliceIndex])\n                ];\n\n                newOffsets.push(offsets);\n                newTensorDims.push(offsets[1] - offsets[0]);\n\n            } else {\n                throw new Error(`Invalid slice: ${slice}`);\n            }\n        }\n\n        let newDims = newOffsets.map(([start, end]) => end - start);\n        let newBufferSize = newDims.reduce((a, b) => a * b);\n\n        // Allocate memory\n        let data = new this.data.constructor(newBufferSize);\n\n        // Precompute strides\n        const stride = new Array(this.dims.length);\n        for (let i = newDims.length - 1, s2 = 1; i >= 0; --i) {\n            stride[i] = s2;\n            s2 *= this.dims[i];\n        }\n\n        for (let i = 0; i < newBufferSize; ++i) {\n            let originalIndex = 0;\n            for (let j = newDims.length - 1, num = i; j >= 0; --j) {\n                const size = newDims[j];\n                originalIndex += ((num % size) + newOffsets[j][0]) * stride[j];\n                num = Math.floor(num / size);\n            }\n            data[i] = this.data[originalIndex];\n        }\n        return new Tensor(this.type, data, newTensorDims);\n\n    }\n\n    /**\n     * Return a transposed version of this Tensor, according to the provided dimensions.\n     * @param  {...number} dims Dimensions to transpose.\n     * @returns {Tensor} The transposed tensor.\n     */\n    transpose(...dims) {\n        return transpose(this, dims);\n    }\n\n    // TODO add .max() and .min() methods\n\n    /**\n     * Returns the sum of each row of the input tensor in the given dimension dim.\n     * \n     * @param {number} [dim=null] The dimension or dimensions to reduce. If `null`, all dimensions are reduced.\n     * @param {boolean} keepdim Whether the output tensor has `dim` retained or not.\n     * @returns The summed tensor\n     */\n    sum(dim = null, keepdim = false) {\n        return this.norm(1, dim, keepdim);\n    }\n\n    /**\n     * Returns the matrix norm or vector norm of a given tensor.\n     * @param {number|string} [p='fro'] The order of norm\n     * @param {number} [dim=null] Specifies which dimension of the tensor to calculate the norm across.\n     * If dim is None, the norm will be calculated across all dimensions of input.\n     * @param {boolean} [keepdim=false] Whether the output tensors have dim retained or not.\n     * @returns {Tensor} The norm of the tensor.\n     */\n    norm(p = 'fro', dim = null, keepdim = false) {\n        if (p === 'fro') {\n            // NOTE: Since we only support integer dims, Frobenius norm produces the same result as p=2.\n            p = 2;\n        } else if (typeof p === 'string') {\n            throw Error(`Unsupported norm: ${p}`);\n        }\n\n        if (dim === null) {\n            // @ts-ignore\n            let val = this.data.reduce((a, b) => a + (b ** p), 0) ** (1 / p);\n            return new Tensor(this.type, [val], [1]);\n        }\n\n        if (dim < 0) {\n            // Negative indexing\n            dim += this.dims.length;\n        }\n\n\n        // Calculate the shape of the resulting array after summation\n        const resultDims = this.dims.slice(); // Copy the original dimensions\n        resultDims[dim] = 1; // Remove the specified axis\n\n        // Create a new array to store the accumulated values\n        const result = new this.data.constructor(this.data.length / this.dims[dim]);\n\n        // Iterate over the data array\n        for (let i = 0; i < this.data.length; ++i) {\n\n            // Calculate the index in the resulting array\n            let resultIndex = 0;\n\n            for (let j = this.dims.length - 1, num = i, resultMultiplier = 1; j >= 0; --j) {\n                const size = this.dims[j];\n                if (j !== dim) {\n                    const index = num % size;\n                    resultIndex += index * resultMultiplier;\n                    resultMultiplier *= resultDims[j];\n                }\n                num = Math.floor(num / size);\n            }\n\n            // Accumulate the value at the current index\n            result[resultIndex] += (this.data[i]) ** p;\n        }\n\n        if (p !== 1) {\n            for (let i = 0; i < result.length; ++i) {\n                result[i] = result[i] ** (1 / p);\n            }\n        }\n\n        if (!keepdim) {\n            resultDims.splice(dim, 1);\n        }\n\n        return new Tensor(this.type, result, resultDims);\n    }\n\n    /**\n     * Performs `L_p` normalization of inputs over specified dimension. Operates in place.\n     * @param {number} [p=2] The exponent value in the norm formulation\n     * @param {number} [dim=1] The dimension to reduce\n     * @returns {Tensor} `this` for operation chaining.\n     */\n    normalize_(p = 2.0, dim = 1) {\n        if (dim < 0) {\n            // Negative indexing\n            dim += this.dims.length;\n        }\n\n        const norm = this.norm(p, dim, true);\n\n        for (let i = 0; i < this.data.length; ++i) {\n\n            // Calculate the index in the resulting array\n            let resultIndex = 0;\n\n            for (let j = this.dims.length - 1, num = i, resultMultiplier = 1; j >= 0; --j) {\n                const size = this.dims[j];\n                if (j !== dim) {\n                    const index = num % size;\n                    resultIndex += index * resultMultiplier;\n                    resultMultiplier *= this.dims[j];\n                }\n                num = Math.floor(num / size);\n            }\n\n            // Divide by normalized value\n            this.data[i] /= norm.data[resultIndex];\n        }\n\n        return this;\n    }\n\n    /**\n     * Performs `L_p` normalization of inputs over specified dimension.\n     * @param {number} [p=2] The exponent value in the norm formulation\n     * @param {number} [dim=1] The dimension to reduce\n     * @returns {Tensor} The normalized tensor.\n     */\n    normalize(p = 2.0, dim = 1) {\n        return this.clone().normalize_(p, dim);\n    }\n\n    /**\n     * Compute and return the stride of this tensor.\n     * Stride is the jump necessary to go from one element to the next one in the specified dimension dim.\n     * @returns {number[]} The stride of this tensor.\n     */\n    stride() {\n        const stride = new Array(this.dims.length);\n        for (let i = this.dims.length - 1, s2 = 1; i >= 0; --i) {\n            stride[i] = s2;\n            s2 *= this.dims[i];\n        }\n        return stride;\n    }\n\n    /**\n     * Returns a tensor with all specified dimensions of input of size 1 removed.\n     * \n     * NOTE: The returned tensor shares the storage with the input tensor, so changing the contents of one will change the contents of the other.\n     * If you would like a copy, use `tensor.clone()` before squeezing.\n     * \n     * @param {number} [dim=null] If given, the input will be squeezed only in the specified dimensions.\n     * @returns The squeezed tensor\n     */\n    squeeze(dim = null) {\n        return new Tensor(\n            this.type,\n            this.data,\n            calc_squeeze_dims(this.dims, dim)\n        )\n    }\n\n    /**\n     * In-place version of @see {@link Tensor.squeeze}\n     */\n    squeeze_(dim = null) {\n        this.dims = calc_squeeze_dims(this.dims, dim);\n        return this;\n    }\n\n    /**\n     * Returns a new tensor with a dimension of size one inserted at the specified position.\n     * \n     * NOTE: The returned tensor shares the same underlying data with this tensor.\n     * \n     * @param {number} dim The index at which to insert the singleton dimension\n     * @returns The unsqueezed tensor\n     */\n    unsqueeze(dim = null) {\n        return new Tensor(\n            this.type,\n            this.data,\n            calc_unsqueeze_dims(this.dims, dim)\n        );\n    }\n\n    /**\n     * In-place version of @see {@link Tensor.unsqueeze}\n     */\n    unsqueeze_(dim = null) {\n        this.dims = calc_unsqueeze_dims(this.dims, dim);\n        return this;\n    }\n\n    /**\n     * In-place version of @see {@link Tensor.flatten}\n     */\n    flatten_(start_dim = 0, end_dim = -1) {\n        // TODO validate inputs\n        end_dim = (end_dim + this.dims.length) % this.dims.length;\n\n        let dimsToKeepBefore = this.dims.slice(0, start_dim);\n        let dimsToFlatten = this.dims.slice(start_dim, end_dim + 1);\n        let dimsToKeepAfter = this.dims.slice(end_dim + 1);\n\n        this.dims = [...dimsToKeepBefore, dimsToFlatten.reduce((a, b) => a * b, 1), ...dimsToKeepAfter]\n        return this;\n    }\n\n    /**\n     * Flattens input by reshaping it into a one-dimensional tensor.\n     * If `start_dim` or `end_dim` are passed, only dimensions starting with `start_dim`\n     * and ending with `end_dim` are flattened. The order of elements in input is unchanged.\n     * @param {number} start_dim the first dim to flatten\n     * @param {number} end_dim the last dim to flatten\n     * @returns The flattened tensor.\n     */\n    flatten(start_dim = 0, end_dim = -1) {\n        return this.clone().flatten_(start_dim, end_dim);\n    }\n\n    /**\n     * Returns a new tensor with the same data as the `self` tensor but of a different `shape`.\n     * @param  {...number} dims the desired size\n     * @returns {Tensor} The tensor with the same data but different shape\n     */\n    view(...dims) {\n        // TODO: validate dims\n        let inferredIndex = -1;\n        for (let i = 0; i < dims.length; ++i) {\n            if (dims[i] === -1) {\n                if (inferredIndex !== -1) {\n                    throw new Error(\"Only one dimension can be inferred\");\n                }\n                inferredIndex = i;\n            }\n        }\n\n        if (inferredIndex !== -1) {\n            // Some dimension must be inferred\n            const productOther = dims.reduce((product, curr, index) => {\n                return index !== inferredIndex ? product * curr : product\n            }, 1);\n\n            dims[inferredIndex] = this.data.length / productOther;\n        }\n        return new Tensor(this.type, this.data, dims); // NOTE: uses same underlying storage\n    }\n}\n\n/**\n * This creates a nested array of a given type and depth (see examples).\n * \n * @example\n *   NestArray<string, 1>; // string[]\n * @example\n *   NestArray<number, 2>; // number[][]\n * @example\n *   NestArray<string, 3>; // string[][][] etc.\n * @template T\n * @template {number} Depth\n * @template {never[]} [Acc=[]]\n * @typedef {Acc['length'] extends Depth ? T : NestArray<T[], Depth, [...Acc, never]>} NestArray\n */\n\n/**\n * Reshapes a 1-dimensional array into an n-dimensional array, according to the provided dimensions.\n *\n * @example\n *   reshape([10                    ], [1      ]); // Type: number[]      Value: [10]\n *   reshape([1, 2, 3, 4            ], [2, 2   ]); // Type: number[][]    Value: [[1, 2], [3, 4]]\n *   reshape([1, 2, 3, 4, 5, 6, 7, 8], [2, 2, 2]); // Type: number[][][]  Value: [[[1, 2], [3, 4]], [[5, 6], [7, 8]]]\n *   reshape([1, 2, 3, 4, 5, 6, 7, 8], [4, 2   ]); // Type: number[][]    Value: [[1, 2], [3, 4], [5, 6], [7, 8]]\n * @param {T[]} data The input array to reshape.\n * @param {DIM} dimensions The target shape/dimensions.\n * @template T\n * @template {[number]|[number, number]|[number, number, number]|[number, number, number, number]} DIM\n * @returns {NestArray<T, DIM[\"length\"]>} The reshaped array.\n */\nfunction reshape(data, dimensions) {\n\n    const totalElements = data.length;\n    const dimensionSize = dimensions.reduce((a, b) => a * b);\n\n    if (totalElements !== dimensionSize) {\n        throw Error(`cannot reshape array of size ${totalElements} into shape (${dimensions})`);\n    }\n\n    /** @type {any} */\n    let reshapedArray = data;\n\n    for (let i = dimensions.length - 1; i >= 0; i--) {\n        reshapedArray = reshapedArray.reduce((acc, val) => {\n            let lastArray = acc[acc.length - 1];\n\n            if (lastArray.length < dimensions[i]) {\n                lastArray.push(val);\n            } else {\n                acc.push([val]);\n            }\n\n            return acc;\n        }, [[]]);\n    }\n\n    return reshapedArray[0];\n}\n\n/**\n * Transposes a tensor according to the provided axes.\n * @param {any} tensor The input tensor to transpose.\n * @param {Array} axes The axes to transpose the tensor along.\n * @returns {Tensor} The transposed tensor.\n */\nexport function transpose(tensor, axes) {\n    const [transposedData, shape] = transpose_data(tensor.data, tensor.dims, axes);\n    return new Tensor(tensor.type, transposedData, shape);\n}\n\n\n/**\n * Concatenates an array of tensors along the 0th dimension.\n *\n * @param {any} tensors The array of tensors to concatenate.\n * @returns {Tensor} The concatenated tensor.\n */\nexport function cat(tensors) {\n    if (tensors.length === 0) {\n        return tensors[0];\n    }\n    // NOTE: tensors must be batched\n    // NOTE: currently only supports dim=0\n    // TODO: add support for dim != 0\n\n\n    let tensorType = tensors[0].type;\n    let tensorShape = [...tensors[0].dims];\n    tensorShape[0] = tensors.length;\n\n    // Calculate total size to allocate\n    let total = 0;\n    for (let t of tensors) {\n        total += t.data.length;\n    }\n\n    // Create output tensor of same type as first\n    let data = new tensors[0].data.constructor(total);\n\n    let offset = 0;\n    for (let t of tensors) {\n        data.set(t.data, offset);\n        offset += t.data.length;\n    }\n\n    return new Tensor(tensorType, data, tensorShape)\n}\n\n/**\n * Interpolates an Tensor to the given size.\n * @param {Tensor} input The input tensor to interpolate. Data must be channel-first (i.e., [c, h, w])\n * @param {number[]} size The output size of the image\n * @param {string} mode The interpolation mode\n * @param {boolean} align_corners Whether to align corners.\n * @returns {Tensor} The interpolated tensor.\n */\nexport function interpolate(input, [out_height, out_width], mode = 'bilinear', align_corners = false) {\n\n    // Input image dimensions\n    const in_channels = input.dims.at(-3) ?? 1;\n    const in_height = input.dims.at(-2);\n    const in_width = input.dims.at(-1);\n\n    let output = interpolate_data(\n        input.data,\n        [in_channels, in_height, in_width],\n        [out_height, out_width],\n        mode,\n        align_corners\n    );\n    return new Tensor(input.type, output, [in_channels, out_height, out_width]);\n}\n\n/**\n * Perform mean pooling of the last hidden state followed by a normalization step.\n * @param {Tensor} last_hidden_state Tensor of shape [batchSize, seqLength, embedDim]\n * @param {Tensor} attention_mask Tensor of shape [batchSize, seqLength]\n * @returns {Tensor} Returns a new Tensor of shape [batchSize, embedDim].\n */\nexport function mean_pooling(last_hidden_state, attention_mask) {\n    // last_hidden_state: [batchSize, seqLength, embedDim]\n    // attention_mask:    [batchSize, seqLength]\n\n    let shape = [last_hidden_state.dims[0], last_hidden_state.dims[2]];\n    let returnedData = new last_hidden_state.data.constructor(shape[0] * shape[1]);\n    let [batchSize, seqLength, embedDim] = last_hidden_state.dims;\n\n    let outIndex = 0;\n    for (let i = 0; i < batchSize; ++i) {\n        let offset = i * embedDim * seqLength;\n\n        for (let k = 0; k < embedDim; ++k) {\n            let sum = 0;\n            let count = 0;\n\n            let attnMaskOffset = i * seqLength;\n            let offset2 = offset + k;\n            // Pool over all words in sequence\n            for (let j = 0; j < seqLength; ++j) {\n                // index into attention mask\n                let attn = Number(attention_mask.data[attnMaskOffset + j]);\n\n                count += attn;\n                sum += last_hidden_state.data[offset2 + j * embedDim] * attn;\n            }\n\n            let avg = sum / count;\n            returnedData[outIndex++] = avg;\n        }\n    }\n\n    return new Tensor(\n        last_hidden_state.type,\n        returnedData,\n        shape\n    )\n}\n\n/**\n * Helper function to calculate new dimensions when performing a squeeze operation.\n * @param {number[]} dims The dimensions of the tensor.\n * @param {number|number[]|null} dim The dimension(s) to squeeze.\n * @returns The new dimensions.\n * @private\n */\nfunction calc_squeeze_dims(dims, dim) {\n    dims = dims.slice();\n    if (dim === null) {\n        dims = dims.filter((d) => d !== 1);\n    } else if (typeof dim === 'number') {\n        if (dims[dim] === 1) {\n            dims.splice(dim, 1);\n        }\n    } else if (Array.isArray(dim)) {\n        dims = dims.filter((x, i) => {\n            return x !== 1 || !dim.includes(i);\n        });\n    }\n    return dims;\n}\n\n/**\n * Helper function to calculate new dimensions when performing an unsqueeze operation.\n * @param {number[]} dims The dimensions of the tensor.\n * @param {number} dim The dimension to unsqueeze.\n * @returns The new dimensions.\n * @private\n */\nfunction calc_unsqueeze_dims(dims, dim) {\n    // TODO: add bounds error checking\n\n    dims = dims.slice();\n    if (dim < 0) {\n        // Negative indexing, ensuring positive index\n        dim = ((dim % dims.length) + dims.length) % dims.length;\n    }\n\n    // Insert 1 into specified dimension\n    dims.splice(dim, 0, 1);\n    return dims;\n}\n"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,SAASA,IAAI,QAAQ,qBAAqB;AAE1C,SACIC,gBAAgB,EAChBC,cAAc,QACX,YAAY;;AAGnB;AACA;AACA;;AAEA;AACA,MAAMC,UAAU,GAAGH,IAAI,CAACI,MAAM;AAE9B,OAAO,MAAMA,MAAM,SAASD,UAAU,CAAC;EACnC;AACJ;AACA;AACA;EACIE,WAAWA,CAAA,EAAU;IAAA,SAAAC,IAAA,GAAAC,SAAA,CAAAC,MAAA,EAANC,IAAI,OAAAC,KAAA,CAAAJ,IAAA,GAAAK,IAAA,MAAAA,IAAA,GAAAL,IAAA,EAAAK,IAAA;MAAJF,IAAI,CAAAE,IAAA,IAAAJ,SAAA,CAAAI,IAAA;IAAA;IACf,IAAIF,IAAI,CAAC,CAAC,CAAC,YAAYT,IAAI,CAACI,MAAM,EAAE;MAChC;MACA,KAAK,CAACK,IAAI,CAAC,CAAC,CAAC,CAACG,IAAI,EAAEH,IAAI,CAAC,CAAC,CAAC,CAACI,IAAI,EAAEJ,IAAI,CAAC,CAAC,CAAC,CAACK,IAAI,CAAC;IAEnD,CAAC,MAAM;MACH;MACA,KAAK,CAAC,GAAGL,IAAI,CAAC;IAClB;IAEA,OAAO,IAAIM,KAAK,CAAC,IAAI,EAAE;MACnBC,GAAG,EAAEA,CAACC,GAAG,EAAEC,GAAG,KAAK;QACf,IAAI,OAAOA,GAAG,KAAK,QAAQ,EAAE;UACzB,IAAIC,KAAK,GAAGC,MAAM,CAACF,GAAG,CAAC;UACvB,IAAIE,MAAM,CAACC,SAAS,CAACF,KAAK,CAAC,EAAE;YACzB;YACA,OAAOF,GAAG,CAACK,QAAQ,CAACH,KAAK,CAAC;UAC9B;QACJ;QACA;QACA,OAAOF,GAAG,CAACC,GAAG,CAAC;MACnB,CAAC;MACDK,GAAG,EAAEA,CAACN,GAAG,EAAEC,GAAG,EAAEM,KAAK,KAAK;QACtB;;QAEA;QACA,OAAOP,GAAG,CAACC,GAAG,CAAC,GAAGM,KAAK;MAC3B;IACJ,CAAC,CAAC;EACN;;EAEA;AACJ;AACA;AACA;AACA;EACI,EAAEC,MAAM,CAACC,QAAQ,IAAI;IACjB,MAAM,CAACC,UAAU,EAAE,GAAGC,QAAQ,CAAC,GAAG,IAAI,CAACd,IAAI;IAE3C,IAAIc,QAAQ,CAACpB,MAAM,GAAG,CAAC,EAAE;MACrB,MAAMqB,QAAQ,GAAGD,QAAQ,CAACE,MAAM,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKD,CAAC,GAAGC,CAAC,CAAC;MACjD,KAAK,IAAIC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGN,UAAU,EAAE,EAAEM,CAAC,EAAE;QACjC,MAAM,IAAI,CAACC,SAAS,CAACD,CAAC,EAAEJ,QAAQ,EAAED,QAAQ,CAAC;MAC/C;IACJ,CAAC,MAAM;MACH,OAAO,IAAI,CAACf,IAAI;IACpB;EAEJ;;EAEA;AACJ;AACA;AACA;AACA;EACIS,QAAQA,CAACH,KAAK,EAAE;IACZ,MAAM,CAACQ,UAAU,EAAE,GAAGC,QAAQ,CAAC,GAAG,IAAI,CAACd,IAAI;IAE3C,IAAIK,KAAK,IAAIQ,UAAU,IAAIR,KAAK,GAAG,CAACQ,UAAU,EAAE;MAC5C,MAAM,IAAIQ,KAAK,CAAE,SAAQhB,KAAM,+CAA8CQ,UAAW,EAAC,CAAC;IAC9F;IACA,IAAIR,KAAK,GAAG,CAAC,EAAE;MACX;MACAA,KAAK,IAAIQ,UAAU;IACvB;IAEA,IAAIC,QAAQ,CAACpB,MAAM,GAAG,CAAC,EAAE;MACrB,MAAMqB,QAAQ,GAAGD,QAAQ,CAACE,MAAM,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKD,CAAC,GAAGC,CAAC,CAAC;MACjD,OAAO,IAAI,CAACE,SAAS,CAACf,KAAK,EAAEU,QAAQ,EAAED,QAAQ,CAAC;IACpD,CAAC,MAAM;MACH,OAAO,IAAIxB,MAAM,CAAC,IAAI,CAACQ,IAAI,EAAE,CAAC,IAAI,CAACC,IAAI,CAACM,KAAK,CAAC,CAAC,EAAES,QAAQ,CAAC;IAC9D;EACJ;;EAEA;AACJ;AACA;AACA;EACIQ,OAAOA,CAACC,IAAI,EAAE;IACV,KAAK,IAAIlB,KAAK,GAAG,CAAC,EAAEA,KAAK,GAAG,IAAI,CAACN,IAAI,CAACL,MAAM,EAAE,EAAEW,KAAK,EAAE;MACnD;MACA,IAAI,IAAI,CAACN,IAAI,CAACM,KAAK,CAAC,IAAIkB,IAAI,EAAE;QAC1B,OAAOlB,KAAK;MAChB;IACJ;IACA,OAAO,CAAC,CAAC;EACb;;EAEA;AACJ;AACA;AACA;AACA;AACA;EACIe,SAASA,CAACf,KAAK,EAAEU,QAAQ,EAAED,QAAQ,EAAE;IACjC,IAAIf,IAAI,GAAG,IAAI,CAACA,IAAI,CAACyB,QAAQ,CAACnB,KAAK,GAAGU,QAAQ,EAAE,CAACV,KAAK,GAAG,CAAC,IAAIU,QAAQ,CAAC;IACvE,OAAO,IAAIzB,MAAM,CAAC,IAAI,CAACQ,IAAI,EAAEC,IAAI,EAAEe,QAAQ,CAAC;EAChD;;EAEA;AACJ;AACA;AACA;AACA;AACA;EACIS,IAAIA,CAAA,EAAG;IACH,IAAI,IAAI,CAACxB,IAAI,CAACL,MAAM,KAAK,CAAC,EAAE;MACxB,MAAM,IAAI2B,KAAK,CAAE,iBAAgB,IAAI,CAACtB,IAAI,CAACL,MAAO,yCAAwC,CAAC;IAC/F;IACA,OAAO,IAAI,CAACK,IAAI,CAAC,CAAC,CAAC;EACvB;;EAEA;AACJ;AACA;AACA;EACI0B,MAAMA,CAAA,EAAG;IACL,OAAOC,OAAO,CAAC,IAAI,CAAC3B,IAAI,EAAE,IAAI,CAACC,IAAI,CAAC;EACxC;;EAEA;AACJ;AACA;AACA;EACI2B,OAAOA,CAAA,EAAG;IACN,OAAO,IAAI,CAACC,KAAK,CAAC,CAAC,CAACC,QAAQ,CAAC,CAAC;EAClC;;EAEA;AACJ;AACA;AACA;EACIA,QAAQA,CAAA,EAAG;IACP,KAAK,IAAIV,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG,IAAI,CAACpB,IAAI,CAACL,MAAM,EAAE,EAAEyB,CAAC,EAAE;MACvC,IAAI,CAACpB,IAAI,CAACoB,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,GAAGW,IAAI,CAACC,GAAG,CAAC,CAAC,IAAI,CAAChC,IAAI,CAACoB,CAAC,CAAC,CAAC,CAAC;IACpD;IACA,OAAO,IAAI;EACf;EAEAS,KAAKA,CAAA,EAAG;IACJ,OAAO,IAAItC,MAAM,CAAC,IAAI,CAACQ,IAAI,EAAE,IAAI,CAACC,IAAI,CAACiC,KAAK,CAAC,CAAC,EAAE,IAAI,CAAChC,IAAI,CAACgC,KAAK,CAAC,CAAC,CAAC;EACtE;EAEAA,KAAKA,CAAA,EAAY;IACb;IACA,IAAIC,aAAa,GAAG,EAAE;IACtB,IAAIC,UAAU,GAAG,EAAE;;IAEnB;IACA;IACA,KAAK,IAAIC,UAAU,GAAG,CAAC,EAAEA,UAAU,GAAG,IAAI,CAACnC,IAAI,CAACN,MAAM,EAAE,EAAEyC,UAAU,EAAE;MAClE,IAAIH,KAAK,GAAUG,UAAU,QAAA1C,SAAA,CAAAC,MAAA,IAAVyC,UAAU,GAAAC,SAAA,GAAA3C,SAAA,CAAV0C,UAAU,CAAC;MAE9B,IAAIH,KAAK,KAAK,IAAI,IAAIA,KAAK,KAAKI,SAAS,EAAE;QACvC;QACAF,UAAU,CAACG,IAAI,CAAC,CAAC,CAAC,EAAE,IAAI,CAACrC,IAAI,CAACmC,UAAU,CAAC,CAAC,CAAC;QAC3CF,aAAa,CAACI,IAAI,CAAC,IAAI,CAACrC,IAAI,CAACmC,UAAU,CAAC,CAAC;MAE7C,CAAC,MAAM,IAAI,OAAOH,KAAK,KAAK,QAAQ,EAAE;QAClC,IAAIA,KAAK,GAAG,CAAC,IAAI,CAAChC,IAAI,CAACmC,UAAU,CAAC,IAAIH,KAAK,IAAI,IAAI,CAAChC,IAAI,CAACmC,UAAU,CAAC,EAAE;UAClE,MAAM,IAAId,KAAK,CAAE,qBAAoBW,KAAM,mCAAkCG,UAAW,cAAa,IAAI,CAACnC,IAAI,CAACmC,UAAU,CAAE,EAAC,CAAC;QACjI;QACA,IAAIH,KAAK,GAAG,CAAC,EAAE;UACXA,KAAK,IAAI,IAAI,CAAChC,IAAI,CAACmC,UAAU,CAAC;QAClC;;QAEA;QACAD,UAAU,CAACG,IAAI,CAAC,CAACL,KAAK,EAAEA,KAAK,GAAG,CAAC,CAAC,CAAC;MAEvC,CAAC,MAAM,IAAIpC,KAAK,CAAC0C,OAAO,CAACN,KAAK,CAAC,IAAIA,KAAK,CAACtC,MAAM,KAAK,CAAC,EAAE;QACnD;;QAEA,IAAIsC,KAAK,CAAC,CAAC,CAAC,GAAGA,KAAK,CAAC,CAAC,CAAC,EAAE;UACrB,MAAM,IAAIX,KAAK,CAAE,kBAAiBW,KAAM,EAAC,CAAC;QAC9C;QAEA,IAAIO,OAAO,GAAG,CACVT,IAAI,CAACU,GAAG,CAACR,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EACrBF,IAAI,CAACW,GAAG,CAACT,KAAK,CAAC,CAAC,CAAC,EAAE,IAAI,CAAChC,IAAI,CAACmC,UAAU,CAAC,CAAC,CAC5C;QAEDD,UAAU,CAACG,IAAI,CAACE,OAAO,CAAC;QACxBN,aAAa,CAACI,IAAI,CAACE,OAAO,CAAC,CAAC,CAAC,GAAGA,OAAO,CAAC,CAAC,CAAC,CAAC;MAE/C,CAAC,MAAM;QACH,MAAM,IAAIlB,KAAK,CAAE,kBAAiBW,KAAM,EAAC,CAAC;MAC9C;IACJ;IAEA,IAAIU,OAAO,GAAGR,UAAU,CAACS,GAAG,CAACC,IAAA;MAAA,IAAC,CAACC,KAAK,EAAEC,GAAG,CAAC,GAAAF,IAAA;MAAA,OAAKE,GAAG,GAAGD,KAAK;IAAA,EAAC;IAC3D,IAAIE,aAAa,GAAGL,OAAO,CAAC1B,MAAM,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKD,CAAC,GAAGC,CAAC,CAAC;;IAEnD;IACA,IAAInB,IAAI,GAAG,IAAI,IAAI,CAACA,IAAI,CAACR,WAAW,CAACwD,aAAa,CAAC;;IAEnD;IACA,MAAMC,MAAM,GAAG,IAAIpD,KAAK,CAAC,IAAI,CAACI,IAAI,CAACN,MAAM,CAAC;IAC1C,KAAK,IAAIyB,CAAC,GAAGuB,OAAO,CAAChD,MAAM,GAAG,CAAC,EAAEuD,EAAE,GAAG,CAAC,EAAE9B,CAAC,IAAI,CAAC,EAAE,EAAEA,CAAC,EAAE;MAClD6B,MAAM,CAAC7B,CAAC,CAAC,GAAG8B,EAAE;MACdA,EAAE,IAAI,IAAI,CAACjD,IAAI,CAACmB,CAAC,CAAC;IACtB;IAEA,KAAK,IAAIA,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG4B,aAAa,EAAE,EAAE5B,CAAC,EAAE;MACpC,IAAI+B,aAAa,GAAG,CAAC;MACrB,KAAK,IAAIC,CAAC,GAAGT,OAAO,CAAChD,MAAM,GAAG,CAAC,EAAE0D,GAAG,GAAGjC,CAAC,EAAEgC,CAAC,IAAI,CAAC,EAAE,EAAEA,CAAC,EAAE;QACnD,MAAME,IAAI,GAAGX,OAAO,CAACS,CAAC,CAAC;QACvBD,aAAa,IAAI,CAAEE,GAAG,GAAGC,IAAI,GAAInB,UAAU,CAACiB,CAAC,CAAC,CAAC,CAAC,CAAC,IAAIH,MAAM,CAACG,CAAC,CAAC;QAC9DC,GAAG,GAAGtB,IAAI,CAACwB,KAAK,CAACF,GAAG,GAAGC,IAAI,CAAC;MAChC;MACAtD,IAAI,CAACoB,CAAC,CAAC,GAAG,IAAI,CAACpB,IAAI,CAACmD,aAAa,CAAC;IACtC;IACA,OAAO,IAAI5D,MAAM,CAAC,IAAI,CAACQ,IAAI,EAAEC,IAAI,EAAEkC,aAAa,CAAC;EAErD;;EAEA;AACJ;AACA;AACA;AACA;EACIsB,SAASA,CAAA,EAAU;IAAA,SAAAC,KAAA,GAAA/D,SAAA,CAAAC,MAAA,EAANM,IAAI,OAAAJ,KAAA,CAAA4D,KAAA,GAAAC,KAAA,MAAAA,KAAA,GAAAD,KAAA,EAAAC,KAAA;MAAJzD,IAAI,CAAAyD,KAAA,IAAAhE,SAAA,CAAAgE,KAAA;IAAA;IACb,OAAOF,SAAS,CAAC,IAAI,EAAEvD,IAAI,CAAC;EAChC;;EAEA;;EAEA;AACJ;AACA;AACA;AACA;AACA;AACA;EACI0D,GAAGA,CAAA,EAA8B;IAAA,IAA7BC,GAAG,GAAAlE,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAA2C,SAAA,GAAA3C,SAAA,MAAG,IAAI;IAAA,IAAEmE,OAAO,GAAAnE,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAA2C,SAAA,GAAA3C,SAAA,MAAG,KAAK;IAC3B,OAAO,IAAI,CAACoE,IAAI,CAAC,CAAC,EAAEF,GAAG,EAAEC,OAAO,CAAC;EACrC;;EAEA;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;EACIC,IAAIA,CAAA,EAAyC;IAAA,IAAxCC,CAAC,GAAArE,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAA2C,SAAA,GAAA3C,SAAA,MAAG,KAAK;IAAA,IAAEkE,GAAG,GAAAlE,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAA2C,SAAA,GAAA3C,SAAA,MAAG,IAAI;IAAA,IAAEmE,OAAO,GAAAnE,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAA2C,SAAA,GAAA3C,SAAA,MAAG,KAAK;IACvC,IAAIqE,CAAC,KAAK,KAAK,EAAE;MACb;MACAA,CAAC,GAAG,CAAC;IACT,CAAC,MAAM,IAAI,OAAOA,CAAC,KAAK,QAAQ,EAAE;MAC9B,MAAMzC,KAAK,CAAE,qBAAoByC,CAAE,EAAC,CAAC;IACzC;IAEA,IAAIH,GAAG,KAAK,IAAI,EAAE;MACd;MACA,IAAII,GAAG,GAAG,IAAI,CAAChE,IAAI,CAACiB,MAAM,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKD,CAAC,GAAIC,CAAC,IAAI4C,CAAE,EAAE,CAAC,CAAC,KAAK,CAAC,GAAGA,CAAC,CAAC;MAChE,OAAO,IAAIxE,MAAM,CAAC,IAAI,CAACQ,IAAI,EAAE,CAACiE,GAAG,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;IAC5C;IAEA,IAAIJ,GAAG,GAAG,CAAC,EAAE;MACT;MACAA,GAAG,IAAI,IAAI,CAAC3D,IAAI,CAACN,MAAM;IAC3B;;IAGA;IACA,MAAMsE,UAAU,GAAG,IAAI,CAAChE,IAAI,CAACgC,KAAK,CAAC,CAAC,CAAC,CAAC;IACtCgC,UAAU,CAACL,GAAG,CAAC,GAAG,CAAC,CAAC,CAAC;;IAErB;IACA,MAAMM,MAAM,GAAG,IAAI,IAAI,CAAClE,IAAI,CAACR,WAAW,CAAC,IAAI,CAACQ,IAAI,CAACL,MAAM,GAAG,IAAI,CAACM,IAAI,CAAC2D,GAAG,CAAC,CAAC;;IAE3E;IACA,KAAK,IAAIxC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG,IAAI,CAACpB,IAAI,CAACL,MAAM,EAAE,EAAEyB,CAAC,EAAE;MAEvC;MACA,IAAI+C,WAAW,GAAG,CAAC;MAEnB,KAAK,IAAIf,CAAC,GAAG,IAAI,CAACnD,IAAI,CAACN,MAAM,GAAG,CAAC,EAAE0D,GAAG,GAAGjC,CAAC,EAAEgD,gBAAgB,GAAG,CAAC,EAAEhB,CAAC,IAAI,CAAC,EAAE,EAAEA,CAAC,EAAE;QAC3E,MAAME,IAAI,GAAG,IAAI,CAACrD,IAAI,CAACmD,CAAC,CAAC;QACzB,IAAIA,CAAC,KAAKQ,GAAG,EAAE;UACX,MAAMtD,KAAK,GAAG+C,GAAG,GAAGC,IAAI;UACxBa,WAAW,IAAI7D,KAAK,GAAG8D,gBAAgB;UACvCA,gBAAgB,IAAIH,UAAU,CAACb,CAAC,CAAC;QACrC;QACAC,GAAG,GAAGtB,IAAI,CAACwB,KAAK,CAACF,GAAG,GAAGC,IAAI,CAAC;MAChC;;MAEA;MACAY,MAAM,CAACC,WAAW,CAAC,IAAK,IAAI,CAACnE,IAAI,CAACoB,CAAC,CAAC,IAAK2C,CAAC;IAC9C;IAEA,IAAIA,CAAC,KAAK,CAAC,EAAE;MACT,KAAK,IAAI3C,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG8C,MAAM,CAACvE,MAAM,EAAE,EAAEyB,CAAC,EAAE;QACpC8C,MAAM,CAAC9C,CAAC,CAAC,GAAG8C,MAAM,CAAC9C,CAAC,CAAC,KAAK,CAAC,GAAG2C,CAAC,CAAC;MACpC;IACJ;IAEA,IAAI,CAACF,OAAO,EAAE;MACVI,UAAU,CAACI,MAAM,CAACT,GAAG,EAAE,CAAC,CAAC;IAC7B;IAEA,OAAO,IAAIrE,MAAM,CAAC,IAAI,CAACQ,IAAI,EAAEmE,MAAM,EAAED,UAAU,CAAC;EACpD;;EAEA;AACJ;AACA;AACA;AACA;AACA;EACIK,UAAUA,CAAA,EAAmB;IAAA,IAAlBP,CAAC,GAAArE,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAA2C,SAAA,GAAA3C,SAAA,MAAG,GAAG;IAAA,IAAEkE,GAAG,GAAAlE,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAA2C,SAAA,GAAA3C,SAAA,MAAG,CAAC;IACvB,IAAIkE,GAAG,GAAG,CAAC,EAAE;MACT;MACAA,GAAG,IAAI,IAAI,CAAC3D,IAAI,CAACN,MAAM;IAC3B;IAEA,MAAMmE,IAAI,GAAG,IAAI,CAACA,IAAI,CAACC,CAAC,EAAEH,GAAG,EAAE,IAAI,CAAC;IAEpC,KAAK,IAAIxC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG,IAAI,CAACpB,IAAI,CAACL,MAAM,EAAE,EAAEyB,CAAC,EAAE;MAEvC;MACA,IAAI+C,WAAW,GAAG,CAAC;MAEnB,KAAK,IAAIf,CAAC,GAAG,IAAI,CAACnD,IAAI,CAACN,MAAM,GAAG,CAAC,EAAE0D,GAAG,GAAGjC,CAAC,EAAEgD,gBAAgB,GAAG,CAAC,EAAEhB,CAAC,IAAI,CAAC,EAAE,EAAEA,CAAC,EAAE;QAC3E,MAAME,IAAI,GAAG,IAAI,CAACrD,IAAI,CAACmD,CAAC,CAAC;QACzB,IAAIA,CAAC,KAAKQ,GAAG,EAAE;UACX,MAAMtD,KAAK,GAAG+C,GAAG,GAAGC,IAAI;UACxBa,WAAW,IAAI7D,KAAK,GAAG8D,gBAAgB;UACvCA,gBAAgB,IAAI,IAAI,CAACnE,IAAI,CAACmD,CAAC,CAAC;QACpC;QACAC,GAAG,GAAGtB,IAAI,CAACwB,KAAK,CAACF,GAAG,GAAGC,IAAI,CAAC;MAChC;;MAEA;MACA,IAAI,CAACtD,IAAI,CAACoB,CAAC,CAAC,IAAI0C,IAAI,CAAC9D,IAAI,CAACmE,WAAW,CAAC;IAC1C;IAEA,OAAO,IAAI;EACf;;EAEA;AACJ;AACA;AACA;AACA;AACA;EACII,SAASA,CAAA,EAAmB;IAAA,IAAlBR,CAAC,GAAArE,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAA2C,SAAA,GAAA3C,SAAA,MAAG,GAAG;IAAA,IAAEkE,GAAG,GAAAlE,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAA2C,SAAA,GAAA3C,SAAA,MAAG,CAAC;IACtB,OAAO,IAAI,CAACmC,KAAK,CAAC,CAAC,CAACyC,UAAU,CAACP,CAAC,EAAEH,GAAG,CAAC;EAC1C;;EAEA;AACJ;AACA;AACA;AACA;EACIX,MAAMA,CAAA,EAAG;IACL,MAAMA,MAAM,GAAG,IAAIpD,KAAK,CAAC,IAAI,CAACI,IAAI,CAACN,MAAM,CAAC;IAC1C,KAAK,IAAIyB,CAAC,GAAG,IAAI,CAACnB,IAAI,CAACN,MAAM,GAAG,CAAC,EAAEuD,EAAE,GAAG,CAAC,EAAE9B,CAAC,IAAI,CAAC,EAAE,EAAEA,CAAC,EAAE;MACpD6B,MAAM,CAAC7B,CAAC,CAAC,GAAG8B,EAAE;MACdA,EAAE,IAAI,IAAI,CAACjD,IAAI,CAACmB,CAAC,CAAC;IACtB;IACA,OAAO6B,MAAM;EACjB;;EAEA;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACIuB,OAAOA,CAAA,EAAa;IAAA,IAAZZ,GAAG,GAAAlE,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAA2C,SAAA,GAAA3C,SAAA,MAAG,IAAI;IACd,OAAO,IAAIH,MAAM,CACb,IAAI,CAACQ,IAAI,EACT,IAAI,CAACC,IAAI,EACTyE,iBAAiB,CAAC,IAAI,CAACxE,IAAI,EAAE2D,GAAG,CACpC,CAAC;EACL;;EAEA;AACJ;AACA;EACIc,QAAQA,CAAA,EAAa;IAAA,IAAZd,GAAG,GAAAlE,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAA2C,SAAA,GAAA3C,SAAA,MAAG,IAAI;IACf,IAAI,CAACO,IAAI,GAAGwE,iBAAiB,CAAC,IAAI,CAACxE,IAAI,EAAE2D,GAAG,CAAC;IAC7C,OAAO,IAAI;EACf;;EAEA;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;EACIe,SAASA,CAAA,EAAa;IAAA,IAAZf,GAAG,GAAAlE,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAA2C,SAAA,GAAA3C,SAAA,MAAG,IAAI;IAChB,OAAO,IAAIH,MAAM,CACb,IAAI,CAACQ,IAAI,EACT,IAAI,CAACC,IAAI,EACT4E,mBAAmB,CAAC,IAAI,CAAC3E,IAAI,EAAE2D,GAAG,CACtC,CAAC;EACL;;EAEA;AACJ;AACA;EACIiB,UAAUA,CAAA,EAAa;IAAA,IAAZjB,GAAG,GAAAlE,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAA2C,SAAA,GAAA3C,SAAA,MAAG,IAAI;IACjB,IAAI,CAACO,IAAI,GAAG2E,mBAAmB,CAAC,IAAI,CAAC3E,IAAI,EAAE2D,GAAG,CAAC;IAC/C,OAAO,IAAI;EACf;;EAEA;AACJ;AACA;EACIkB,QAAQA,CAAA,EAA8B;IAAA,IAA7BC,SAAS,GAAArF,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAA2C,SAAA,GAAA3C,SAAA,MAAG,CAAC;IAAA,IAAEsF,OAAO,GAAAtF,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAA2C,SAAA,GAAA3C,SAAA,MAAG,CAAC,CAAC;IAChC;IACAsF,OAAO,GAAG,CAACA,OAAO,GAAG,IAAI,CAAC/E,IAAI,CAACN,MAAM,IAAI,IAAI,CAACM,IAAI,CAACN,MAAM;IAEzD,IAAIsF,gBAAgB,GAAG,IAAI,CAAChF,IAAI,CAACgC,KAAK,CAAC,CAAC,EAAE8C,SAAS,CAAC;IACpD,IAAIG,aAAa,GAAG,IAAI,CAACjF,IAAI,CAACgC,KAAK,CAAC8C,SAAS,EAAEC,OAAO,GAAG,CAAC,CAAC;IAC3D,IAAIG,eAAe,GAAG,IAAI,CAAClF,IAAI,CAACgC,KAAK,CAAC+C,OAAO,GAAG,CAAC,CAAC;IAElD,IAAI,CAAC/E,IAAI,GAAG,CAAC,GAAGgF,gBAAgB,EAAEC,aAAa,CAACjE,MAAM,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKD,CAAC,GAAGC,CAAC,EAAE,CAAC,CAAC,EAAE,GAAGgE,eAAe,CAAC;IAC/F,OAAO,IAAI;EACf;;EAEA;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;EACIC,OAAOA,CAAA,EAA8B;IAAA,IAA7BL,SAAS,GAAArF,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAA2C,SAAA,GAAA3C,SAAA,MAAG,CAAC;IAAA,IAAEsF,OAAO,GAAAtF,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAA2C,SAAA,GAAA3C,SAAA,MAAG,CAAC,CAAC;IAC/B,OAAO,IAAI,CAACmC,KAAK,CAAC,CAAC,CAACiD,QAAQ,CAACC,SAAS,EAAEC,OAAO,CAAC;EACpD;;EAEA;AACJ;AACA;AACA;AACA;EACIK,IAAIA,CAAA,EAAU;IACV;IACA,IAAIC,aAAa,GAAG,CAAC,CAAC;IAAC,SAAAC,KAAA,GAAA7F,SAAA,CAAAC,MAAA,EAFnBM,IAAI,OAAAJ,KAAA,CAAA0F,KAAA,GAAAC,KAAA,MAAAA,KAAA,GAAAD,KAAA,EAAAC,KAAA;MAAJvF,IAAI,CAAAuF,KAAA,IAAA9F,SAAA,CAAA8F,KAAA;IAAA;IAGR,KAAK,IAAIpE,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGnB,IAAI,CAACN,MAAM,EAAE,EAAEyB,CAAC,EAAE;MAClC,IAAInB,IAAI,CAACmB,CAAC,CAAC,KAAK,CAAC,CAAC,EAAE;QAChB,IAAIkE,aAAa,KAAK,CAAC,CAAC,EAAE;UACtB,MAAM,IAAIhE,KAAK,CAAC,oCAAoC,CAAC;QACzD;QACAgE,aAAa,GAAGlE,CAAC;MACrB;IACJ;IAEA,IAAIkE,aAAa,KAAK,CAAC,CAAC,EAAE;MACtB;MACA,MAAMG,YAAY,GAAGxF,IAAI,CAACgB,MAAM,CAAC,CAACyE,OAAO,EAAEC,IAAI,EAAErF,KAAK,KAAK;QACvD,OAAOA,KAAK,KAAKgF,aAAa,GAAGI,OAAO,GAAGC,IAAI,GAAGD,OAAO;MAC7D,CAAC,EAAE,CAAC,CAAC;MAELzF,IAAI,CAACqF,aAAa,CAAC,GAAG,IAAI,CAACtF,IAAI,CAACL,MAAM,GAAG8F,YAAY;IACzD;IACA,OAAO,IAAIlG,MAAM,CAAC,IAAI,CAACQ,IAAI,EAAE,IAAI,CAACC,IAAI,EAAEC,IAAI,CAAC,CAAC,CAAC;EACnD;AACJ;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS0B,OAAOA,CAAC3B,IAAI,EAAE4F,UAAU,EAAE;EAE/B,MAAMC,aAAa,GAAG7F,IAAI,CAACL,MAAM;EACjC,MAAMmG,aAAa,GAAGF,UAAU,CAAC3E,MAAM,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKD,CAAC,GAAGC,CAAC,CAAC;EAExD,IAAI0E,aAAa,KAAKC,aAAa,EAAE;IACjC,MAAMxE,KAAK,CAAE,gCAA+BuE,aAAc,gBAAeD,UAAW,GAAE,CAAC;EAC3F;;EAEA;EACA,IAAIG,aAAa,GAAG/F,IAAI;EAExB,KAAK,IAAIoB,CAAC,GAAGwE,UAAU,CAACjG,MAAM,GAAG,CAAC,EAAEyB,CAAC,IAAI,CAAC,EAAEA,CAAC,EAAE,EAAE;IAC7C2E,aAAa,GAAGA,aAAa,CAAC9E,MAAM,CAAC,CAAC+E,GAAG,EAAEhC,GAAG,KAAK;MAC/C,IAAIiC,SAAS,GAAGD,GAAG,CAACA,GAAG,CAACrG,MAAM,GAAG,CAAC,CAAC;MAEnC,IAAIsG,SAAS,CAACtG,MAAM,GAAGiG,UAAU,CAACxE,CAAC,CAAC,EAAE;QAClC6E,SAAS,CAAC3D,IAAI,CAAC0B,GAAG,CAAC;MACvB,CAAC,MAAM;QACHgC,GAAG,CAAC1D,IAAI,CAAC,CAAC0B,GAAG,CAAC,CAAC;MACnB;MAEA,OAAOgC,GAAG;IACd,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC;EACZ;EAEA,OAAOD,aAAa,CAAC,CAAC,CAAC;AAC3B;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,SAASvC,SAASA,CAAC0C,MAAM,EAAEC,IAAI,EAAE;EACpC,MAAM,CAACC,cAAc,EAAEC,KAAK,CAAC,GAAGhH,cAAc,CAAC6G,MAAM,CAAClG,IAAI,EAAEkG,MAAM,CAACjG,IAAI,EAAEkG,IAAI,CAAC;EAC9E,OAAO,IAAI5G,MAAM,CAAC2G,MAAM,CAACnG,IAAI,EAAEqG,cAAc,EAAEC,KAAK,CAAC;AACzD;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,SAASC,GAAGA,CAACC,OAAO,EAAE;EACzB,IAAIA,OAAO,CAAC5G,MAAM,KAAK,CAAC,EAAE;IACtB,OAAO4G,OAAO,CAAC,CAAC,CAAC;EACrB;EACA;EACA;EACA;;EAGA,IAAIC,UAAU,GAAGD,OAAO,CAAC,CAAC,CAAC,CAACxG,IAAI;EAChC,IAAI0G,WAAW,GAAG,CAAC,GAAGF,OAAO,CAAC,CAAC,CAAC,CAACtG,IAAI,CAAC;EACtCwG,WAAW,CAAC,CAAC,CAAC,GAAGF,OAAO,CAAC5G,MAAM;;EAE/B;EACA,IAAI+G,KAAK,GAAG,CAAC;EACb,KAAK,IAAIC,CAAC,IAAIJ,OAAO,EAAE;IACnBG,KAAK,IAAIC,CAAC,CAAC3G,IAAI,CAACL,MAAM;EAC1B;;EAEA;EACA,IAAIK,IAAI,GAAG,IAAIuG,OAAO,CAAC,CAAC,CAAC,CAACvG,IAAI,CAACR,WAAW,CAACkH,KAAK,CAAC;EAEjD,IAAIE,MAAM,GAAG,CAAC;EACd,KAAK,IAAID,CAAC,IAAIJ,OAAO,EAAE;IACnBvG,IAAI,CAACU,GAAG,CAACiG,CAAC,CAAC3G,IAAI,EAAE4G,MAAM,CAAC;IACxBA,MAAM,IAAID,CAAC,CAAC3G,IAAI,CAACL,MAAM;EAC3B;EAEA,OAAO,IAAIJ,MAAM,CAACiH,UAAU,EAAExG,IAAI,EAAEyG,WAAW,CAAC;AACpD;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,SAASI,WAAWA,CAACC,KAAK,EAAAC,KAAA,EAAqE;EAAA,IAAnE,CAACC,UAAU,EAAEC,SAAS,CAAC,GAAAF,KAAA;EAAA,IAAEG,IAAI,GAAAxH,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAA2C,SAAA,GAAA3C,SAAA,MAAG,UAAU;EAAA,IAAEyH,aAAa,GAAAzH,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAA2C,SAAA,GAAA3C,SAAA,MAAG,KAAK;EAEhG;EACA,MAAM0H,WAAW,GAAGN,KAAK,CAAC7G,IAAI,CAACoH,EAAE,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC;EAC1C,MAAMC,SAAS,GAAGR,KAAK,CAAC7G,IAAI,CAACoH,EAAE,CAAC,CAAC,CAAC,CAAC;EACnC,MAAME,QAAQ,GAAGT,KAAK,CAAC7G,IAAI,CAACoH,EAAE,CAAC,CAAC,CAAC,CAAC;EAElC,IAAIG,MAAM,GAAGpI,gBAAgB,CACzB0H,KAAK,CAAC9G,IAAI,EACV,CAACoH,WAAW,EAAEE,SAAS,EAAEC,QAAQ,CAAC,EAClC,CAACP,UAAU,EAAEC,SAAS,CAAC,EACvBC,IAAI,EACJC,aACJ,CAAC;EACD,OAAO,IAAI5H,MAAM,CAACuH,KAAK,CAAC/G,IAAI,EAAEyH,MAAM,EAAE,CAACJ,WAAW,EAAEJ,UAAU,EAAEC,SAAS,CAAC,CAAC;AAC/E;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,SAASQ,YAAYA,CAACC,iBAAiB,EAAEC,cAAc,EAAE;EAC5D;EACA;;EAEA,IAAItB,KAAK,GAAG,CAACqB,iBAAiB,CAACzH,IAAI,CAAC,CAAC,CAAC,EAAEyH,iBAAiB,CAACzH,IAAI,CAAC,CAAC,CAAC,CAAC;EAClE,IAAI2H,YAAY,GAAG,IAAIF,iBAAiB,CAAC1H,IAAI,CAACR,WAAW,CAAC6G,KAAK,CAAC,CAAC,CAAC,GAAGA,KAAK,CAAC,CAAC,CAAC,CAAC;EAC9E,IAAI,CAACwB,SAAS,EAAEC,SAAS,EAAEC,QAAQ,CAAC,GAAGL,iBAAiB,CAACzH,IAAI;EAE7D,IAAI+H,QAAQ,GAAG,CAAC;EAChB,KAAK,IAAI5G,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGyG,SAAS,EAAE,EAAEzG,CAAC,EAAE;IAChC,IAAIwF,MAAM,GAAGxF,CAAC,GAAG2G,QAAQ,GAAGD,SAAS;IAErC,KAAK,IAAIG,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGF,QAAQ,EAAE,EAAEE,CAAC,EAAE;MAC/B,IAAItE,GAAG,GAAG,CAAC;MACX,IAAIuE,KAAK,GAAG,CAAC;MAEb,IAAIC,cAAc,GAAG/G,CAAC,GAAG0G,SAAS;MAClC,IAAIM,OAAO,GAAGxB,MAAM,GAAGqB,CAAC;MACxB;MACA,KAAK,IAAI7E,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG0E,SAAS,EAAE,EAAE1E,CAAC,EAAE;QAChC;QACA,IAAIiF,IAAI,GAAG9H,MAAM,CAACoH,cAAc,CAAC3H,IAAI,CAACmI,cAAc,GAAG/E,CAAC,CAAC,CAAC;QAE1D8E,KAAK,IAAIG,IAAI;QACb1E,GAAG,IAAI+D,iBAAiB,CAAC1H,IAAI,CAACoI,OAAO,GAAGhF,CAAC,GAAG2E,QAAQ,CAAC,GAAGM,IAAI;MAChE;MAEA,IAAIC,GAAG,GAAG3E,GAAG,GAAGuE,KAAK;MACrBN,YAAY,CAACI,QAAQ,EAAE,CAAC,GAAGM,GAAG;IAClC;EACJ;EAEA,OAAO,IAAI/I,MAAM,CACbmI,iBAAiB,CAAC3H,IAAI,EACtB6H,YAAY,EACZvB,KACJ,CAAC;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS5B,iBAAiBA,CAACxE,IAAI,EAAE2D,GAAG,EAAE;EAClC3D,IAAI,GAAGA,IAAI,CAACgC,KAAK,CAAC,CAAC;EACnB,IAAI2B,GAAG,KAAK,IAAI,EAAE;IACd3D,IAAI,GAAGA,IAAI,CAACsI,MAAM,CAAEC,CAAC,IAAKA,CAAC,KAAK,CAAC,CAAC;EACtC,CAAC,MAAM,IAAI,OAAO5E,GAAG,KAAK,QAAQ,EAAE;IAChC,IAAI3D,IAAI,CAAC2D,GAAG,CAAC,KAAK,CAAC,EAAE;MACjB3D,IAAI,CAACoE,MAAM,CAACT,GAAG,EAAE,CAAC,CAAC;IACvB;EACJ,CAAC,MAAM,IAAI/D,KAAK,CAAC0C,OAAO,CAACqB,GAAG,CAAC,EAAE;IAC3B3D,IAAI,GAAGA,IAAI,CAACsI,MAAM,CAAC,CAACE,CAAC,EAAErH,CAAC,KAAK;MACzB,OAAOqH,CAAC,KAAK,CAAC,IAAI,CAAC7E,GAAG,CAAC8E,QAAQ,CAACtH,CAAC,CAAC;IACtC,CAAC,CAAC;EACN;EACA,OAAOnB,IAAI;AACf;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS2E,mBAAmBA,CAAC3E,IAAI,EAAE2D,GAAG,EAAE;EACpC;;EAEA3D,IAAI,GAAGA,IAAI,CAACgC,KAAK,CAAC,CAAC;EACnB,IAAI2B,GAAG,GAAG,CAAC,EAAE;IACT;IACAA,GAAG,GAAG,CAAEA,GAAG,GAAG3D,IAAI,CAACN,MAAM,GAAIM,IAAI,CAACN,MAAM,IAAIM,IAAI,CAACN,MAAM;EAC3D;;EAEA;EACAM,IAAI,CAACoE,MAAM,CAACT,GAAG,EAAE,CAAC,EAAE,CAAC,CAAC;EACtB,OAAO3D,IAAI;AACf"},"metadata":{},"sourceType":"module","externalDependencies":[]}